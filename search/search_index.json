{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"<p>   \ud83d\udcab Graph-based foundation model for spatial transcriptomics data  <p>Novae is a deep learning model for spatial domain assignments of spatial transcriptomics data (at both single-cell or spot resolution). It works across multiple gene panels, tissues, and technologies. Novae offers several additional features, including: (i) native batch-effect correction, (ii) analysis of spatially variable genes and pathways, and (iii) architecture analysis of tissue slides.</p> <p>Info</p> <p>Novae was developed by the authors of <code>sopa</code> and is part of the <code>scverse</code> ecosystem.</p>"},{"location":"#overview","title":"Overview","text":"<p>(a) Novae was trained on a large dataset, and is shared on Hugging Face Hub. (b) Illustration of the main tasks and properties of Novae. (c) Illustration of the method behind Novae (self-supervision on graphs, adapted from SwAV).</p>"},{"location":"#why-using-novae","title":"Why using Novae","text":"<ul> <li>It is already pretrained on a large dataset (pan human/mouse tissues, brain, ...). Therefore, you can compute spatial domains in a zero-shot manner (i.e., without fine-tuning).</li> <li>It has been developed to find consistent domains across many slides. This also works if you have different technologies (e.g., MERSCOPE/Xenium) and multiple gene panels.</li> <li>You can natively correct batch-effect, without using external tools.</li> <li>After inference, the spatial domain assignment is super fast, allowing you to try multiple resolutions easily.</li> <li>It supports many downstream tasks, all included inside one framework.</li> </ul>"},{"location":"advice/","title":"Usage advice","text":"<p>Here, we list some advice to help you get the best out of Novae.</p>"},{"location":"advice/#high-quality-training-subset","title":"High-quality training subset","text":"<p>When you have many slides, it's recommended to train or fine-tune Novae only on the high-quality slides and run inference (i.e., spatial domain assignment) on all slides. This allows noise removal in the model training while still applying Novae to the whole dataset.</p>"},{"location":"advice/#resolution-or-level","title":"Resolution or level","text":"<p>When running <code>assign_domains</code> in zero-shot, it may be better to use the <code>resolution</code> argument. When fine-tuning or re-training a Novae model, using <code>level</code> is recommended.</p> <p>Info</p> <p>An advantage of using <code>level</code> is that the domains will be nested through the different levels \u2014 we don't have such a property using the <code>resolution</code> argument.</p>"},{"location":"advice/#rare-tissues","title":"Rare tissues","text":"<p>If you have a rare tissue or a tissue that was not used in our large dataset, you might consider re-training a model from scratch. The pre-trained models may work, but if you have low-quality results, it may be interesting to consider re-training a model (see this tutorial \u2014 you can skip the H&amp;E-embedding section if you don't have an H&amp;E slide aligned).</p>"},{"location":"advice/#hyperparameters","title":"Hyperparameters","text":"<p>We recommend using the default Novae hyperparameters, which should work great in most cases. Yet, if you confortable with Novae you might consider updating them. In that case, here are some of the most important hyperparameters in <code>fit</code> or <code>fine_tune</code>:</p> <ul> <li><code>lr</code>, the learning rate: you can decrease it, but we recommend values in <code>[0.0001, 0.001]</code>.</li> <li><code>max_epochs</code>: you can increase it to push the model learning longer. If the model stops because of early stopping, you can also decrease <code>min_delta</code> or increase the <code>patience</code>.</li> </ul> <p>If you train a new model, you can also change <code>n_hops_local</code> and <code>n_hops_view</code> (for instance, use 1 for Visium data), a different temperature (around <code>0.1</code>), or even make the model bigger - see here the initialization parameters.</p> <p>If you want to search for the best hyperparameters, we recommend using a monitoring library, see this FAQ section.</p>"},{"location":"advice/#saving-a-model","title":"Saving a model","text":"<p>If you are satisfied with an existing Novae model that you trained or fine-tuned, you can save it for later usage; see this FAQ section.</p>"},{"location":"cite_us/","title":"Cite us","text":"<p>You can cite our preprint as below:</p> <pre><code>@article{blampeyNovae2024,\n  title = {Novae: A Graph-Based Foundation Model for Spatial Transcriptomics Data},\n  author = {Blampey, Quentin and Benkirane, Hakim and Bercovici, Nadege and Andre, Fabrice and Cournede, Paul-Henry},\n  year = {2024},\n  pages = {2024.09.09.612009},\n  publisher = {bioRxiv},\n  doi = {10.1101/2024.09.09.612009},\n}\n</code></pre> <p>This library has been developed by Quentin Blampey, PhD student in biomathematics and deep learning. The following institutions funded this work:</p> <ul> <li>Lab of Mathematics and Computer Science (MICS), CentraleSup\u00e9lec (Engineering School, Paris-Saclay University).</li> <li>PRISM center, Gustave Roussy Institute (Cancer campus, Paris-Saclay University).</li> </ul>"},{"location":"faq/","title":"Frequently asked questions","text":""},{"location":"faq/#how-to-use-the-gpu","title":"How to use the GPU?","text":"<p>Using a GPU may significantly speed up Novae's training or inference.</p> <p>If you have a valid GPU for PyTorch, you can set the <code>accelerator</code> argument (e.g., one of <code>[\"cpu\", \"gpu\", \"tpu\", \"hpu\", \"mps\", \"auto\"]</code>) in the following methods: model.fit(), model.fine_tune(), model.compute_representations().</p> <p>When using a GPU, we also highly recommend setting multiple workers to speed up the dataset <code>__getitem__</code>. For that, you'll need to set the <code>num_workers</code> argument in the previous methods, according to the number of CPUs available (<code>num_workers=8</code> is usually a good value).</p> <p>For more details, refer to the API of the PyTorch Lightning Trainer and to the API of the PyTorch DataLoader.</p>"},{"location":"faq/#how-to-load-a-pretrained-model","title":"How to load a pretrained model?","text":"<p>We highly recommend loading a pre-trained Novae model instead of re-training from scratch. For that, choose an available Novae model name on our HuggingFace collection, and provide this name to the model.save_pretrained() method:</p> <pre><code>from novae import Novae\n\nmodel = Novae.from_pretrained(\"MICS-Lab/novae-human-0\") # or any valid model name\n</code></pre>"},{"location":"faq/#how-to-avoid-overcorrecting","title":"How to avoid overcorrecting?","text":"<p>By default, Novae corrects the batch-effect to get shared spatial domains across slides. The batch information is used only during training (<code>fit</code> or <code>fine_tune</code>), which should prevent Novae from overcorrecting in <code>zero_shot</code> mode.</p> <p>If not using the <code>zero_shot</code> mode, you can provide the <code>min_prototypes_ratio</code> parameter to control batch effect correction: either (i) in the <code>fine_tune</code> method itself, or (ii) during the model initialization (if retraining a model from scratch).</p> <p>For instance, if <code>min_prototypes_ratio=0.5</code>, Novae expects each slide to contain at least 50% of the prototypes (each prototype can be interpreted as an \"elementary spatial domain\"). Therefore, the lower <code>min_prototypes_ratio</code>, the lower the batch-effect correction. Conversely, if <code>min_prototypes_ratio=1</code>, all prototypes are expected to be found in all slides (this doesn't mean the proportions will be the same overall slides, though).</p>"},{"location":"faq/#how-do-i-save-my-own-model","title":"How do I save my own model?","text":"<p>If you have trained or fine-tuned your own Novae model, you can save it for later use. For that, use the model.save_pretrained() method as below:</p> <pre><code>model.save_pretrained(save_directory=\"./my-model-directory\")\n</code></pre> <p>Then, you can load this model back via the model.from_pretrained() method:</p> <pre><code>from novae import Novae\n\nmodel = Novae.from_pretrained(\"./my-model-directory\")\n</code></pre>"},{"location":"faq/#how-to-turn-lazy-loading-on-or-off","title":"How to turn lazy loading on or off?","text":"<p>By default, lazy loading is used only on large datasets. To enforce a specific behavior, you can do the following:</p> <pre><code># never use lazy loading\nnovae.settings.disable_lazy_loading()\n\n# always use lazy loading\nnovae.settings.enable_lazy_loading()\n\n# use lazy loading only for AnnData objects with 1M+ cells\nnovae.settings.enable_lazy_loading(n_obs_threshold=1_000_000)\n</code></pre>"},{"location":"faq/#how-to-update-the-logging-level","title":"How to update the logging level?","text":"<p>The logging level can be updated as below:</p> <pre><code>import logging\nfrom novae import log\n\nlog.setLevel(logging.ERROR) # or any other level, e.g. logging.DEBUG\n</code></pre>"},{"location":"faq/#how-to-disable-auto-preprocessing","title":"How to disable auto-preprocessing?","text":"<p>By default, Novae will preprocess your <code>adata</code> object if you provide raw counts. More specifically, it will consider you have raw counts if <code>adata.X.max() &gt; 10</code>, and then it will run <code>sc.pp.normalize_total</code> and <code>sc.pp.log1p</code>. To avoid that, you can run:</p> <pre><code>novae.settings.auto_preprocessing = False\n</code></pre>"},{"location":"faq/#how-to-disable-the-multimodal-mode","title":"How to disable the multimodal mode?","text":"<p>By default, Novae will use multimodal mode if and only if you ran <code>novae.compute_histo_embeddings</code> and <code>novae.compute_histo_pca</code>.</p> <p>To force not using the multimodal mode although you already computed H&amp;E embeddings per cell, you can run: <pre><code>novae.settings.disable_multimodal = True\n</code></pre></p>"},{"location":"faq/#how-long-does-it-take-to-use-novae","title":"How long does it take to use Novae?","text":"<p>The <code>pip</code> installation of Novae usually takes less than a minute on a standard laptop. The inference time depends on the number of cells, but typically takes 5-20 minutes on a CPUs, or 30sec to 2 minutes on a GPU (expect it to be roughly 10x times faster on a GPU).</p>"},{"location":"faq/#how-to-train-a-new-novae-model","title":"How to train a new Novae model?","text":"<p>You can decide to train your own Novae model. To do that, simply create a new model as below and use the <code>model.fit</code> method.</p> <pre><code>model = novae.Novae(adata) # one or a list of adata objects\n\nmodel.fit(adata, accelerator=\"cuda\", num_workers=4)\n</code></pre>"},{"location":"faq/#how-to-monitor-the-model-training","title":"How to monitor the model training?","text":"<p>Since we use Pytorch Lightning to train Novae, you can provide an existing Lightning Logger to the <code>fit</code> or <code>fine_tune</code> methods. For instance, there is an existing logger for Weight and Biases, which will allow you to aggregate plenty of training metrics, such as loss curves, hardware usage, time, and many others.</p> <p>If you don't want to use a monitoring library but just want to see the model loss curve, you can also use a CSVLogger and then use our novae.plot.loss_curve function. For instance:</p> <pre><code>from lightning.pytorch.loggers import CSVLogger\n\n# save the logs in a directory called \"logs\"\nmodel.fine_tune(logger=CSVLogger(\"logs\"), log_every_n_steps=10)\n\nnovae.plot.loss_curve(\"logs\")\n</code></pre>"},{"location":"faq/#how-to-contribute","title":"How to contribute?","text":"<p>If you want to contribute, check our contributing guide.</p>"},{"location":"faq/#how-to-resolve-any-other-issue","title":"How to resolve any other issue?","text":"<p>If you have any bugs/questions/suggestions, don't hesitate to open a new issue. We'll be happy to help!</p>"},{"location":"getting_started/","title":"Getting started","text":""},{"location":"getting_started/#installation","title":"Installation","text":"<p>Novae can be installed on every OS via <code>pip</code> on any Python version from <code>3.10</code> to <code>3.12</code> (included). By default, we recommend using <code>python==3.10</code>.</p> <p>Advice (optional)</p> <p>We advise creating a new environment via a package manager.</p> <p>For instance, you can create a new <code>conda</code> environment:</p> <pre><code>conda create --name novae python=3.10\nconda activate novae\n</code></pre> <p>Choose one of the following installation mode, depending on your needs.</p> From PyPIuv (editable mode)Using condapip (editable mode) <pre><code>pip install novae\n</code></pre> <p>If you want to use Novae in multimodal mode, you can also install the two following extras: <code>multimodal</code> and <code>conch</code>. You can install both as follows:</p> <pre><code>pip install 'novae[multimodal,conch]'\n</code></pre> <p>Contributing</p> <p>If you want to contribute to Novae, using <code>uv</code> is recommended. You'll also need create a fork, see the CONTRIBUTING guidelines.</p> <pre><code>git clone https://github.com/MICS-Lab/novae.git # or your own fork of Novae\ncd novae\n\nuv sync --all-extras --dev # all extras and the dev dependencies\n</code></pre> <pre><code>conda install bioconda::novae\n</code></pre> <p>Warning</p> <p>You won't be able to install the extra dependencies of Novae with conda.</p> <pre><code>git clone https://github.com/MICS-Lab/novae.git\ncd novae\n\npip install -e . # no extra\npip install -e '.[multimodal,conch]' # all extras\n</code></pre>"},{"location":"getting_started/#next-steps","title":"Next steps","text":"<ul> <li>We recommend to start with our first tutorial.</li> <li>You can also read the API.</li> <li>If you have questions, please check our FAQ or open an issue on the GitHub repository.</li> <li>If you want to contribute, check our contributing guide.</li> </ul>"},{"location":"api/Novae/","title":"Novae model","text":""},{"location":"api/Novae/#novae.Novae","title":"<code>novae.Novae</code>","text":"<p>               Bases: <code>LightningModule</code>, <code>PyTorchModelHubMixin</code></p> <p>Novae model class. It can be used to load a pretrained model or train a new one.</p> <p>Example usage</p> <pre><code>import novae\n\nmodel = novae.Novae.from_pretrained(\"MICS-Lab/novae-human-0\")\n\nmodel.compute_representations(adata, zero_shot=True)\nmodel.assign_domains(adata)\n</code></pre> Source code in <code>novae/model.py</code> <pre><code>class Novae(L.LightningModule, PyTorchModelHubMixin):\n    \"\"\"Novae model class. It can be used to load a pretrained model or train a new one.\n\n    !!! note \"Example usage\"\n        ```python\n        import novae\n\n        model = novae.Novae.from_pretrained(\"MICS-Lab/novae-human-0\")\n\n        model.compute_representations(adata, zero_shot=True)\n        model.assign_domains(adata)\n        ```\n    \"\"\"\n\n    adatas: list[AnnData] | None = None\n\n    def __init__(\n        self,\n        adata: AnnData | list[AnnData] | None = None,\n        embedding_size: int = 100,\n        min_prototypes_ratio: float = 0.3,\n        n_hops_local: int = 2,\n        n_hops_view: int = 2,\n        temperature: float = 0.1,\n        output_size: int = 64,\n        heads: int = 8,\n        hidden_size: int = 128,\n        num_layers: int = 10,\n        batch_size: int = 256,\n        num_prototypes: int = 512,\n        panel_subset_size: float = 0.8,\n        background_noise_lambda: float = 8.0,\n        sensitivity_noise_std: float = 0.05,\n        dropout_rate: float = 0.0,\n        histo_embedding_size: int = 50,\n        scgpt_model_dir: str | None = None,\n        var_names: list[str] | None = None,\n    ) -&gt; None:\n        \"\"\"\n\n        Args:\n            adata: An `AnnData` object, or a list of `AnnData` objects. Optional if the model was initialized with `adata`.\n            embedding_size: Size of the embeddings of the genes (`E` in the article). Do not use it when loading embeddings from scGPT.\n            min_prototypes_ratio: Minimum ratio of prototypes to be used for each slide. Use a low value to get highly slide-specific or condition-specific prototypes.\n            n_hops_local: Number of hops between a cell and its neighborhood cells.\n            n_hops_view: Number of hops between a cell and the origin of a second graph (or 'view').\n            temperature: Temperature used in the cross-entropy loss.\n            output_size: Size of the representations, i.e. the encoder outputs (`O` in the article).\n            heads: Number of heads for the graph encoder.\n            hidden_size: Hidden size for the graph encoder.\n            num_layers: Number of layers for the graph encoder.\n            batch_size: Mini-batch size.\n            num_prototypes: Number of prototypes (`K` in the article).\n            panel_subset_size: Ratio of genes kept from the panel during augmentation.\n            background_noise_lambda: Parameter of the exponential distribution for the noise augmentation.\n            sensitivity_noise_std: Standard deviation for the multiplicative for for the noise augmentation.\n            dropout_rate: Dropout rate for the genes during augmentation.\n            scgpt_model_dir: Path to a directory containing a scGPT checkpoint, i.e. a `vocab.json` and a `best_model.pt` file.\n            var_names: Used when loading a pretrained model. Can also be used to specify the names of the variables to train on, e.g. to not consider low quality proteins whose intensity highly depends on the FOV.\n        \"\"\"\n        super().__init__()\n        ### Initialize cell embedder and prepare adata(s) object(s)\n        if scgpt_model_dir is None:\n            self.adatas, var_names = utils.prepare_adatas(adata, var_names=var_names)\n            self.cell_embedder = CellEmbedder(var_names, embedding_size)\n            self.cell_embedder.pca_init(self.adatas)\n        else:\n            self.cell_embedder = CellEmbedder.from_scgpt_embedding(scgpt_model_dir)\n            embedding_size = self.cell_embedder.embedding_size\n            _scgpt_var_names = self.cell_embedder.gene_names\n            self.adatas, var_names = utils.prepare_adatas(adata, var_names=_scgpt_var_names)\n\n        self.save_hyperparameters(ignore=[\"adata\", \"scgpt_model_dir\"])\n        self.mode = utils.Mode()\n\n        ### Initialize modules\n        self.encoder = GraphEncoder(embedding_size, hidden_size, num_layers, output_size, heads, histo_embedding_size)\n        self.augmentation = GraphAugmentation(\n            panel_subset_size, background_noise_lambda, sensitivity_noise_std, dropout_rate\n        )\n        self.swav_head = SwavHead(self.mode, output_size, num_prototypes, temperature)\n\n        ### Misc\n        self._num_workers = 0\n        self._model_name = None\n        self._datamodule = None\n        self.init_slide_queue(self.adatas, min_prototypes_ratio)\n        self._update_multimodal_mode()\n\n    def init_slide_queue(self, adata: AnnData | list[AnnData] | None, min_prototypes_ratio: float) -&gt; None:\n        \"\"\"\n        Initialize the slide-queue for the SwAV head.\n        This can be used before training (`fit` or `fine_tune`) when there are potentially slide-specific or condition-specific prototypes.\n\n        Args:\n            adata: An `AnnData` object, or a list of `AnnData` objects. Optional if the model was initialized with `adata`.\n            min_prototypes_ratio: Minimum ratio of prototypes to be used for each slide. Use a low value to get highly slide-specific or condition-specific prototypes.\n        \"\"\"\n        self.hparams.min_prototypes_ratio = min_prototypes_ratio\n\n        if adata is None or min_prototypes_ratio == 1:\n            return\n\n        slide_ids = list(utils.unique_obs(adata, Keys.SLIDE_ID))\n        if len(slide_ids) &gt; 1:\n            self.swav_head.set_min_prototypes(min_prototypes_ratio)\n            self.swav_head.init_queue(slide_ids)\n\n    def init_prototypes(\n        self,\n        adata: AnnData | list[AnnData] | None = None,\n        reference: Literal[\"all\", \"largest\"] | str | int | list[str] | list[int] = \"all\",\n    ):\n        datamodule = self._init_datamodule(\n            self._prepare_adatas(utils.get_reference(adata, reference)), sample_cells=Nums.DEFAULT_SAMPLE_CELLS\n        )\n        latent = self._compute_representations_datamodule(None, datamodule, return_representations=True)\n        self.swav_head._prototypes = self.swav_head.compute_kmeans_prototypes(latent)\n\n    def __repr__(self) -&gt; str:\n        info_dict = {\n            \"Known genes\": self.cell_embedder.voc_size,\n            \"Parameters\": utils.pretty_num_parameters(self),\n            \"Model name\": self._model_name,\n            \"Trained\": self.mode.trained,\n            \"Multimodal\": self.mode.multimodal,\n        }\n        return utils.pretty_model_repr(info_dict)\n\n    def __new__(cls, *args, **kwargs) -&gt; \"Novae\":\n        # trick to enable auto-completion despite PyTorchModelHubMixin inheritance\n        return super().__new__(cls, *args, **kwargs)\n\n    @property\n    def datamodule(self) -&gt; NovaeDatamodule:\n        assert self._datamodule is not None, (\n            \"The datamodule was not initialized. You first need to fit the model, i.e. `model.fit(...)`\"\n        )\n        return self._datamodule\n\n    @property\n    def dataset(self) -&gt; NovaeDataset:\n        return self.datamodule.dataset\n\n    @property\n    def num_workers(self) -&gt; int:\n        return self._num_workers\n\n    @num_workers.setter\n    def num_workers(self, value: int) -&gt; None:\n        self._num_workers = value\n        if self._datamodule is not None:\n            self._datamodule.num_workers = value\n\n    def _update_multimodal_mode(self):\n        if settings.disable_multimodal:\n            self.mode.multimodal = False\n            return\n\n        if self.adatas is None:\n            return\n\n        adata = self.adatas[0]\n        self.mode.multimodal = Keys.HISTO_EMBEDDINGS in adata.obsm\n\n        if self.mode.multimodal:\n            n_components = adata.obsm[Keys.HISTO_EMBEDDINGS].shape[1]\n            assert self.hparams.histo_embedding_size == n_components, (\n                f\"H&amp;E embeddings computed with {n_components} components, but model initialized with histo_embedding_size={self.hparams.histo_embedding_size}.\"\n            )\n\n    def _to_anndata_list(self, adata: AnnData | list[AnnData] | None) -&gt; list[AnnData]:\n        if adata is None:\n            assert self.adatas is not None, \"No AnnData object found. Please provide an AnnData object.\"\n            return self.adatas\n        elif isinstance(adata, AnnData):\n            return [adata]\n        elif isinstance(adata, list):\n            return adata\n        else:\n            raise ValueError(f\"Invalid type for `adata`: {type(adata)}\")\n\n    def _prepare_adatas(self, adata: AnnData | list[AnnData] | None):\n        if adata is None:\n            return self.adatas\n        return utils.prepare_adatas(adata, var_names=self.cell_embedder.gene_names)[0]\n\n    def _init_datamodule(\n        self, adata: AnnData | list[AnnData] | None = None, sample_cells: int | None = None, **kwargs: int\n    ):\n        return NovaeDatamodule(\n            self._to_anndata_list(adata),\n            cell_embedder=self.cell_embedder,\n            batch_size=self.hparams.batch_size,\n            n_hops_local=self.hparams.n_hops_local,\n            n_hops_view=self.hparams.n_hops_view,\n            num_workers=self._num_workers,\n            sample_cells=sample_cells,\n            **kwargs,\n        )\n\n    def configure_optimizers(self):\n        lr = self._lr if hasattr(self, \"_lr\") else 1e-3\n        return optim.Adam(self.parameters(), lr=lr)\n\n    def _parse_hardware_args(self, accelerator: str, num_workers: int | None, use_device: bool = False) -&gt; None:\n        if accelerator == \"cpu\" and num_workers:\n            log.warning(\n                \"On CPU, `num_workers != 0` can be very slow. Consider using a GPU, or setting `num_workers=0`.\"\n            )\n\n        if accelerator in [\"auto\", \"cuda\", \"gpu\", \"mps\"] and not num_workers:\n            log.warning(\"On GPU, consider setting `num_workers` (e.g., 4 or 8) for better performance.\")\n\n        if num_workers is not None:\n            self.num_workers = num_workers\n\n        if use_device:\n            device = utils.parse_device_args(accelerator)\n            self.to(device)\n\n    def _embed_pyg_data(self, data: Batch) -&gt; Batch:\n        if self.training:\n            data = self.augmentation(data)\n        return self.cell_embedder(data)\n\n    def forward(self, batch: dict[str, Batch]) -&gt; dict[str, Tensor]:\n        return {key: self.encoder(self._embed_pyg_data(data)) for key, data in batch.items()}\n\n    def training_step(self, batch: dict[str, Batch], batch_idx: int):\n        z_dict: dict[str, Tensor] = self(batch)\n        slide_id = batch[\"main\"].get(\"slide_id\", [None])[0]\n\n        loss, mean_entropy_normalized = self.swav_head.forward(z_dict[\"main\"], z_dict[\"view\"], slide_id)\n\n        self._log_progress_bar(\"loss\", loss)\n        self._log_progress_bar(\"entropy\", mean_entropy_normalized, on_epoch=False)\n\n        return loss\n\n    def on_train_epoch_start(self):\n        self.training = True\n\n        self.datamodule.dataset.shuffle_obs_ilocs()\n\n        after_warm_up = self.current_epoch &gt;= Nums.WARMUP_EPOCHS\n        self.swav_head.prototypes.requires_grad_(after_warm_up or self.mode.pretrained)\n\n    def _log_progress_bar(self, name: str, value: float, on_epoch: bool = True, prog_bar: bool = True, **kwargs):\n        self.log(\n            f\"train/{name}\",\n            value,\n            on_epoch=on_epoch,\n            on_step=True,\n            batch_size=self.hparams.batch_size,\n            prog_bar=prog_bar,\n            **kwargs,\n        )\n\n    @classmethod\n    def from_pretrained(self, model_name_or_path: str, **kwargs: int) -&gt; \"Novae\":\n        \"\"\"Load a pretrained `Novae` model from HuggingFace Hub.\n\n        !!! info \"Available model names\"\n            See [here](https://huggingface.co/collections/MICS-Lab/novae-669cdf1754729d168a69f6bd) the available Novae model names.\n\n        Args:\n            model_name_or_path: Name of the model, e.g. `\"MICS-Lab/novae-1-medium\"`, or path to the local model.\n            **kwargs: Optional kwargs for Hugging Face [`from_pretrained`](https://huggingface.co/docs/huggingface_hub/v0.24.0/en/package_reference/mixins#huggingface_hub.ModelHubMixin.from_pretrained) method.\n\n        Returns:\n            A pretrained `Novae` model.\n        \"\"\"\n        model = super().from_pretrained(model_name_or_path, **kwargs)\n\n        model.mode.from_pretrained()\n        model._model_name = model_name_or_path\n        model.cell_embedder.embedding.weight.requires_grad_(False)\n\n        return model\n\n    def save_pretrained(\n        self,\n        save_directory: str,\n        *,\n        repo_id: str | None = None,\n        push_to_hub: bool = False,\n        **kwargs: int,\n    ):\n        \"\"\"Save a pretrained `Novae` model to a directory.\n\n        Args:\n            save_directory: Path to the directory where the model will be saved.\n            **kwargs: Do not use. These are used to push a new model on HuggingFace Hub.\n        \"\"\"\n\n        super().save_pretrained(\n            save_directory,\n            config=dict(self.hparams),\n            repo_id=repo_id,\n            push_to_hub=push_to_hub,\n            **kwargs,\n        )\n\n    def on_save_checkpoint(self, checkpoint):\n        checkpoint[Keys.NOVAE_VERSION] = __version__\n\n    @classmethod\n    def _load_wandb_artifact(cls, model_name: str, map_location: str = \"cpu\", **kwargs: int) -&gt; \"Novae\":\n        artifact_path = _load_wandb_artifact(model_name) / \"model.ckpt\"\n\n        try:\n            model = cls.load_from_checkpoint(artifact_path, map_location=map_location, strict=False, **kwargs)\n        except TypeError:\n            ckpt_version = torch.load(artifact_path, map_location=map_location).get(Keys.NOVAE_VERSION, \"unknown\")\n            raise ValueError(f\"The model was trained with `novae=={ckpt_version}`, but your version is {__version__}\")\n\n        model.mode.from_pretrained()\n        model._model_name = model_name\n        return model\n\n    @torch.no_grad()\n    def compute_representations(\n        self,\n        adata: AnnData | list[AnnData] | None = None,\n        *,\n        zero_shot: bool = False,\n        reference: str | int | Literal[\"all\", \"largest\"] = \"all\",\n        accelerator: str = \"cpu\",\n        num_workers: int | None = None,\n    ) -&gt; None:\n        \"\"\"Compute the latent representation of Novae for all cells neighborhoods.\n\n        Note:\n            Representations are saved in `adata.obsm[\"novae_latent\"]`\n\n        Args:\n            adata: An `AnnData` object, or a list of `AnnData` objects. Optional if the model was initialized with `adata`.\n            zero_shot: If `True`, the model will be used in zero-shot mode, i.e. without training. In this case, the model will assign each cell to a leaf based on the latent representations.\n            reference: Use only if `zero_shot=True`. Reference slide to use for the new prototypes. Can be the AnnData index, a unique slide id, or one of `[\"all\", \"largest\"]`.\n            accelerator: Accelerator to use. For instance, `'cuda'`, `'cpu'`, or `'auto'`. See Pytorch Lightning for more details.\n            num_workers: Number of workers for the dataloader.\n        \"\"\"\n        assert self.mode.trained, \"Novae must be trained first, so consider running `model.fit()`\"\n\n        self.mode.zero_shot = zero_shot\n        self.training = False\n        self._parse_hardware_args(accelerator, num_workers, use_device=True)\n\n        if adata is None and len(self.adatas) == 1:  # using existing datamodule\n            adatas = self.adatas\n            self._compute_representations_datamodule(self.adatas[0], self.datamodule)\n        else:\n            adatas = self._prepare_adatas(adata)\n            for adata in adatas:\n                datamodule = self._init_datamodule(adata)\n                self._compute_representations_datamodule(adata, datamodule)\n\n        if self.mode.zero_shot:\n            self.assign_to_kmeans_prototypes(adatas, reference)\n\n    def assign_to_kmeans_prototypes(\n        self, adatas: AnnData | list[AnnData], reference: str | int | Literal[\"all\", \"largest\"]\n    ):\n        \"\"\"Compute prototypes based on the latent representations, and assign each cell to a leaf.\"\"\"\n        adatas = [adatas] if isinstance(adatas, AnnData) else adatas\n\n        adatas_refs = utils.get_reference(adatas, reference)\n        adatas_refs = [adatas_refs] if isinstance(adatas_refs, AnnData) else adatas_refs\n\n        latent = np.concatenate([adata.obsm[Keys.REPR][utils.valid_indices(adata)] for adata in adatas_refs])\n        self.swav_head._kmeans_prototypes = self.swav_head.compute_kmeans_prototypes(latent)\n        self.swav_head.reset_clustering(only_zero_shot=True)\n\n        for adata in adatas:\n            self._compute_leaves(adata, None, None)\n\n    @torch.no_grad()\n    def _compute_representations_datamodule(\n        self, adata: AnnData | None, datamodule: NovaeDatamodule, return_representations: bool = False\n    ) -&gt; np.ndarray | None:\n        valid_indices = datamodule.dataset.valid_indices[0]\n        representations, projections = [], []\n\n        if (adata is not None) and self.mode.multimodal is not (Keys.HISTO_EMBEDDINGS in adata.obsm):\n            raise ValueError(\n                f\"Multimodal mode is {'enabled' if self.mode.multimodal else 'disabled'} but `adata.obsm` {'does not' if self.mode.multimodal else 'does'} contain H&amp;E embeddings.\"\n            )\n\n        for batch in utils.tqdm(datamodule.predict_dataloader(), desc=\"Computing representations\"):\n            batch = self.transfer_batch_to_device(batch, self.device, dataloader_idx=0)\n            batch_repr: Tensor = self.encoder(self._embed_pyg_data(batch[\"main\"]))\n\n            representations.append(batch_repr.numpy(force=True))\n\n            if not self.mode.zero_shot:\n                batch_projections = self.swav_head.projection(batch_repr)\n                projections.append(batch_projections.numpy(force=True))\n\n        representations = np.concatenate(representations)\n\n        if return_representations:\n            return representations\n\n        adata.obsm[Keys.REPR] = utils.fill_invalid_indices(representations, adata.n_obs, valid_indices, fill_value=0)\n\n        if not self.mode.zero_shot:\n            projections = np.concatenate(projections)\n            self._compute_leaves(adata, projections, valid_indices)\n\n    def _compute_leaves(self, adata: AnnData, projections: np.ndarray | None, valid_indices: np.ndarray | None):\n        assert (projections is None) is (valid_indices is None)\n\n        if projections is None:\n            valid_indices = utils.valid_indices(adata)\n            representations = torch.tensor(adata.obsm[Keys.REPR][valid_indices])\n            projections = self.swav_head.projection(representations).numpy(force=True)\n\n        leaves_predictions = projections.argmax(axis=1)\n        leaves_predictions = utils.fill_invalid_indices(leaves_predictions, adata.n_obs, valid_indices)\n        adata.obs[Keys.LEAVES] = [x if np.isnan(x) else f\"D{int(x)}\" for x in leaves_predictions]\n\n    def plot_domains_hierarchy(\n        self,\n        max_level: int = 10,\n        hline_level: int | list[int] | None = None,\n        leaf_font_size: int = 8,\n        **kwargs,\n    ):\n        \"\"\"Plot the domains hierarchy as a dendogram.\n\n        Args:\n            max_level: Maximum level to be plot.\n            hline_level: If not `None`, a red line will ne drawn at this/these level(s).\n            leaf_font_size: The font size for the leaf labels.\n        \"\"\"\n        plot._domains_hierarchy(\n            self.swav_head.clustering,\n            max_level=max_level,\n            hline_level=hline_level,\n            leaf_font_size=leaf_font_size,\n            **kwargs,\n        )\n\n    def plot_prototype_weights(self, assign_zeros: bool = True, **kwargs: int):\n        \"\"\"Plot the weights of the prototypes per slide.\"\"\"\n\n        assert self.swav_head.queue is not None, (\n            \"Swav queue not initialized. Initialize it with `model.init_slide_queue(...)`, then train or fine-tune the model.\"\n        )\n\n        weights, thresholds = self.swav_head.queue_weights()\n        weights, thresholds = weights.numpy(force=True), thresholds.numpy(force=True)\n\n        if assign_zeros:\n            for i in range(len(weights)):\n                below_threshold_ilocs = np.where(weights[i] &lt; thresholds)[0]\n                if len(thresholds) - len(below_threshold_ilocs) &gt;= self.swav_head.min_prototypes:\n                    weights[i, below_threshold_ilocs] = 0\n                else:\n                    n_missing = len(thresholds) - self.swav_head.min_prototypes\n                    ilocs = below_threshold_ilocs[\n                        np.argpartition(weights[i, below_threshold_ilocs], n_missing)[:n_missing]\n                    ]\n                    weights[i, ilocs] = 0\n\n        plot._weights_clustermap(weights, self.adatas, list(self.swav_head.slide_label_encoder.keys()), **kwargs)\n\n    def plot_prototype_covariance(self, vmax: float | None = None, **kwargs):\n        covariance = np.cov(self.swav_head.prototypes.data.numpy(force=True))\n\n        vmax = vmax or covariance.max()\n\n        plot._weights_clustermap(\n            covariance, None, [], show_yticklabels=False, show_tissue_legend=False, vmax=vmax, **kwargs\n        )\n\n    def assign_domains(\n        self,\n        adata: AnnData | list[AnnData] | None = None,\n        level: int = 7,\n        n_domains: int | None = None,\n        resolution: float | None = None,\n        key_added: str | None = None,\n    ) -&gt; str:\n        \"\"\"Assign a domain to each cell based on the \"leaves\" classes.\n        It either (i) uses a specific `level` of the hierarchical tree,\n        (ii) enforces a precise number of `n_domains`,\n        or (iii) uses the Leiden clustering on the prototypes with a specific `resolution`.\n\n        By default, uses `level`. On zero-shot only, option (iii) can be better.\n\n        Note:\n            You'll need to run [novae.Novae.compute_representations][] first.\n\n            The domains are saved in `adata.obs[\"novae_domains_X]`, where `X` is the `level` argument or `res{resolution}` if using Leiden.\n\n        Args:\n            adata: An `AnnData` object, or a list of `AnnData` objects. Optional if the model was initialized with `adata`.\n            level: Level of the domains hierarchical tree (i.e., number of different domains to assigned).\n            n_domains: If `level` is not providing the desired number of domains, use this argument to enforce a precise number of domains.\n            resolution: Resolution for the Leiden clustering.\n            key_added: The spatial domains will be saved in `adata.obs[key_added]`. By default, it is `adata.obs[\"novae_domains_X]`, where `X` is the `level` argument.\n\n        Returns:\n            The name of the key added to `adata.obs`.\n        \"\"\"\n        adatas = self._to_anndata_list(adata)\n\n        assert all(Keys.LEAVES in adata.obs for adata in adatas), (\n            f\"Did not found `adata.obs['{Keys.LEAVES}']`. Please run `model.compute_representations(...)` first\"\n        )\n\n        if resolution is not None:\n            _leiden_codes = self._leiden_prototypes(resolution=resolution)\n\n            key_added = f\"{Keys.DOMAINS_PREFIX}res{resolution}\"\n\n            for adata in adatas:\n                adata.obs[key_added] = adata.obs[Keys.LEAVES].map(\n                    lambda x: f\"L{_leiden_codes[int(x[1:])]}\" if isinstance(x, str) else x\n                )\n\n            return key_added\n\n        if n_domains is not None:\n            leaves_indices = utils.unique_leaves_indices(adatas)\n            level = self.swav_head.find_level(leaves_indices, n_domains)\n            return self.assign_domains(adatas, level=level, key_added=key_added)\n\n        assert level is not None, \"The `level` argument can't be None.\"\n\n        key_added = f\"{Keys.DOMAINS_PREFIX}{level}\" if key_added is None else key_added\n\n        for adata in adatas:\n            adata.obs[key_added] = self.swav_head.map_leaves_domains(adata.obs[Keys.LEAVES], level)\n            adata.obs[key_added] = adata.obs[key_added].astype(\"category\")\n\n        return key_added\n\n    @torch.no_grad()\n    def _leiden_prototypes(self, resolution: float = 1, return_codes: bool = True) -&gt; AnnData | np.ndarray:\n        adata_proto = AnnData(self.swav_head.prototypes.numpy(force=True))\n\n        sc.pp.pca(adata_proto)\n        sc.pp.neighbors(adata_proto)\n        sc.tl.leiden(adata_proto, flavor=\"igraph\", resolution=resolution)\n\n        if return_codes:\n            return adata_proto.obs[\"leiden\"].values.codes\n        return adata_proto\n\n    def batch_effect_correction(self, adata: AnnData | list[AnnData] | None = None, obs_key: str | None = None):\n        \"\"\"Correct batch effects from the spatial representations of cells.\n\n        !!! info\n            The corrected spatial representations will be saved in `adata.obsm[\"novae_latent_corrected\"]`.\n\n        Args:\n            adata: An `AnnData` object, or a list of `AnnData` objects.\n            obs_key: Optional key in `adata.obs` containing the domains to use for batch correction. If not provided, the key will be automatically selected.\n        \"\"\"\n        adatas = self._to_anndata_list(adata)\n        obs_key = utils.check_available_domains_key(adatas, obs_key)\n\n        utils.batch_effect_correction(adatas, obs_key)\n\n    def fine_tune(\n        self,\n        adata: AnnData | list[AnnData],\n        *,\n        reference: Literal[\"all\", \"largest\"] | str | int | list[str] | list[int] = \"all\",\n        max_epochs: int = 20,\n        accelerator: str = \"cpu\",\n        num_workers: int | None = None,\n        lr: float = 5e-4,\n        min_delta: float = 0.1,\n        min_prototypes_ratio: float = 0.3,\n        **fit_kwargs: int,\n    ):\n        \"\"\"Fine tune a pretrained Novae model. This will update the prototypes with the new data, and `fit` for one or a few epochs.\n\n        Args:\n            adata: An `AnnData` object, or a list of `AnnData` objects. Optional if the model was initialized with `adata`.\n            reference: Reference slide to use for the new prototypes. Can be the AnnData index, a unique slide id, or one of `[\"all\", \"largest\"]`.\n            max_epochs: Maximum number of training epochs.\n            accelerator: Accelerator to use. For instance, `'cuda'`, `'cpu'`, or `'auto'`. See Pytorch Lightning for more details.\n            num_workers: Number of workers for the dataloader.\n            lr: Model learning rate.\n            min_delta: Minimum change in the monitored quantity to qualify as an improvement (early stopping).\n            min_prototypes_ratio: Minimum ratio of prototypes to be used for each slide. Use a low value to get highly slide-specific or condition-specific prototypes.\n            **fit_kwargs: Optional kwargs for the [novae.Novae.fit][] method.\n        \"\"\"\n        self.mode.fine_tune()\n        self._parse_hardware_args(accelerator, num_workers, use_device=True)\n\n        assert adata is not None, \"Please provide an AnnData object to fine-tune the model.\"\n\n        self.init_prototypes(adata, reference=reference)\n        self.init_slide_queue(adata, min_prototypes_ratio)\n\n        self.fit(\n            adata=adata,\n            max_epochs=max_epochs,\n            accelerator=accelerator,\n            num_workers=num_workers,\n            lr=lr,\n            min_delta=min_delta,\n            **fit_kwargs,\n        )\n\n    def fit(\n        self,\n        adata: AnnData | list[AnnData] | None = None,\n        max_epochs: int = 20,\n        accelerator: str = \"cpu\",\n        num_workers: int | None = None,\n        lr: float = 1e-3,\n        min_delta: float = 0.1,\n        patience: int = 3,\n        callbacks: list[Callback] | None = None,\n        logger: Logger | list[Logger] | bool = False,\n        **trainer_kwargs: int,\n    ):\n        \"\"\"Train a Novae model. The training will be stopped by early stopping.\n\n        !!! warn\n            If you loaded a pretrained model, use [novae.Novae.fine_tune][] instead.\n\n        Args:\n            adata: An `AnnData` object, or a list of `AnnData` objects. Optional if the model was initialized with `adata`.\n            max_epochs: Maximum number of training epochs.\n            accelerator: Accelerator to use. For instance, `'cuda'`, `'cpu'`, or `'auto'`. See Pytorch Lightning for more details.\n            num_workers: Number of workers for the dataloader.\n            lr: Model learning rate.\n            min_delta: Minimum change in the monitored quantity to qualify as an improvement (early stopping).\n            patience: Number of epochs with no improvement after which training will be stopped (early stopping).\n            callbacks: Optional list of Pytorch lightning callbacks.\n            logger: The pytorch lightning logger.\n            **trainer_kwargs: Optional kwargs for the Pytorch Lightning `Trainer` class.\n        \"\"\"\n        self.mode.fit()\n\n        if adata is not None:\n            self.adatas, _ = utils.prepare_adatas(adata, var_names=self.cell_embedder.gene_names)\n\n        ### Misc\n        self._update_multimodal_mode()\n        self._lr = lr\n        self.swav_head.reset_clustering()  # ensure we don't re-use old clusters\n        self._parse_hardware_args(accelerator, num_workers)\n        self._datamodule = self._init_datamodule()\n\n        utils.train(\n            self,\n            self.datamodule,\n            accelerator,\n            max_epochs=max_epochs,\n            patience=patience,\n            min_delta=min_delta,\n            callbacks=callbacks,\n            logger=logger,\n            **trainer_kwargs,\n        )\n\n        self.mode.trained = True\n</code></pre>"},{"location":"api/Novae/#novae.Novae.__init__","title":"<code>__init__(adata=None, embedding_size=100, min_prototypes_ratio=0.3, n_hops_local=2, n_hops_view=2, temperature=0.1, output_size=64, heads=8, hidden_size=128, num_layers=10, batch_size=256, num_prototypes=512, panel_subset_size=0.8, background_noise_lambda=8.0, sensitivity_noise_std=0.05, dropout_rate=0.0, histo_embedding_size=50, scgpt_model_dir=None, var_names=None)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>adata</code> <code>AnnData | list[AnnData] | None</code> <p>An <code>AnnData</code> object, or a list of <code>AnnData</code> objects. Optional if the model was initialized with <code>adata</code>.</p> <code>None</code> <code>embedding_size</code> <code>int</code> <p>Size of the embeddings of the genes (<code>E</code> in the article). Do not use it when loading embeddings from scGPT.</p> <code>100</code> <code>min_prototypes_ratio</code> <code>float</code> <p>Minimum ratio of prototypes to be used for each slide. Use a low value to get highly slide-specific or condition-specific prototypes.</p> <code>0.3</code> <code>n_hops_local</code> <code>int</code> <p>Number of hops between a cell and its neighborhood cells.</p> <code>2</code> <code>n_hops_view</code> <code>int</code> <p>Number of hops between a cell and the origin of a second graph (or 'view').</p> <code>2</code> <code>temperature</code> <code>float</code> <p>Temperature used in the cross-entropy loss.</p> <code>0.1</code> <code>output_size</code> <code>int</code> <p>Size of the representations, i.e. the encoder outputs (<code>O</code> in the article).</p> <code>64</code> <code>heads</code> <code>int</code> <p>Number of heads for the graph encoder.</p> <code>8</code> <code>hidden_size</code> <code>int</code> <p>Hidden size for the graph encoder.</p> <code>128</code> <code>num_layers</code> <code>int</code> <p>Number of layers for the graph encoder.</p> <code>10</code> <code>batch_size</code> <code>int</code> <p>Mini-batch size.</p> <code>256</code> <code>num_prototypes</code> <code>int</code> <p>Number of prototypes (<code>K</code> in the article).</p> <code>512</code> <code>panel_subset_size</code> <code>float</code> <p>Ratio of genes kept from the panel during augmentation.</p> <code>0.8</code> <code>background_noise_lambda</code> <code>float</code> <p>Parameter of the exponential distribution for the noise augmentation.</p> <code>8.0</code> <code>sensitivity_noise_std</code> <code>float</code> <p>Standard deviation for the multiplicative for for the noise augmentation.</p> <code>0.05</code> <code>dropout_rate</code> <code>float</code> <p>Dropout rate for the genes during augmentation.</p> <code>0.0</code> <code>scgpt_model_dir</code> <code>str | None</code> <p>Path to a directory containing a scGPT checkpoint, i.e. a <code>vocab.json</code> and a <code>best_model.pt</code> file.</p> <code>None</code> <code>var_names</code> <code>list[str] | None</code> <p>Used when loading a pretrained model. Can also be used to specify the names of the variables to train on, e.g. to not consider low quality proteins whose intensity highly depends on the FOV.</p> <code>None</code> Source code in <code>novae/model.py</code> <pre><code>def __init__(\n    self,\n    adata: AnnData | list[AnnData] | None = None,\n    embedding_size: int = 100,\n    min_prototypes_ratio: float = 0.3,\n    n_hops_local: int = 2,\n    n_hops_view: int = 2,\n    temperature: float = 0.1,\n    output_size: int = 64,\n    heads: int = 8,\n    hidden_size: int = 128,\n    num_layers: int = 10,\n    batch_size: int = 256,\n    num_prototypes: int = 512,\n    panel_subset_size: float = 0.8,\n    background_noise_lambda: float = 8.0,\n    sensitivity_noise_std: float = 0.05,\n    dropout_rate: float = 0.0,\n    histo_embedding_size: int = 50,\n    scgpt_model_dir: str | None = None,\n    var_names: list[str] | None = None,\n) -&gt; None:\n    \"\"\"\n\n    Args:\n        adata: An `AnnData` object, or a list of `AnnData` objects. Optional if the model was initialized with `adata`.\n        embedding_size: Size of the embeddings of the genes (`E` in the article). Do not use it when loading embeddings from scGPT.\n        min_prototypes_ratio: Minimum ratio of prototypes to be used for each slide. Use a low value to get highly slide-specific or condition-specific prototypes.\n        n_hops_local: Number of hops between a cell and its neighborhood cells.\n        n_hops_view: Number of hops between a cell and the origin of a second graph (or 'view').\n        temperature: Temperature used in the cross-entropy loss.\n        output_size: Size of the representations, i.e. the encoder outputs (`O` in the article).\n        heads: Number of heads for the graph encoder.\n        hidden_size: Hidden size for the graph encoder.\n        num_layers: Number of layers for the graph encoder.\n        batch_size: Mini-batch size.\n        num_prototypes: Number of prototypes (`K` in the article).\n        panel_subset_size: Ratio of genes kept from the panel during augmentation.\n        background_noise_lambda: Parameter of the exponential distribution for the noise augmentation.\n        sensitivity_noise_std: Standard deviation for the multiplicative for for the noise augmentation.\n        dropout_rate: Dropout rate for the genes during augmentation.\n        scgpt_model_dir: Path to a directory containing a scGPT checkpoint, i.e. a `vocab.json` and a `best_model.pt` file.\n        var_names: Used when loading a pretrained model. Can also be used to specify the names of the variables to train on, e.g. to not consider low quality proteins whose intensity highly depends on the FOV.\n    \"\"\"\n    super().__init__()\n    ### Initialize cell embedder and prepare adata(s) object(s)\n    if scgpt_model_dir is None:\n        self.adatas, var_names = utils.prepare_adatas(adata, var_names=var_names)\n        self.cell_embedder = CellEmbedder(var_names, embedding_size)\n        self.cell_embedder.pca_init(self.adatas)\n    else:\n        self.cell_embedder = CellEmbedder.from_scgpt_embedding(scgpt_model_dir)\n        embedding_size = self.cell_embedder.embedding_size\n        _scgpt_var_names = self.cell_embedder.gene_names\n        self.adatas, var_names = utils.prepare_adatas(adata, var_names=_scgpt_var_names)\n\n    self.save_hyperparameters(ignore=[\"adata\", \"scgpt_model_dir\"])\n    self.mode = utils.Mode()\n\n    ### Initialize modules\n    self.encoder = GraphEncoder(embedding_size, hidden_size, num_layers, output_size, heads, histo_embedding_size)\n    self.augmentation = GraphAugmentation(\n        panel_subset_size, background_noise_lambda, sensitivity_noise_std, dropout_rate\n    )\n    self.swav_head = SwavHead(self.mode, output_size, num_prototypes, temperature)\n\n    ### Misc\n    self._num_workers = 0\n    self._model_name = None\n    self._datamodule = None\n    self.init_slide_queue(self.adatas, min_prototypes_ratio)\n    self._update_multimodal_mode()\n</code></pre>"},{"location":"api/Novae/#novae.Novae.assign_domains","title":"<code>assign_domains(adata=None, level=7, n_domains=None, resolution=None, key_added=None)</code>","text":"<p>Assign a domain to each cell based on the \"leaves\" classes. It either (i) uses a specific <code>level</code> of the hierarchical tree, (ii) enforces a precise number of <code>n_domains</code>, or (iii) uses the Leiden clustering on the prototypes with a specific <code>resolution</code>.</p> <p>By default, uses <code>level</code>. On zero-shot only, option (iii) can be better.</p> Note <p>You'll need to run novae.Novae.compute_representations first.</p> <p>The domains are saved in <code>adata.obs[\"novae_domains_X]</code>, where <code>X</code> is the <code>level</code> argument or <code>res{resolution}</code> if using Leiden.</p> <p>Parameters:</p> Name Type Description Default <code>adata</code> <code>AnnData | list[AnnData] | None</code> <p>An <code>AnnData</code> object, or a list of <code>AnnData</code> objects. Optional if the model was initialized with <code>adata</code>.</p> <code>None</code> <code>level</code> <code>int</code> <p>Level of the domains hierarchical tree (i.e., number of different domains to assigned).</p> <code>7</code> <code>n_domains</code> <code>int | None</code> <p>If <code>level</code> is not providing the desired number of domains, use this argument to enforce a precise number of domains.</p> <code>None</code> <code>resolution</code> <code>float | None</code> <p>Resolution for the Leiden clustering.</p> <code>None</code> <code>key_added</code> <code>str | None</code> <p>The spatial domains will be saved in <code>adata.obs[key_added]</code>. By default, it is <code>adata.obs[\"novae_domains_X]</code>, where <code>X</code> is the <code>level</code> argument.</p> <code>None</code> <p>Returns:</p> Type Description <code>str</code> <p>The name of the key added to <code>adata.obs</code>.</p> Source code in <code>novae/model.py</code> <pre><code>def assign_domains(\n    self,\n    adata: AnnData | list[AnnData] | None = None,\n    level: int = 7,\n    n_domains: int | None = None,\n    resolution: float | None = None,\n    key_added: str | None = None,\n) -&gt; str:\n    \"\"\"Assign a domain to each cell based on the \"leaves\" classes.\n    It either (i) uses a specific `level` of the hierarchical tree,\n    (ii) enforces a precise number of `n_domains`,\n    or (iii) uses the Leiden clustering on the prototypes with a specific `resolution`.\n\n    By default, uses `level`. On zero-shot only, option (iii) can be better.\n\n    Note:\n        You'll need to run [novae.Novae.compute_representations][] first.\n\n        The domains are saved in `adata.obs[\"novae_domains_X]`, where `X` is the `level` argument or `res{resolution}` if using Leiden.\n\n    Args:\n        adata: An `AnnData` object, or a list of `AnnData` objects. Optional if the model was initialized with `adata`.\n        level: Level of the domains hierarchical tree (i.e., number of different domains to assigned).\n        n_domains: If `level` is not providing the desired number of domains, use this argument to enforce a precise number of domains.\n        resolution: Resolution for the Leiden clustering.\n        key_added: The spatial domains will be saved in `adata.obs[key_added]`. By default, it is `adata.obs[\"novae_domains_X]`, where `X` is the `level` argument.\n\n    Returns:\n        The name of the key added to `adata.obs`.\n    \"\"\"\n    adatas = self._to_anndata_list(adata)\n\n    assert all(Keys.LEAVES in adata.obs for adata in adatas), (\n        f\"Did not found `adata.obs['{Keys.LEAVES}']`. Please run `model.compute_representations(...)` first\"\n    )\n\n    if resolution is not None:\n        _leiden_codes = self._leiden_prototypes(resolution=resolution)\n\n        key_added = f\"{Keys.DOMAINS_PREFIX}res{resolution}\"\n\n        for adata in adatas:\n            adata.obs[key_added] = adata.obs[Keys.LEAVES].map(\n                lambda x: f\"L{_leiden_codes[int(x[1:])]}\" if isinstance(x, str) else x\n            )\n\n        return key_added\n\n    if n_domains is not None:\n        leaves_indices = utils.unique_leaves_indices(adatas)\n        level = self.swav_head.find_level(leaves_indices, n_domains)\n        return self.assign_domains(adatas, level=level, key_added=key_added)\n\n    assert level is not None, \"The `level` argument can't be None.\"\n\n    key_added = f\"{Keys.DOMAINS_PREFIX}{level}\" if key_added is None else key_added\n\n    for adata in adatas:\n        adata.obs[key_added] = self.swav_head.map_leaves_domains(adata.obs[Keys.LEAVES], level)\n        adata.obs[key_added] = adata.obs[key_added].astype(\"category\")\n\n    return key_added\n</code></pre>"},{"location":"api/Novae/#novae.Novae.assign_to_kmeans_prototypes","title":"<code>assign_to_kmeans_prototypes(adatas, reference)</code>","text":"<p>Compute prototypes based on the latent representations, and assign each cell to a leaf.</p> Source code in <code>novae/model.py</code> <pre><code>def assign_to_kmeans_prototypes(\n    self, adatas: AnnData | list[AnnData], reference: str | int | Literal[\"all\", \"largest\"]\n):\n    \"\"\"Compute prototypes based on the latent representations, and assign each cell to a leaf.\"\"\"\n    adatas = [adatas] if isinstance(adatas, AnnData) else adatas\n\n    adatas_refs = utils.get_reference(adatas, reference)\n    adatas_refs = [adatas_refs] if isinstance(adatas_refs, AnnData) else adatas_refs\n\n    latent = np.concatenate([adata.obsm[Keys.REPR][utils.valid_indices(adata)] for adata in adatas_refs])\n    self.swav_head._kmeans_prototypes = self.swav_head.compute_kmeans_prototypes(latent)\n    self.swav_head.reset_clustering(only_zero_shot=True)\n\n    for adata in adatas:\n        self._compute_leaves(adata, None, None)\n</code></pre>"},{"location":"api/Novae/#novae.Novae.batch_effect_correction","title":"<code>batch_effect_correction(adata=None, obs_key=None)</code>","text":"<p>Correct batch effects from the spatial representations of cells.</p> <p>Info</p> <p>The corrected spatial representations will be saved in <code>adata.obsm[\"novae_latent_corrected\"]</code>.</p> <p>Parameters:</p> Name Type Description Default <code>adata</code> <code>AnnData | list[AnnData] | None</code> <p>An <code>AnnData</code> object, or a list of <code>AnnData</code> objects.</p> <code>None</code> <code>obs_key</code> <code>str | None</code> <p>Optional key in <code>adata.obs</code> containing the domains to use for batch correction. If not provided, the key will be automatically selected.</p> <code>None</code> Source code in <code>novae/model.py</code> <pre><code>def batch_effect_correction(self, adata: AnnData | list[AnnData] | None = None, obs_key: str | None = None):\n    \"\"\"Correct batch effects from the spatial representations of cells.\n\n    !!! info\n        The corrected spatial representations will be saved in `adata.obsm[\"novae_latent_corrected\"]`.\n\n    Args:\n        adata: An `AnnData` object, or a list of `AnnData` objects.\n        obs_key: Optional key in `adata.obs` containing the domains to use for batch correction. If not provided, the key will be automatically selected.\n    \"\"\"\n    adatas = self._to_anndata_list(adata)\n    obs_key = utils.check_available_domains_key(adatas, obs_key)\n\n    utils.batch_effect_correction(adatas, obs_key)\n</code></pre>"},{"location":"api/Novae/#novae.Novae.compute_representations","title":"<code>compute_representations(adata=None, *, zero_shot=False, reference='all', accelerator='cpu', num_workers=None)</code>","text":"<p>Compute the latent representation of Novae for all cells neighborhoods.</p> Note <p>Representations are saved in <code>adata.obsm[\"novae_latent\"]</code></p> <p>Parameters:</p> Name Type Description Default <code>adata</code> <code>AnnData | list[AnnData] | None</code> <p>An <code>AnnData</code> object, or a list of <code>AnnData</code> objects. Optional if the model was initialized with <code>adata</code>.</p> <code>None</code> <code>zero_shot</code> <code>bool</code> <p>If <code>True</code>, the model will be used in zero-shot mode, i.e. without training. In this case, the model will assign each cell to a leaf based on the latent representations.</p> <code>False</code> <code>reference</code> <code>str | int | Literal['all', 'largest']</code> <p>Use only if <code>zero_shot=True</code>. Reference slide to use for the new prototypes. Can be the AnnData index, a unique slide id, or one of <code>[\"all\", \"largest\"]</code>.</p> <code>'all'</code> <code>accelerator</code> <code>str</code> <p>Accelerator to use. For instance, <code>'cuda'</code>, <code>'cpu'</code>, or <code>'auto'</code>. See Pytorch Lightning for more details.</p> <code>'cpu'</code> <code>num_workers</code> <code>int | None</code> <p>Number of workers for the dataloader.</p> <code>None</code> Source code in <code>novae/model.py</code> <pre><code>@torch.no_grad()\ndef compute_representations(\n    self,\n    adata: AnnData | list[AnnData] | None = None,\n    *,\n    zero_shot: bool = False,\n    reference: str | int | Literal[\"all\", \"largest\"] = \"all\",\n    accelerator: str = \"cpu\",\n    num_workers: int | None = None,\n) -&gt; None:\n    \"\"\"Compute the latent representation of Novae for all cells neighborhoods.\n\n    Note:\n        Representations are saved in `adata.obsm[\"novae_latent\"]`\n\n    Args:\n        adata: An `AnnData` object, or a list of `AnnData` objects. Optional if the model was initialized with `adata`.\n        zero_shot: If `True`, the model will be used in zero-shot mode, i.e. without training. In this case, the model will assign each cell to a leaf based on the latent representations.\n        reference: Use only if `zero_shot=True`. Reference slide to use for the new prototypes. Can be the AnnData index, a unique slide id, or one of `[\"all\", \"largest\"]`.\n        accelerator: Accelerator to use. For instance, `'cuda'`, `'cpu'`, or `'auto'`. See Pytorch Lightning for more details.\n        num_workers: Number of workers for the dataloader.\n    \"\"\"\n    assert self.mode.trained, \"Novae must be trained first, so consider running `model.fit()`\"\n\n    self.mode.zero_shot = zero_shot\n    self.training = False\n    self._parse_hardware_args(accelerator, num_workers, use_device=True)\n\n    if adata is None and len(self.adatas) == 1:  # using existing datamodule\n        adatas = self.adatas\n        self._compute_representations_datamodule(self.adatas[0], self.datamodule)\n    else:\n        adatas = self._prepare_adatas(adata)\n        for adata in adatas:\n            datamodule = self._init_datamodule(adata)\n            self._compute_representations_datamodule(adata, datamodule)\n\n    if self.mode.zero_shot:\n        self.assign_to_kmeans_prototypes(adatas, reference)\n</code></pre>"},{"location":"api/Novae/#novae.Novae.fine_tune","title":"<code>fine_tune(adata, *, reference='all', max_epochs=20, accelerator='cpu', num_workers=None, lr=0.0005, min_delta=0.1, min_prototypes_ratio=0.3, **fit_kwargs)</code>","text":"<p>Fine tune a pretrained Novae model. This will update the prototypes with the new data, and <code>fit</code> for one or a few epochs.</p> <p>Parameters:</p> Name Type Description Default <code>adata</code> <code>AnnData | list[AnnData]</code> <p>An <code>AnnData</code> object, or a list of <code>AnnData</code> objects. Optional if the model was initialized with <code>adata</code>.</p> required <code>reference</code> <code>Literal['all', 'largest'] | str | int | list[str] | list[int]</code> <p>Reference slide to use for the new prototypes. Can be the AnnData index, a unique slide id, or one of <code>[\"all\", \"largest\"]</code>.</p> <code>'all'</code> <code>max_epochs</code> <code>int</code> <p>Maximum number of training epochs.</p> <code>20</code> <code>accelerator</code> <code>str</code> <p>Accelerator to use. For instance, <code>'cuda'</code>, <code>'cpu'</code>, or <code>'auto'</code>. See Pytorch Lightning for more details.</p> <code>'cpu'</code> <code>num_workers</code> <code>int | None</code> <p>Number of workers for the dataloader.</p> <code>None</code> <code>lr</code> <code>float</code> <p>Model learning rate.</p> <code>0.0005</code> <code>min_delta</code> <code>float</code> <p>Minimum change in the monitored quantity to qualify as an improvement (early stopping).</p> <code>0.1</code> <code>min_prototypes_ratio</code> <code>float</code> <p>Minimum ratio of prototypes to be used for each slide. Use a low value to get highly slide-specific or condition-specific prototypes.</p> <code>0.3</code> <code>**fit_kwargs</code> <code>int</code> <p>Optional kwargs for the novae.Novae.fit method.</p> <code>{}</code> Source code in <code>novae/model.py</code> <pre><code>def fine_tune(\n    self,\n    adata: AnnData | list[AnnData],\n    *,\n    reference: Literal[\"all\", \"largest\"] | str | int | list[str] | list[int] = \"all\",\n    max_epochs: int = 20,\n    accelerator: str = \"cpu\",\n    num_workers: int | None = None,\n    lr: float = 5e-4,\n    min_delta: float = 0.1,\n    min_prototypes_ratio: float = 0.3,\n    **fit_kwargs: int,\n):\n    \"\"\"Fine tune a pretrained Novae model. This will update the prototypes with the new data, and `fit` for one or a few epochs.\n\n    Args:\n        adata: An `AnnData` object, or a list of `AnnData` objects. Optional if the model was initialized with `adata`.\n        reference: Reference slide to use for the new prototypes. Can be the AnnData index, a unique slide id, or one of `[\"all\", \"largest\"]`.\n        max_epochs: Maximum number of training epochs.\n        accelerator: Accelerator to use. For instance, `'cuda'`, `'cpu'`, or `'auto'`. See Pytorch Lightning for more details.\n        num_workers: Number of workers for the dataloader.\n        lr: Model learning rate.\n        min_delta: Minimum change in the monitored quantity to qualify as an improvement (early stopping).\n        min_prototypes_ratio: Minimum ratio of prototypes to be used for each slide. Use a low value to get highly slide-specific or condition-specific prototypes.\n        **fit_kwargs: Optional kwargs for the [novae.Novae.fit][] method.\n    \"\"\"\n    self.mode.fine_tune()\n    self._parse_hardware_args(accelerator, num_workers, use_device=True)\n\n    assert adata is not None, \"Please provide an AnnData object to fine-tune the model.\"\n\n    self.init_prototypes(adata, reference=reference)\n    self.init_slide_queue(adata, min_prototypes_ratio)\n\n    self.fit(\n        adata=adata,\n        max_epochs=max_epochs,\n        accelerator=accelerator,\n        num_workers=num_workers,\n        lr=lr,\n        min_delta=min_delta,\n        **fit_kwargs,\n    )\n</code></pre>"},{"location":"api/Novae/#novae.Novae.fit","title":"<code>fit(adata=None, max_epochs=20, accelerator='cpu', num_workers=None, lr=0.001, min_delta=0.1, patience=3, callbacks=None, logger=False, **trainer_kwargs)</code>","text":"<p>Train a Novae model. The training will be stopped by early stopping.</p> <p>Warn</p> <p>If you loaded a pretrained model, use novae.Novae.fine_tune instead.</p> <p>Parameters:</p> Name Type Description Default <code>adata</code> <code>AnnData | list[AnnData] | None</code> <p>An <code>AnnData</code> object, or a list of <code>AnnData</code> objects. Optional if the model was initialized with <code>adata</code>.</p> <code>None</code> <code>max_epochs</code> <code>int</code> <p>Maximum number of training epochs.</p> <code>20</code> <code>accelerator</code> <code>str</code> <p>Accelerator to use. For instance, <code>'cuda'</code>, <code>'cpu'</code>, or <code>'auto'</code>. See Pytorch Lightning for more details.</p> <code>'cpu'</code> <code>num_workers</code> <code>int | None</code> <p>Number of workers for the dataloader.</p> <code>None</code> <code>lr</code> <code>float</code> <p>Model learning rate.</p> <code>0.001</code> <code>min_delta</code> <code>float</code> <p>Minimum change in the monitored quantity to qualify as an improvement (early stopping).</p> <code>0.1</code> <code>patience</code> <code>int</code> <p>Number of epochs with no improvement after which training will be stopped (early stopping).</p> <code>3</code> <code>callbacks</code> <code>list[Callback] | None</code> <p>Optional list of Pytorch lightning callbacks.</p> <code>None</code> <code>logger</code> <code>Logger | list[Logger] | bool</code> <p>The pytorch lightning logger.</p> <code>False</code> <code>**trainer_kwargs</code> <code>int</code> <p>Optional kwargs for the Pytorch Lightning <code>Trainer</code> class.</p> <code>{}</code> Source code in <code>novae/model.py</code> <pre><code>def fit(\n    self,\n    adata: AnnData | list[AnnData] | None = None,\n    max_epochs: int = 20,\n    accelerator: str = \"cpu\",\n    num_workers: int | None = None,\n    lr: float = 1e-3,\n    min_delta: float = 0.1,\n    patience: int = 3,\n    callbacks: list[Callback] | None = None,\n    logger: Logger | list[Logger] | bool = False,\n    **trainer_kwargs: int,\n):\n    \"\"\"Train a Novae model. The training will be stopped by early stopping.\n\n    !!! warn\n        If you loaded a pretrained model, use [novae.Novae.fine_tune][] instead.\n\n    Args:\n        adata: An `AnnData` object, or a list of `AnnData` objects. Optional if the model was initialized with `adata`.\n        max_epochs: Maximum number of training epochs.\n        accelerator: Accelerator to use. For instance, `'cuda'`, `'cpu'`, or `'auto'`. See Pytorch Lightning for more details.\n        num_workers: Number of workers for the dataloader.\n        lr: Model learning rate.\n        min_delta: Minimum change in the monitored quantity to qualify as an improvement (early stopping).\n        patience: Number of epochs with no improvement after which training will be stopped (early stopping).\n        callbacks: Optional list of Pytorch lightning callbacks.\n        logger: The pytorch lightning logger.\n        **trainer_kwargs: Optional kwargs for the Pytorch Lightning `Trainer` class.\n    \"\"\"\n    self.mode.fit()\n\n    if adata is not None:\n        self.adatas, _ = utils.prepare_adatas(adata, var_names=self.cell_embedder.gene_names)\n\n    ### Misc\n    self._update_multimodal_mode()\n    self._lr = lr\n    self.swav_head.reset_clustering()  # ensure we don't re-use old clusters\n    self._parse_hardware_args(accelerator, num_workers)\n    self._datamodule = self._init_datamodule()\n\n    utils.train(\n        self,\n        self.datamodule,\n        accelerator,\n        max_epochs=max_epochs,\n        patience=patience,\n        min_delta=min_delta,\n        callbacks=callbacks,\n        logger=logger,\n        **trainer_kwargs,\n    )\n\n    self.mode.trained = True\n</code></pre>"},{"location":"api/Novae/#novae.Novae.from_pretrained","title":"<code>from_pretrained(model_name_or_path, **kwargs)</code>  <code>classmethod</code>","text":"<p>Load a pretrained <code>Novae</code> model from HuggingFace Hub.</p> <p>Available model names</p> <p>See here the available Novae model names.</p> <p>Parameters:</p> Name Type Description Default <code>model_name_or_path</code> <code>str</code> <p>Name of the model, e.g. <code>\"MICS-Lab/novae-1-medium\"</code>, or path to the local model.</p> required <code>**kwargs</code> <code>int</code> <p>Optional kwargs for Hugging Face <code>from_pretrained</code> method.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Novae</code> <p>A pretrained <code>Novae</code> model.</p> Source code in <code>novae/model.py</code> <pre><code>@classmethod\ndef from_pretrained(self, model_name_or_path: str, **kwargs: int) -&gt; \"Novae\":\n    \"\"\"Load a pretrained `Novae` model from HuggingFace Hub.\n\n    !!! info \"Available model names\"\n        See [here](https://huggingface.co/collections/MICS-Lab/novae-669cdf1754729d168a69f6bd) the available Novae model names.\n\n    Args:\n        model_name_or_path: Name of the model, e.g. `\"MICS-Lab/novae-1-medium\"`, or path to the local model.\n        **kwargs: Optional kwargs for Hugging Face [`from_pretrained`](https://huggingface.co/docs/huggingface_hub/v0.24.0/en/package_reference/mixins#huggingface_hub.ModelHubMixin.from_pretrained) method.\n\n    Returns:\n        A pretrained `Novae` model.\n    \"\"\"\n    model = super().from_pretrained(model_name_or_path, **kwargs)\n\n    model.mode.from_pretrained()\n    model._model_name = model_name_or_path\n    model.cell_embedder.embedding.weight.requires_grad_(False)\n\n    return model\n</code></pre>"},{"location":"api/Novae/#novae.Novae.init_slide_queue","title":"<code>init_slide_queue(adata, min_prototypes_ratio)</code>","text":"<p>Initialize the slide-queue for the SwAV head. This can be used before training (<code>fit</code> or <code>fine_tune</code>) when there are potentially slide-specific or condition-specific prototypes.</p> <p>Parameters:</p> Name Type Description Default <code>adata</code> <code>AnnData | list[AnnData] | None</code> <p>An <code>AnnData</code> object, or a list of <code>AnnData</code> objects. Optional if the model was initialized with <code>adata</code>.</p> required <code>min_prototypes_ratio</code> <code>float</code> <p>Minimum ratio of prototypes to be used for each slide. Use a low value to get highly slide-specific or condition-specific prototypes.</p> required Source code in <code>novae/model.py</code> <pre><code>def init_slide_queue(self, adata: AnnData | list[AnnData] | None, min_prototypes_ratio: float) -&gt; None:\n    \"\"\"\n    Initialize the slide-queue for the SwAV head.\n    This can be used before training (`fit` or `fine_tune`) when there are potentially slide-specific or condition-specific prototypes.\n\n    Args:\n        adata: An `AnnData` object, or a list of `AnnData` objects. Optional if the model was initialized with `adata`.\n        min_prototypes_ratio: Minimum ratio of prototypes to be used for each slide. Use a low value to get highly slide-specific or condition-specific prototypes.\n    \"\"\"\n    self.hparams.min_prototypes_ratio = min_prototypes_ratio\n\n    if adata is None or min_prototypes_ratio == 1:\n        return\n\n    slide_ids = list(utils.unique_obs(adata, Keys.SLIDE_ID))\n    if len(slide_ids) &gt; 1:\n        self.swav_head.set_min_prototypes(min_prototypes_ratio)\n        self.swav_head.init_queue(slide_ids)\n</code></pre>"},{"location":"api/Novae/#novae.Novae.plot_domains_hierarchy","title":"<code>plot_domains_hierarchy(max_level=10, hline_level=None, leaf_font_size=8, **kwargs)</code>","text":"<p>Plot the domains hierarchy as a dendogram.</p> <p>Parameters:</p> Name Type Description Default <code>max_level</code> <code>int</code> <p>Maximum level to be plot.</p> <code>10</code> <code>hline_level</code> <code>int | list[int] | None</code> <p>If not <code>None</code>, a red line will ne drawn at this/these level(s).</p> <code>None</code> <code>leaf_font_size</code> <code>int</code> <p>The font size for the leaf labels.</p> <code>8</code> Source code in <code>novae/model.py</code> <pre><code>def plot_domains_hierarchy(\n    self,\n    max_level: int = 10,\n    hline_level: int | list[int] | None = None,\n    leaf_font_size: int = 8,\n    **kwargs,\n):\n    \"\"\"Plot the domains hierarchy as a dendogram.\n\n    Args:\n        max_level: Maximum level to be plot.\n        hline_level: If not `None`, a red line will ne drawn at this/these level(s).\n        leaf_font_size: The font size for the leaf labels.\n    \"\"\"\n    plot._domains_hierarchy(\n        self.swav_head.clustering,\n        max_level=max_level,\n        hline_level=hline_level,\n        leaf_font_size=leaf_font_size,\n        **kwargs,\n    )\n</code></pre>"},{"location":"api/Novae/#novae.Novae.plot_prototype_weights","title":"<code>plot_prototype_weights(assign_zeros=True, **kwargs)</code>","text":"<p>Plot the weights of the prototypes per slide.</p> Source code in <code>novae/model.py</code> <pre><code>def plot_prototype_weights(self, assign_zeros: bool = True, **kwargs: int):\n    \"\"\"Plot the weights of the prototypes per slide.\"\"\"\n\n    assert self.swav_head.queue is not None, (\n        \"Swav queue not initialized. Initialize it with `model.init_slide_queue(...)`, then train or fine-tune the model.\"\n    )\n\n    weights, thresholds = self.swav_head.queue_weights()\n    weights, thresholds = weights.numpy(force=True), thresholds.numpy(force=True)\n\n    if assign_zeros:\n        for i in range(len(weights)):\n            below_threshold_ilocs = np.where(weights[i] &lt; thresholds)[0]\n            if len(thresholds) - len(below_threshold_ilocs) &gt;= self.swav_head.min_prototypes:\n                weights[i, below_threshold_ilocs] = 0\n            else:\n                n_missing = len(thresholds) - self.swav_head.min_prototypes\n                ilocs = below_threshold_ilocs[\n                    np.argpartition(weights[i, below_threshold_ilocs], n_missing)[:n_missing]\n                ]\n                weights[i, ilocs] = 0\n\n    plot._weights_clustermap(weights, self.adatas, list(self.swav_head.slide_label_encoder.keys()), **kwargs)\n</code></pre>"},{"location":"api/Novae/#novae.Novae.save_pretrained","title":"<code>save_pretrained(save_directory, *, repo_id=None, push_to_hub=False, **kwargs)</code>","text":"<p>Save a pretrained <code>Novae</code> model to a directory.</p> <p>Parameters:</p> Name Type Description Default <code>save_directory</code> <code>str</code> <p>Path to the directory where the model will be saved.</p> required <code>**kwargs</code> <code>int</code> <p>Do not use. These are used to push a new model on HuggingFace Hub.</p> <code>{}</code> Source code in <code>novae/model.py</code> <pre><code>def save_pretrained(\n    self,\n    save_directory: str,\n    *,\n    repo_id: str | None = None,\n    push_to_hub: bool = False,\n    **kwargs: int,\n):\n    \"\"\"Save a pretrained `Novae` model to a directory.\n\n    Args:\n        save_directory: Path to the directory where the model will be saved.\n        **kwargs: Do not use. These are used to push a new model on HuggingFace Hub.\n    \"\"\"\n\n    super().save_pretrained(\n        save_directory,\n        config=dict(self.hparams),\n        repo_id=repo_id,\n        push_to_hub=push_to_hub,\n        **kwargs,\n    )\n</code></pre>"},{"location":"api/data/","title":"Data","text":""},{"location":"api/data/#loading-datasets","title":"Loading datasets","text":""},{"location":"api/data/#novae.load_dataset","title":"<code>novae.load_dataset(pattern=None, tissue=None, species=None, technology=None, custom_filter=None, top_k=None, dry_run=False)</code>","text":"<p>Automatically load slides from the Novae dataset repository.</p> <p>Selecting slides</p> <p>The function arguments allow to filter the slides based on the tissue, species, and name pattern. Internally, the function reads this dataset metadata file to select the slides that match the provided filters.</p> <p>Parameters:</p> Name Type Description Default <code>pattern</code> <code>str | None</code> <p>Optional pattern to match the slides names.</p> <code>None</code> <code>tissue</code> <code>list[str] | str | None</code> <p>Optional tissue (or tissue list) to filter the slides. E.g., <code>\"brain\", \"colon\"</code>.</p> <code>None</code> <code>species</code> <code>list[str] | str | None</code> <p>Optional species (or species list) to filter the slides. E.g., <code>\"human\", \"mouse\"</code>.</p> <code>None</code> <code>technology</code> <code>list[str] | str | None</code> <p>Optional technology (or technology list) to filter the slides. E.g., <code>\"xenium\", or \"visium_hd\"</code>.</p> <code>None</code> <code>custom_filter</code> <code>Callable[[DataFrame], Series] | None</code> <p>Custom filter function that takes the metadata DataFrame (see above link) and returns a boolean Series to decide which rows should be kept.</p> <code>None</code> <code>top_k</code> <code>int | None</code> <p>Optional number of slides to keep. If <code>None</code>, keeps all slides.</p> <code>None</code> <code>dry_run</code> <code>bool</code> <p>If <code>True</code>, the function will only return the metadata of slides that match the filters.</p> <code>False</code> <p>Returns:</p> Type Description <code>list[AnnData]</code> <p>A list of <code>AnnData</code> objects, each object corresponds to one slide.</p> Source code in <code>novae/data/_load/_hf.py</code> <pre><code>def load_dataset(\n    pattern: str | None = None,\n    tissue: list[str] | str | None = None,\n    species: list[str] | str | None = None,\n    technology: list[str] | str | None = None,\n    custom_filter: Callable[[pd.DataFrame], pd.Series] | None = None,\n    top_k: int | None = None,\n    dry_run: bool = False,\n) -&gt; list[AnnData]:\n    \"\"\"Automatically load slides from the Novae dataset repository.\n\n    !!! info \"Selecting slides\"\n        The function arguments allow to filter the slides based on the tissue, species, and name pattern.\n        Internally, the function reads [this dataset metadata file](https://huggingface.co/datasets/MICS-Lab/novae/blob/main/metadata.csv) to select the slides that match the provided filters.\n\n    Args:\n        pattern: Optional pattern to match the slides names.\n        tissue: Optional tissue (or tissue list) to filter the slides. E.g., `\"brain\", \"colon\"`.\n        species: Optional species (or species list) to filter the slides. E.g., `\"human\", \"mouse\"`.\n        technology: Optional technology (or technology list) to filter the slides. E.g., `\"xenium\", or \"visium_hd\"`.\n        custom_filter: Custom filter function that takes the metadata DataFrame (see above link) and returns a boolean Series to decide which rows should be kept.\n        top_k: Optional number of slides to keep. If `None`, keeps all slides.\n        dry_run: If `True`, the function will only return the metadata of slides that match the filters.\n\n    Returns:\n        A list of `AnnData` objects, each object corresponds to one slide.\n    \"\"\"\n    metadata = pd.read_csv(\"hf://datasets/MICS-Lab/novae/metadata.csv\", index_col=0)\n\n    FILTER_COLUMN = [(\"species\", species), (\"tissue\", tissue), (\"technology\", technology)]\n    VALID_VALUES = {column: metadata[column].unique() for column, _ in FILTER_COLUMN}\n\n    for column, value in FILTER_COLUMN:\n        if value is not None:\n            values = [value] if isinstance(value, str) else value\n            valid_values = VALID_VALUES[column]\n\n            assert all(value in valid_values for value in values), (\n                f\"Found invalid {column} value in {values}. Valid values are {valid_values}.\"\n            )\n\n            metadata = metadata[metadata[column].isin(values)]\n\n    if custom_filter is not None:\n        metadata = metadata[custom_filter(metadata)]\n\n    assert not metadata.empty, \"No dataset found for the provided filters.\"\n\n    if pattern is not None:\n        where = metadata.index.str.match(pattern)\n        assert len(where), f\"No dataset found for the provided pattern ({', '.join(list(metadata.index))}).\"\n        metadata = metadata[where]\n\n    assert not metadata.empty, \"No dataset found for the provided filters.\"\n\n    if top_k is not None:\n        metadata = metadata.head(top_k)\n\n    if dry_run:\n        return metadata\n\n    log.info(f\"Found {len(metadata)} h5ad file(s) matching the filters.\")\n    return [_read_h5ad_from_hub(name, row) for name, row in metadata.iterrows()]\n</code></pre>"},{"location":"api/data/#novae.toy_dataset","title":"<code>novae.toy_dataset(n_panels=3, n_domains=4, n_slides_per_panel=1, xmax=500, n_vars=100, n_drop=20, step=20, panel_shift_lambda=5, slide_shift_lambda=1.5, domain_shift_lambda=2.0, slide_ids_unique=True, compute_spatial_neighbors=False, merge_last_domain_even_slide=False)</code>","text":"<p>Creates a toy dataset, useful for debugging or testing.</p> <p>Parameters:</p> Name Type Description Default <code>n_panels</code> <code>int</code> <p>Number of panels. Each panel will correspond to one output <code>AnnData</code> object.</p> <code>3</code> <code>n_domains</code> <code>int</code> <p>Number of domains.</p> <code>4</code> <code>n_slides_per_panel</code> <code>int</code> <p>Number of slides per panel.</p> <code>1</code> <code>xmax</code> <code>int</code> <p>Maximum value for the spatial coordinates (the larger, the more cells).</p> <code>500</code> <code>n_vars</code> <code>int</code> <p>Maxmium number of genes per panel.</p> <code>100</code> <code>n_drop</code> <code>int</code> <p>Number of genes that are randomly removed for each <code>AnnData</code> object. It will create non-identical panels.</p> <code>20</code> <code>step</code> <code>int</code> <p>Step between cells in their spatial coordinates.</p> <code>20</code> <code>panel_shift_lambda</code> <code>float</code> <p>Lambda used in the exponential law for each panel.</p> <code>5</code> <code>slide_shift_lambda</code> <code>float</code> <p>Lambda used in the exponential law for each slide.</p> <code>1.5</code> <code>domain_shift_lambda</code> <code>float</code> <p>Lambda used in the exponential law for each domain.</p> <code>2.0</code> <code>slide_ids_unique</code> <code>bool</code> <p>Whether to ensure that slide ids are unique.</p> <code>True</code> <code>compute_spatial_neighbors</code> <code>bool</code> <p>Whether to compute the spatial neighbors graph. We remove some the edges of one node for testing purposes.</p> <code>False</code> <p>Returns:</p> Type Description <code>list[AnnData]</code> <p>A list of <code>AnnData</code> objects representing a valid <code>Novae</code> dataset.</p> Source code in <code>novae/data/_load/_toy.py</code> <pre><code>def toy_dataset(\n    n_panels: int = 3,\n    n_domains: int = 4,\n    n_slides_per_panel: int = 1,\n    xmax: int = 500,\n    n_vars: int = 100,\n    n_drop: int = 20,\n    step: int = 20,\n    panel_shift_lambda: float = 5,\n    slide_shift_lambda: float = 1.5,\n    domain_shift_lambda: float = 2.0,\n    slide_ids_unique: bool = True,\n    compute_spatial_neighbors: bool = False,\n    merge_last_domain_even_slide: bool = False,\n) -&gt; list[AnnData]:\n    \"\"\"Creates a toy dataset, useful for debugging or testing.\n\n    Args:\n        n_panels: Number of panels. Each panel will correspond to one output `AnnData` object.\n        n_domains: Number of domains.\n        n_slides_per_panel: Number of slides per panel.\n        xmax: Maximum value for the spatial coordinates (the larger, the more cells).\n        n_vars: Maxmium number of genes per panel.\n        n_drop: Number of genes that are randomly removed for each `AnnData` object. It will create non-identical panels.\n        step: Step between cells in their spatial coordinates.\n        panel_shift_lambda: Lambda used in the exponential law for each panel.\n        slide_shift_lambda: Lambda used in the exponential law for each slide.\n        domain_shift_lambda: Lambda used in the exponential law for each domain.\n        slide_ids_unique: Whether to ensure that slide ids are unique.\n        compute_spatial_neighbors: Whether to compute the spatial neighbors graph. We remove some the edges of one node for testing purposes.\n\n    Returns:\n        A list of `AnnData` objects representing a valid `Novae` dataset.\n    \"\"\"\n    assert n_vars - n_drop - n_panels &gt; 2\n\n    spatial = np.mgrid[-xmax:xmax:step, -xmax:xmax:step].reshape(2, -1).T\n    spatial = spatial[(spatial**2).sum(1) &lt;= xmax**2]\n    n_obs = len(spatial)\n\n    int_domains = (np.sqrt((spatial**2).sum(1)) // (xmax / n_domains + 1e-8)).astype(int)\n    domain = \"domain_\" + int_domains.astype(str).astype(object)\n    merge_domain = \"domain_\" + int_domains.clip(0, n_domains - 2).astype(str).astype(object)\n\n    adatas = []\n\n    var_names = np.array(\n        GENE_NAMES_SUBSET[:n_vars] if n_vars &lt;= len(GENE_NAMES_SUBSET) else [f\"g{i}\" for i in range(n_vars)]\n    )\n\n    domains_shift = np.random.exponential(domain_shift_lambda, size=(n_domains, n_vars))\n\n    for panel_index in range(n_panels):\n        adatas_panel = []\n        panel_shift = np.random.exponential(panel_shift_lambda, size=n_vars)\n\n        for slide_index in range(n_slides_per_panel):\n            slide_shift = np.random.exponential(slide_shift_lambda, size=n_vars)\n\n            merge = merge_last_domain_even_slide and (slide_index % 2 == 0)\n\n            adata = AnnData(\n                np.zeros((n_obs, n_vars)),\n                obsm={\"spatial\": spatial + panel_index + slide_index},  # ensure the locs are different\n                obs=pd.DataFrame(\n                    {\"domain\": merge_domain if merge else domain}, index=[f\"cell_{i}\" for i in range(spatial.shape[0])]\n                ),\n            )\n\n            adata.var_names = var_names\n            adata.obs_names = [f\"c_{panel_index}_{slide_index}_{i}\" for i in range(adata.n_obs)]\n\n            slide_key = f\"slide_{panel_index}_{slide_index}\" if slide_ids_unique else f\"slide_{slide_index}\"\n            adata.obs[\"slide_key\"] = slide_key\n\n            for i in range(n_domains):\n                condition = adata.obs[\"domain\"] == \"domain_\" + str(i)\n                n_obs_domain = condition.sum()\n\n                lambdas = domains_shift[i] + slide_shift + panel_shift\n                X_domain = np.random.exponential(lambdas, size=(n_obs_domain, n_vars))\n                adata.X[condition] = X_domain.astype(int)  # values should look like counts\n\n            if n_drop:\n                size = n_vars - n_drop - panel_index  # different number of genes\n                var_indices = np.random.choice(n_vars, size=size, replace=False)\n                adata = adata[:, var_indices].copy()\n\n            adatas_panel.append(adata[: -1 - panel_index - slide_index].copy())  # different number of cells\n\n        adata_panel = anndata.concat(adatas_panel)\n\n        if compute_spatial_neighbors:\n            spatial_neighbors(adata_panel, slide_key=\"slide_key\")\n            _drop_neighbors(adata_panel, index=3)  # ensure one node is not connected to any other\n\n        adata_panel.layers[\"counts\"] = adata_panel.X.copy()\n        sc.pp.normalize_total(adata_panel)\n        sc.pp.log1p(adata_panel)\n\n        adatas.append(adata_panel)\n\n    return adatas\n</code></pre>"},{"location":"api/data/#preprocessing","title":"Preprocessing","text":""},{"location":"api/data/#novae.quantile_scaling","title":"<code>novae.quantile_scaling(adata, multiplier=5, quantile=0.2, per_slide=True)</code>","text":"<p>Preprocess fluorescence data from <code>adata.X</code> using quantiles of expression. For each column <code>X</code>, we compute <code>asinh(X / 5*Q(0.2, X))</code>, and store them back.</p> <p>Parameters:</p> Name Type Description Default <code>adata</code> <code>AnnData | list[AnnData]</code> <p>An <code>AnnData</code> object, or a list of <code>AnnData</code> objects.</p> required <code>multiplier</code> <code>float</code> <p>The multiplier for the quantile.</p> <code>5</code> <code>quantile</code> <code>float</code> <p>The quantile to compute.</p> <code>0.2</code> <code>per_slide</code> <code>bool</code> <p>Whether to compute the quantile per slide. If <code>False</code>, the quantile is computed for each <code>AnnData</code> object.</p> <code>True</code> Source code in <code>novae/data/preprocess.py</code> <pre><code>def quantile_scaling(\n    adata: AnnData | list[AnnData],\n    multiplier: float = 5,\n    quantile: float = 0.2,\n    per_slide: bool = True,\n) -&gt; pd.DataFrame:\n    \"\"\"Preprocess fluorescence data from `adata.X` using quantiles of expression.\n    For each column `X`, we compute `asinh(X / 5*Q(0.2, X))`, and store them back.\n\n    Args:\n        adata: An `AnnData` object, or a list of `AnnData` objects.\n        multiplier: The multiplier for the quantile.\n        quantile: The quantile to compute.\n        per_slide: Whether to compute the quantile per slide. If `False`, the quantile is computed for each `AnnData` object.\n    \"\"\"\n    _check_has_slide_id(adata)\n\n    if isinstance(adata, list):\n        for adata_ in adata:\n            quantile_scaling(adata_, multiplier, quantile, per_slide=per_slide)\n        return\n\n    if not per_slide:\n        return _quantile_scaling(adata, multiplier, quantile)\n\n    for adata_ in iter_slides(adata):\n        _quantile_scaling(adata_, multiplier, quantile)\n</code></pre>"},{"location":"api/data/#novae.compute_histo_embeddings","title":"<code>novae.compute_histo_embeddings(sdata, model='conch', table_key='table', patch_overlap_ratio=0.5, image_key=None, device=None, batch_size=32)</code>","text":"<p>Compute histology embeddings for a given model on a grid of overlapping patches.</p> <p>It will add a new <code>AnnData</code> object to the <code>SpatialData</code> object, containing the embeddings of the patches, and add a column in the cells table with the index of the closest patch.</p> <p>Installation</p> <p>This function requires the <code>multimodal</code> extra. You can install it with <code>pip install novae[multimodal]</code>. If you use the CONCH model (default), you also need to install the <code>conch</code> extra with <code>pip install 'novae[multimodal,conch]'</code>.</p> <p>Parameters:</p> Name Type Description Default <code>sdata</code> <code>SpatialData</code> <p>A <code>SpatialData</code> object containing the data.</p> required <code>model</code> <code>str | Callable</code> <p>The model to use for computing embeddings. See the sopa documentation for more details.</p> <code>'conch'</code> <code>table_key</code> <code>str</code> <p>Name of the <code>AnnData</code> object containing the cells.</p> <code>'table'</code> <code>patch_overlap_ratio</code> <code>float</code> <p>Ratio of overlap between patches.</p> <code>0.5</code> <code>image_key</code> <code>str | None</code> <p>Name of the histology image. If None, the function will try to find the image key automatically.</p> <code>None</code> <code>device</code> <code>str | None</code> <p>Torch device to use for computation.</p> <code>None</code> <code>batch_size</code> <code>int</code> <p>Mini-batch size for computation.</p> <code>32</code> Source code in <code>novae/data/_embeddings/_histo.py</code> <pre><code>def compute_histo_embeddings(\n    sdata: \"SpatialData\",\n    model: str | Callable = \"conch\",\n    table_key: str = \"table\",\n    patch_overlap_ratio: float = 0.5,\n    image_key: str | None = None,\n    device: str | None = None,\n    batch_size: int = 32,\n) -&gt; None:\n    \"\"\"Compute histology embeddings for a given model on a grid of overlapping patches.\n\n    It will add a new `AnnData` object to the `SpatialData` object, containing the embeddings of the patches, and\n    add a column in the cells table with the index of the closest patch.\n\n    !!! warning \"Installation\"\n        This function requires the `multimodal` extra. You can install it with `pip install novae[multimodal]`. If you use the CONCH model (default), you also need to install the `conch` extra with `pip install 'novae[multimodal,conch]'`.\n\n    Args:\n        sdata: A `SpatialData` object containing the data.\n        model: The model to use for computing embeddings. See the [sopa documentation](https://gustaveroussy.github.io/sopa/api/patches/#sopa.patches.compute_embeddings) for more details.\n        table_key: Name of the `AnnData` object containing the cells.\n        patch_overlap_ratio: Ratio of overlap between patches.\n        image_key: Name of the histology image. If None, the function will try to find the image key automatically.\n        device: Torch device to use for computation.\n        batch_size: Mini-batch size for computation.\n    \"\"\"\n    try:\n        import sopa\n        from sopa._constants import SopaAttrs, SopaKeys\n        from spatialdata.models import get_table_keys\n    except ImportError:\n        raise ImportError(\n            \"Please install the multimodal extra via `pip install novae[multimodal]`.\\nIf you want to use CONCH, also install the corresponding extra via `pip install 'novae[multimodal,conch]'`.\"\n        )\n\n    assert 0 &lt;= patch_overlap_ratio &lt; 1, \"patch_overlap_ratio must be between 0 and 1\"\n    patch_overlap = int(patch_overlap_ratio * Nums.HE_PATCH_WIDTH)\n\n    adata: AnnData = sdata[table_key]\n\n    if image_key is None:\n        image_key, _ = sopa.utils.get_spatial_element(\n            sdata.images, sdata.attrs.get(SopaAttrs.TISSUE_SEGMENTATION, None), return_key=True\n        )\n\n    # align the cells boundaries to the image coordinate system\n    shapes_key, _, instance_key = get_table_keys(adata)\n\n    if not sdata.shapes[shapes_key].geometry.is_valid.all():\n        log.warning(f\"Found invalid geometries in `sdata['{shapes_key}']`. They will be fixed using `.make_valid()`.\")\n        sdata.shapes[shapes_key].geometry = sdata.shapes[shapes_key].make_valid()\n\n    cells = sopa.utils.to_intrinsic(sdata, shapes_key, image_key)\n    cells = cells.loc[adata.obs[instance_key]]\n\n    key_added = sopa.patches.compute_embeddings(\n        sdata,\n        model,\n        level=0,\n        patch_width=Nums.HE_PATCH_WIDTH,\n        patch_overlap=patch_overlap,\n        image_key=image_key,\n        device=device,\n        batch_size=batch_size,\n        roi_key=shapes_key,\n        use_roi_centroids=True,\n    )\n\n    patches_centroids = sdata[SopaKeys.EMBEDDINGS_PATCHES].centroid\n    indices, distances = patches_centroids.sindex.nearest(cells.centroid, return_all=False, return_distance=True)\n\n    _quality_control_join(distances)\n\n    adata.obs[\"embedding_key\"] = key_added\n    adata.obs[\"embedding_index\"] = indices[1]\n</code></pre>"},{"location":"api/data/#novae.compute_histo_pca","title":"<code>novae.compute_histo_pca(sdatas, n_components=50, table_key='table')</code>","text":"<p>Run PCA on the histology embeddings associated to each cell (from the closest patch). The embedding is stored in <code>adata.obsm[\"histo_embeddings\"]</code>, where <code>adata</code> is the table of cell expression.</p> <p>Info</p> <p>You need to run novae.data.compute_histo_embeddings before running this function.</p> <p>Parameters:</p> Name Type Description Default <code>sdatas</code> <code>Union[SpatialData, list[SpatialData]]</code> <p>One or several <code>SpatialData</code> object(s).</p> required <code>n_components</code> <code>int</code> <p>Number of components for the PCA.</p> <code>50</code> <code>table_key</code> <code>str</code> <p>Name of the <code>AnnData</code> object containing the cells.</p> <code>'table'</code> Source code in <code>novae/data/_embeddings/_histo.py</code> <pre><code>def compute_histo_pca(\n    sdatas: Union[\"SpatialData\", list[\"SpatialData\"]], n_components: int = 50, table_key: str = \"table\"\n) -&gt; None:\n    \"\"\"Run PCA on the histology embeddings associated to each cell (from the closest patch).\n    The embedding is stored in `adata.obsm[\"histo_embeddings\"]`, where `adata` is the table of cell expression.\n\n    !!! info\n        You need to run [novae.data.compute_histo_embeddings][] before running this function.\n\n    Args:\n        sdatas: One or several `SpatialData` object(s).\n        n_components: Number of components for the PCA.\n        table_key: Name of the `AnnData` object containing the cells.\n    \"\"\"\n    from spatialdata import SpatialData\n\n    if isinstance(sdatas, SpatialData):\n        sdatas = [sdatas]\n\n    def _histo_emb(sdata: \"SpatialData\") -&gt; np.ndarray:\n        _table: AnnData = sdata.tables[table_key]\n\n        assert \"embedding_key\" in _table.obs, (\n            \"Could not find `embedding_key` in adata.obs. Did you run `novae.data.compute_histo_embeddings` first?\"\n        )\n        embedding_key = _table.obs[\"embedding_key\"].iloc[0]\n        return sdata.tables[embedding_key].X\n\n    X = np.concatenate([_histo_emb(sdata) for sdata in sdatas], axis=0)\n\n    pca = PCA(n_components=n_components)\n    pipeline = Pipeline([(\"pca\", pca), (\"scaler\", StandardScaler())])\n\n    pipeline.fit(X)\n\n    for sdata in sdatas:\n        adata: AnnData = sdata[table_key]\n        adata.obsm[Keys.HISTO_EMBEDDINGS] = pipeline.transform(_histo_emb(sdata)[adata.obs[\"embedding_index\"]])\n</code></pre>"},{"location":"api/dataloader/","title":"Dataloader","text":""},{"location":"api/dataloader/#novae.data.AnnDataTorch","title":"<code>novae.data.AnnDataTorch</code>","text":"Source code in <code>novae/data/convert.py</code> <pre><code>class AnnDataTorch:\n    tensors: list[Tensor] | None\n    genes_indices_list: list[Tensor]\n\n    def __init__(self, adatas: list[AnnData], cell_embedder: CellEmbedder):\n        \"\"\"Converting AnnData objects to PyTorch tensors.\n\n        Args:\n            adatas: A list of `AnnData` objects.\n            cell_embedder: A [novae.module.CellEmbedder][] object.\n        \"\"\"\n        super().__init__()\n        self.adatas = adatas\n        self.cell_embedder = cell_embedder\n\n        self.genes_indices_list = [self._adata_to_genes_indices(adata) for adata in self.adatas]\n        self.tensors = None\n\n        self.means, self.stds, self.label_encoder = self._compute_means_stds()\n\n        # Tensors are loaded in memory for low numbers of cells\n        if sum(adata.n_obs for adata in self.adatas) &lt; Nums.N_OBS_THRESHOLD:\n            self.tensors = [self.to_tensor(adata) for adata in self.adatas]\n\n    def _adata_to_genes_indices(self, adata: AnnData) -&gt; Tensor:\n        return self.cell_embedder.genes_to_indices(adata.var_names[self._keep_var(adata)])[None, :]\n\n    def _keep_var(self, adata: AnnData) -&gt; AnnData:\n        return adata.var[Keys.USE_GENE]\n\n    def _compute_means_stds(self) -&gt; tuple[Tensor, Tensor, LabelEncoder]:\n        means, stds = {}, {}\n\n        for adata in self.adatas:\n            slide_ids = adata.obs[Keys.SLIDE_ID]\n            for slide_id in slide_ids.cat.categories:\n                adata_slide = adata[adata.obs[Keys.SLIDE_ID] == slide_id, self._keep_var(adata)]\n\n                mean = adata_slide.X.mean(0)\n                mean = mean.A1 if isinstance(mean, np.matrix) else mean\n                means[slide_id] = mean.astype(np.float32)\n\n                std = (\n                    adata_slide.X.std(0) if isinstance(adata_slide.X, np.ndarray) else _sparse_std(adata_slide.X, 0).A1\n                )\n                stds[slide_id] = std.astype(np.float32)\n\n        label_encoder = LabelEncoder()\n        label_encoder.fit(list(means.keys()))\n\n        means = [torch.tensor(means[slide_id]) for slide_id in label_encoder.classes_]\n        stds = [torch.tensor(stds[slide_id]) for slide_id in label_encoder.classes_]\n\n        return means, stds, label_encoder\n\n    def to_tensor(self, adata: AnnData) -&gt; Tensor:\n        \"\"\"Get the normalized gene expressions of the cells in the dataset.\n        Only the genes of interest are kept (known genes and highly variable).\n\n        Args:\n            adata: An `AnnData` object.\n\n        Returns:\n            A `Tensor` containing the normalized gene expresions.\n        \"\"\"\n        adata = adata[:, self._keep_var(adata)]\n\n        if len(np.unique(adata.obs[Keys.SLIDE_ID])) == 1:\n            slide_id_index = self.label_encoder.transform([adata.obs.iloc[0][Keys.SLIDE_ID]])[0]\n            mean, std = self.means[slide_id_index], self.stds[slide_id_index]\n        else:\n            slide_id_indices = self.label_encoder.transform(adata.obs[Keys.SLIDE_ID])\n            mean = torch.stack([self.means[i] for i in slide_id_indices])  # TODO: avoid stack (only if not fast enough)\n            std = torch.stack([self.stds[i] for i in slide_id_indices])\n\n        X = adata.X if isinstance(adata.X, np.ndarray) else adata.X.toarray()\n        X = torch.tensor(X, dtype=torch.float32)\n        X = (X - mean) / (std + Nums.EPS)\n\n        return X\n\n    def __getitem__(self, item: tuple[int, slice]) -&gt; tuple[Tensor, Tensor]:\n        \"\"\"Get the expression values for a subset of cells (corresponding to a subgraph).\n\n        Args:\n            item: A `tuple` containing the index of the `AnnData` object and the indices of the cells in the neighborhoods.\n\n        Returns:\n            A `Tensor` of normalized gene expressions and a `Tensor` of gene indices.\n        \"\"\"\n        adata_index, obs_indices = item\n\n        if self.tensors is not None:\n            return self.tensors[adata_index][obs_indices], self.genes_indices_list[adata_index]\n\n        adata = self.adatas[adata_index]\n        adata_view = adata[obs_indices]\n\n        return self.to_tensor(adata_view), self.genes_indices_list[adata_index]\n</code></pre>"},{"location":"api/dataloader/#novae.data.AnnDataTorch.__getitem__","title":"<code>__getitem__(item)</code>","text":"<p>Get the expression values for a subset of cells (corresponding to a subgraph).</p> <p>Parameters:</p> Name Type Description Default <code>item</code> <code>tuple[int, slice]</code> <p>A <code>tuple</code> containing the index of the <code>AnnData</code> object and the indices of the cells in the neighborhoods.</p> required <p>Returns:</p> Type Description <code>tuple[Tensor, Tensor]</code> <p>A <code>Tensor</code> of normalized gene expressions and a <code>Tensor</code> of gene indices.</p> Source code in <code>novae/data/convert.py</code> <pre><code>def __getitem__(self, item: tuple[int, slice]) -&gt; tuple[Tensor, Tensor]:\n    \"\"\"Get the expression values for a subset of cells (corresponding to a subgraph).\n\n    Args:\n        item: A `tuple` containing the index of the `AnnData` object and the indices of the cells in the neighborhoods.\n\n    Returns:\n        A `Tensor` of normalized gene expressions and a `Tensor` of gene indices.\n    \"\"\"\n    adata_index, obs_indices = item\n\n    if self.tensors is not None:\n        return self.tensors[adata_index][obs_indices], self.genes_indices_list[adata_index]\n\n    adata = self.adatas[adata_index]\n    adata_view = adata[obs_indices]\n\n    return self.to_tensor(adata_view), self.genes_indices_list[adata_index]\n</code></pre>"},{"location":"api/dataloader/#novae.data.AnnDataTorch.__init__","title":"<code>__init__(adatas, cell_embedder)</code>","text":"<p>Converting AnnData objects to PyTorch tensors.</p> <p>Parameters:</p> Name Type Description Default <code>adatas</code> <code>list[AnnData]</code> <p>A list of <code>AnnData</code> objects.</p> required <code>cell_embedder</code> <code>CellEmbedder</code> <p>A novae.module.CellEmbedder object.</p> required Source code in <code>novae/data/convert.py</code> <pre><code>def __init__(self, adatas: list[AnnData], cell_embedder: CellEmbedder):\n    \"\"\"Converting AnnData objects to PyTorch tensors.\n\n    Args:\n        adatas: A list of `AnnData` objects.\n        cell_embedder: A [novae.module.CellEmbedder][] object.\n    \"\"\"\n    super().__init__()\n    self.adatas = adatas\n    self.cell_embedder = cell_embedder\n\n    self.genes_indices_list = [self._adata_to_genes_indices(adata) for adata in self.adatas]\n    self.tensors = None\n\n    self.means, self.stds, self.label_encoder = self._compute_means_stds()\n\n    # Tensors are loaded in memory for low numbers of cells\n    if sum(adata.n_obs for adata in self.adatas) &lt; Nums.N_OBS_THRESHOLD:\n        self.tensors = [self.to_tensor(adata) for adata in self.adatas]\n</code></pre>"},{"location":"api/dataloader/#novae.data.AnnDataTorch.to_tensor","title":"<code>to_tensor(adata)</code>","text":"<p>Get the normalized gene expressions of the cells in the dataset. Only the genes of interest are kept (known genes and highly variable).</p> <p>Parameters:</p> Name Type Description Default <code>adata</code> <code>AnnData</code> <p>An <code>AnnData</code> object.</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>A <code>Tensor</code> containing the normalized gene expresions.</p> Source code in <code>novae/data/convert.py</code> <pre><code>def to_tensor(self, adata: AnnData) -&gt; Tensor:\n    \"\"\"Get the normalized gene expressions of the cells in the dataset.\n    Only the genes of interest are kept (known genes and highly variable).\n\n    Args:\n        adata: An `AnnData` object.\n\n    Returns:\n        A `Tensor` containing the normalized gene expresions.\n    \"\"\"\n    adata = adata[:, self._keep_var(adata)]\n\n    if len(np.unique(adata.obs[Keys.SLIDE_ID])) == 1:\n        slide_id_index = self.label_encoder.transform([adata.obs.iloc[0][Keys.SLIDE_ID]])[0]\n        mean, std = self.means[slide_id_index], self.stds[slide_id_index]\n    else:\n        slide_id_indices = self.label_encoder.transform(adata.obs[Keys.SLIDE_ID])\n        mean = torch.stack([self.means[i] for i in slide_id_indices])  # TODO: avoid stack (only if not fast enough)\n        std = torch.stack([self.stds[i] for i in slide_id_indices])\n\n    X = adata.X if isinstance(adata.X, np.ndarray) else adata.X.toarray()\n    X = torch.tensor(X, dtype=torch.float32)\n    X = (X - mean) / (std + Nums.EPS)\n\n    return X\n</code></pre>"},{"location":"api/dataloader/#novae.data.NovaeDataset","title":"<code>novae.data.NovaeDataset</code>","text":"<p>               Bases: <code>Dataset</code></p> <p>Dataset used for training and inference.</p> <p>It extracts the the neighborhood of a cell, and convert it to PyTorch Geometric Data.</p> <p>Attributes:</p> Name Type Description <code>valid_indices</code> <code>list[ndarray]</code> <p>List containing, for each <code>adata</code>, an array that denotes the indices of the cells whose neighborhood is valid.</p> <code>obs_ilocs</code> <code>ndarray</code> <p>An array of shape <code>(total_valid_indices, 2)</code>. The first column corresponds to the adata index, and the second column is the cell index for the corresponding adata.</p> <code>shuffled_obs_ilocs</code> <code>ndarray</code> <p>same as obs_ilocs, but shuffled. Each batch will contain cells from the same slide.</p> Source code in <code>novae/data/dataset.py</code> <pre><code>class NovaeDataset(Dataset):\n    \"\"\"\n    Dataset used for training and inference.\n\n    It extracts the the neighborhood of a cell, and convert it to PyTorch Geometric Data.\n\n    Attributes:\n        valid_indices (list[np.ndarray]): List containing, for each `adata`, an array that denotes the indices of the cells whose neighborhood is valid.\n        obs_ilocs (np.ndarray): An array of shape `(total_valid_indices, 2)`. The first column corresponds to the adata index, and the second column is the cell index for the corresponding adata.\n        shuffled_obs_ilocs (np.ndarray): same as obs_ilocs, but shuffled. Each batch will contain cells from the same slide.\n    \"\"\"\n\n    valid_indices: list[np.ndarray]\n    obs_ilocs: np.ndarray\n    shuffled_obs_ilocs: np.ndarray\n\n    def __init__(\n        self,\n        adatas: list[AnnData],\n        cell_embedder: CellEmbedder,\n        batch_size: int,\n        n_hops_local: int,\n        n_hops_view: int,\n        sample_cells: int | None = None,\n    ) -&gt; None:\n        \"\"\"NovaeDataset constructor.\n\n        Args:\n            adatas: A list of `AnnData` objects.\n            cell_embedder: A [novae.module.CellEmbedder][] object.\n            batch_size: The model batch size.\n            n_hops_local: Number of hops between a cell and its neighborhood cells.\n            n_hops_view: Number of hops between a cell and the origin of a second graph (or 'view').\n            sample_cells: If not None, the dataset if used to sample the subgraphs from precisely `sample_cells` cells.\n        \"\"\"\n        super().__init__()\n        self.adatas = adatas\n        self.cell_embedder = cell_embedder\n        self.anndata_torch = AnnDataTorch(self.adatas, self.cell_embedder)\n\n        self.training = False\n\n        self.batch_size = batch_size\n        self.n_hops_local = n_hops_local\n        self.n_hops_view = n_hops_view\n        self.sample_cells = sample_cells\n\n        self.single_adata = len(self.adatas) == 1\n        self.single_slide_mode = self.single_adata and len(np.unique(self.adatas[0].obs[Keys.SLIDE_ID])) == 1\n\n        self._init_dataset()\n\n    def __repr__(self) -&gt; str:\n        multi_slide_mode, multi_adata = not self.single_slide_mode, not self.single_adata\n        n_samples = sum(len(indices) for indices in self.valid_indices)\n        return f\"{self.__class__.__name__} with {n_samples} samples ({multi_slide_mode=}, {multi_adata=})\"\n\n    def _init_dataset(self):\n        for adata in self.adatas:\n            adjacency: csr_matrix = adata.obsp[Keys.ADJ]\n\n            if Keys.NOVAE_UNS not in adata.uns:\n                adata.uns[Keys.NOVAE_UNS] = {}\n\n            if Keys.ADJ_LOCAL not in adata.obsp or adata.uns[Keys.NOVAE_UNS].get(\"n_hops_local\") != self.n_hops_local:\n                adata.obsp[Keys.ADJ_LOCAL] = _to_adjacency_local(adjacency, self.n_hops_local)\n                adata.uns[Keys.NOVAE_UNS][\"n_hops_local\"] = self.n_hops_local\n\n            if Keys.ADJ_VIEW not in adata.obsp or adata.uns[Keys.NOVAE_UNS].get(\"n_hops_view\") != self.n_hops_view:\n                adata.obsp[Keys.ADJ_VIEW] = _to_adjacency_view(adjacency, self.n_hops_view)\n                adata.uns[Keys.NOVAE_UNS][\"n_hops_view\"] = self.n_hops_view\n\n            adata.obs[Keys.IS_VALID_OBS] = adata.obsp[Keys.ADJ_VIEW].sum(1).A1 &gt; 0\n\n        ratio_valid_obs = pd.concat([adata.obs[Keys.IS_VALID_OBS] for adata in self.adatas]).mean()\n        if ratio_valid_obs &lt; Nums.RATIO_VALID_CELLS_TH:\n            log.warning(\n                f\"Only {ratio_valid_obs:.2%} of the cells have a valid neighborhood.\\n\"\n                \"Consider running `novae.spatial_neighbors` with a larger `radius`.\"\n            )\n\n        self.valid_indices = [utils.valid_indices(adata) for adata in self.adatas]\n\n        self.obs_ilocs = None\n        if self.single_adata:\n            self.obs_ilocs = np.array([(0, obs_index) for obs_index in self.valid_indices[0]])\n\n        self.slides_metadata: pd.DataFrame = pd.concat(\n            [\n                self._adata_slides_metadata(adata_index, obs_indices)\n                for adata_index, obs_indices in enumerate(self.valid_indices)\n            ],\n            axis=0,\n        )\n\n        self.shuffle_obs_ilocs()\n\n    def __len__(self) -&gt; int:\n        if self.sample_cells is not None:\n            return min(self.sample_cells, len(self.shuffled_obs_ilocs))\n\n        if self.training:\n            n_obs = len(self.shuffled_obs_ilocs)\n            return min(n_obs, max(Nums.MIN_DATASET_LENGTH, int(n_obs * Nums.MAX_DATASET_LENGTH_RATIO)))\n\n        assert self.single_adata, \"Multi-adata mode not supported for inference\"\n\n        return len(self.obs_ilocs)\n\n    def __getitem__(self, index: int) -&gt; dict[str, Data]:\n        \"\"\"Gets a sample from the dataset, with one \"main\" graph and its corresponding \"view\" graph (only during training).\n\n        Args:\n            index: Index of the sample to retrieve.\n\n        Returns:\n            A dictionnary whose keys are names, and values are PyTorch Geometric `Data` objects. The `\"view\"` graph is only provided during training.\n        \"\"\"\n        if self.training or self.sample_cells is not None:\n            adata_index, obs_index = self.shuffled_obs_ilocs[index]\n        else:\n            adata_index, obs_index = self.obs_ilocs[index]\n\n        data = self.to_pyg_data(adata_index, obs_index)\n\n        if not self.training:\n            return {\"main\": data}\n\n        adjacency_pair: csr_matrix = self.adatas[adata_index].obsp[Keys.ADJ_VIEW]\n        cell_view_index = np.random.choice(list(adjacency_pair[obs_index].indices), size=1)[0]\n\n        return {\"main\": data, \"view\": self.to_pyg_data(adata_index, cell_view_index)}\n\n    def to_pyg_data(self, adata_index: int, obs_index: int) -&gt; Data:\n        \"\"\"Create a PyTorch Geometric Data object for the input cell\n\n        Args:\n            adata_index: The index of the `AnnData` object\n            obs_index: The index of the input cell for the corresponding `AnnData` object\n\n        Returns:\n            A Data object\n        \"\"\"\n        adata = self.adatas[adata_index]\n        adjacency_local: csr_matrix = adata.obsp[Keys.ADJ_LOCAL]\n        obs_indices = adjacency_local[obs_index].indices\n\n        adjacency: csr_matrix = adata.obsp[Keys.ADJ]\n        edge_index, edge_weight = from_scipy_sparse_matrix(adjacency[obs_indices][:, obs_indices])\n        edge_attr = edge_weight[:, None].to(torch.float32) / Nums.CELLS_CHARACTERISTIC_DISTANCE\n\n        histo_embeddings = None\n        if Keys.HISTO_EMBEDDINGS in adata.obsm and not settings.disable_multimodal:\n            histo_embeddings = adata.obsm[Keys.HISTO_EMBEDDINGS][[obs_index]]\n            histo_embeddings = torch.tensor(histo_embeddings, dtype=torch.float32)\n\n        x, genes_indices = self.anndata_torch[adata_index, obs_indices]\n\n        return Data(\n            x=x,\n            edge_index=edge_index,\n            edge_attr=edge_attr,\n            genes_indices=genes_indices,\n            slide_id=adata.obs[Keys.SLIDE_ID].iloc[obs_index],\n            histo_embeddings=histo_embeddings,\n        )\n\n    def shuffle_obs_ilocs(self):\n        \"\"\"Shuffle the indices of the cells to be used in the dataset (for training only).\"\"\"\n        if self.single_slide_mode:\n            self.shuffled_obs_ilocs = self.obs_ilocs[np.random.permutation(len(self.obs_ilocs))]\n            return\n\n        adata_indices = np.empty((0, self.batch_size), dtype=int)\n        batched_obs_indices = np.empty((0, self.batch_size), dtype=int)\n\n        for uid in self.slides_metadata.index:\n            adata_index = self.slides_metadata.loc[uid, Keys.ADATA_INDEX]\n            adata = self.adatas[adata_index]\n            _obs_indices = np.where((adata.obs[Keys.SLIDE_ID] == uid) &amp; adata.obs[Keys.IS_VALID_OBS])[0]\n            _obs_indices = np.random.permutation(_obs_indices)\n\n            n_elements = self.slides_metadata.loc[uid, Keys.N_BATCHES] * self.batch_size\n            if len(_obs_indices) &gt;= n_elements:\n                _obs_indices = _obs_indices[:n_elements]\n            else:\n                _obs_indices = np.random.choice(_obs_indices, size=n_elements)\n\n            _obs_indices = _obs_indices.reshape((-1, self.batch_size))\n\n            adata_indices = np.concatenate([adata_indices, np.full_like(_obs_indices, adata_index)], axis=0)\n            batched_obs_indices = np.concatenate([batched_obs_indices, _obs_indices], axis=0)\n\n        permutation = np.random.permutation(len(batched_obs_indices))\n        adata_indices = adata_indices[permutation].flatten()\n        obs_indices = batched_obs_indices[permutation].flatten()\n\n        self.shuffled_obs_ilocs = np.stack([adata_indices, obs_indices], axis=1)\n\n    def _adata_slides_metadata(self, adata_index: int, obs_indices: list[int]) -&gt; pd.DataFrame:\n        obs_counts: pd.Series = self.adatas[adata_index].obs.iloc[obs_indices][Keys.SLIDE_ID].value_counts()\n        slides_metadata = obs_counts.to_frame()\n        slides_metadata[Keys.ADATA_INDEX] = adata_index\n        slides_metadata[Keys.N_BATCHES] = (slides_metadata[\"count\"] // self.batch_size).clip(1)\n        return slides_metadata\n</code></pre>"},{"location":"api/dataloader/#novae.data.NovaeDataset.__getitem__","title":"<code>__getitem__(index)</code>","text":"<p>Gets a sample from the dataset, with one \"main\" graph and its corresponding \"view\" graph (only during training).</p> <p>Parameters:</p> Name Type Description Default <code>index</code> <code>int</code> <p>Index of the sample to retrieve.</p> required <p>Returns:</p> Type Description <code>dict[str, Data]</code> <p>A dictionnary whose keys are names, and values are PyTorch Geometric <code>Data</code> objects. The <code>\"view\"</code> graph is only provided during training.</p> Source code in <code>novae/data/dataset.py</code> <pre><code>def __getitem__(self, index: int) -&gt; dict[str, Data]:\n    \"\"\"Gets a sample from the dataset, with one \"main\" graph and its corresponding \"view\" graph (only during training).\n\n    Args:\n        index: Index of the sample to retrieve.\n\n    Returns:\n        A dictionnary whose keys are names, and values are PyTorch Geometric `Data` objects. The `\"view\"` graph is only provided during training.\n    \"\"\"\n    if self.training or self.sample_cells is not None:\n        adata_index, obs_index = self.shuffled_obs_ilocs[index]\n    else:\n        adata_index, obs_index = self.obs_ilocs[index]\n\n    data = self.to_pyg_data(adata_index, obs_index)\n\n    if not self.training:\n        return {\"main\": data}\n\n    adjacency_pair: csr_matrix = self.adatas[adata_index].obsp[Keys.ADJ_VIEW]\n    cell_view_index = np.random.choice(list(adjacency_pair[obs_index].indices), size=1)[0]\n\n    return {\"main\": data, \"view\": self.to_pyg_data(adata_index, cell_view_index)}\n</code></pre>"},{"location":"api/dataloader/#novae.data.NovaeDataset.__init__","title":"<code>__init__(adatas, cell_embedder, batch_size, n_hops_local, n_hops_view, sample_cells=None)</code>","text":"<p>NovaeDataset constructor.</p> <p>Parameters:</p> Name Type Description Default <code>adatas</code> <code>list[AnnData]</code> <p>A list of <code>AnnData</code> objects.</p> required <code>cell_embedder</code> <code>CellEmbedder</code> <p>A novae.module.CellEmbedder object.</p> required <code>batch_size</code> <code>int</code> <p>The model batch size.</p> required <code>n_hops_local</code> <code>int</code> <p>Number of hops between a cell and its neighborhood cells.</p> required <code>n_hops_view</code> <code>int</code> <p>Number of hops between a cell and the origin of a second graph (or 'view').</p> required <code>sample_cells</code> <code>int | None</code> <p>If not None, the dataset if used to sample the subgraphs from precisely <code>sample_cells</code> cells.</p> <code>None</code> Source code in <code>novae/data/dataset.py</code> <pre><code>def __init__(\n    self,\n    adatas: list[AnnData],\n    cell_embedder: CellEmbedder,\n    batch_size: int,\n    n_hops_local: int,\n    n_hops_view: int,\n    sample_cells: int | None = None,\n) -&gt; None:\n    \"\"\"NovaeDataset constructor.\n\n    Args:\n        adatas: A list of `AnnData` objects.\n        cell_embedder: A [novae.module.CellEmbedder][] object.\n        batch_size: The model batch size.\n        n_hops_local: Number of hops between a cell and its neighborhood cells.\n        n_hops_view: Number of hops between a cell and the origin of a second graph (or 'view').\n        sample_cells: If not None, the dataset if used to sample the subgraphs from precisely `sample_cells` cells.\n    \"\"\"\n    super().__init__()\n    self.adatas = adatas\n    self.cell_embedder = cell_embedder\n    self.anndata_torch = AnnDataTorch(self.adatas, self.cell_embedder)\n\n    self.training = False\n\n    self.batch_size = batch_size\n    self.n_hops_local = n_hops_local\n    self.n_hops_view = n_hops_view\n    self.sample_cells = sample_cells\n\n    self.single_adata = len(self.adatas) == 1\n    self.single_slide_mode = self.single_adata and len(np.unique(self.adatas[0].obs[Keys.SLIDE_ID])) == 1\n\n    self._init_dataset()\n</code></pre>"},{"location":"api/dataloader/#novae.data.NovaeDataset.shuffle_obs_ilocs","title":"<code>shuffle_obs_ilocs()</code>","text":"<p>Shuffle the indices of the cells to be used in the dataset (for training only).</p> Source code in <code>novae/data/dataset.py</code> <pre><code>def shuffle_obs_ilocs(self):\n    \"\"\"Shuffle the indices of the cells to be used in the dataset (for training only).\"\"\"\n    if self.single_slide_mode:\n        self.shuffled_obs_ilocs = self.obs_ilocs[np.random.permutation(len(self.obs_ilocs))]\n        return\n\n    adata_indices = np.empty((0, self.batch_size), dtype=int)\n    batched_obs_indices = np.empty((0, self.batch_size), dtype=int)\n\n    for uid in self.slides_metadata.index:\n        adata_index = self.slides_metadata.loc[uid, Keys.ADATA_INDEX]\n        adata = self.adatas[adata_index]\n        _obs_indices = np.where((adata.obs[Keys.SLIDE_ID] == uid) &amp; adata.obs[Keys.IS_VALID_OBS])[0]\n        _obs_indices = np.random.permutation(_obs_indices)\n\n        n_elements = self.slides_metadata.loc[uid, Keys.N_BATCHES] * self.batch_size\n        if len(_obs_indices) &gt;= n_elements:\n            _obs_indices = _obs_indices[:n_elements]\n        else:\n            _obs_indices = np.random.choice(_obs_indices, size=n_elements)\n\n        _obs_indices = _obs_indices.reshape((-1, self.batch_size))\n\n        adata_indices = np.concatenate([adata_indices, np.full_like(_obs_indices, adata_index)], axis=0)\n        batched_obs_indices = np.concatenate([batched_obs_indices, _obs_indices], axis=0)\n\n    permutation = np.random.permutation(len(batched_obs_indices))\n    adata_indices = adata_indices[permutation].flatten()\n    obs_indices = batched_obs_indices[permutation].flatten()\n\n    self.shuffled_obs_ilocs = np.stack([adata_indices, obs_indices], axis=1)\n</code></pre>"},{"location":"api/dataloader/#novae.data.NovaeDataset.to_pyg_data","title":"<code>to_pyg_data(adata_index, obs_index)</code>","text":"<p>Create a PyTorch Geometric Data object for the input cell</p> <p>Parameters:</p> Name Type Description Default <code>adata_index</code> <code>int</code> <p>The index of the <code>AnnData</code> object</p> required <code>obs_index</code> <code>int</code> <p>The index of the input cell for the corresponding <code>AnnData</code> object</p> required <p>Returns:</p> Type Description <code>Data</code> <p>A Data object</p> Source code in <code>novae/data/dataset.py</code> <pre><code>def to_pyg_data(self, adata_index: int, obs_index: int) -&gt; Data:\n    \"\"\"Create a PyTorch Geometric Data object for the input cell\n\n    Args:\n        adata_index: The index of the `AnnData` object\n        obs_index: The index of the input cell for the corresponding `AnnData` object\n\n    Returns:\n        A Data object\n    \"\"\"\n    adata = self.adatas[adata_index]\n    adjacency_local: csr_matrix = adata.obsp[Keys.ADJ_LOCAL]\n    obs_indices = adjacency_local[obs_index].indices\n\n    adjacency: csr_matrix = adata.obsp[Keys.ADJ]\n    edge_index, edge_weight = from_scipy_sparse_matrix(adjacency[obs_indices][:, obs_indices])\n    edge_attr = edge_weight[:, None].to(torch.float32) / Nums.CELLS_CHARACTERISTIC_DISTANCE\n\n    histo_embeddings = None\n    if Keys.HISTO_EMBEDDINGS in adata.obsm and not settings.disable_multimodal:\n        histo_embeddings = adata.obsm[Keys.HISTO_EMBEDDINGS][[obs_index]]\n        histo_embeddings = torch.tensor(histo_embeddings, dtype=torch.float32)\n\n    x, genes_indices = self.anndata_torch[adata_index, obs_indices]\n\n    return Data(\n        x=x,\n        edge_index=edge_index,\n        edge_attr=edge_attr,\n        genes_indices=genes_indices,\n        slide_id=adata.obs[Keys.SLIDE_ID].iloc[obs_index],\n        histo_embeddings=histo_embeddings,\n    )\n</code></pre>"},{"location":"api/dataloader/#novae.data.NovaeDatamodule","title":"<code>novae.data.NovaeDatamodule</code>","text":"<p>               Bases: <code>LightningDataModule</code></p> <p>Datamodule used for training and inference. Small wrapper around the novae.data.NovaeDataset</p> Source code in <code>novae/data/datamodule.py</code> <pre><code>class NovaeDatamodule(L.LightningDataModule):\n    \"\"\"\n    Datamodule used for training and inference. Small wrapper around the [novae.data.NovaeDataset][]\n    \"\"\"\n\n    def __init__(\n        self,\n        adatas: list[AnnData],\n        cell_embedder: CellEmbedder,\n        batch_size: int,\n        n_hops_local: int,\n        n_hops_view: int,\n        num_workers: int = 0,\n        sample_cells: int | None = None,\n    ) -&gt; None:\n        super().__init__()\n        self.dataset = NovaeDataset(\n            adatas,\n            cell_embedder=cell_embedder,\n            batch_size=batch_size,\n            n_hops_local=n_hops_local,\n            n_hops_view=n_hops_view,\n            sample_cells=sample_cells,\n        )\n        self.batch_size = batch_size\n        self.num_workers = num_workers\n\n    def train_dataloader(self) -&gt; DataLoader:\n        \"\"\"Get a Pytorch dataloader for prediction.\n\n        Returns:\n            The training dataloader.\n        \"\"\"\n        self.dataset.training = True\n        return DataLoader(\n            self.dataset,\n            batch_size=self.batch_size,\n            shuffle=False,\n            drop_last=True,\n            num_workers=self.num_workers,\n        )\n\n    def predict_dataloader(self) -&gt; DataLoader:\n        \"\"\"Get a Pytorch dataloader for prediction or inference.\n\n        Returns:\n            The prediction dataloader.\n        \"\"\"\n        self.dataset.training = False\n        return DataLoader(\n            self.dataset,\n            batch_size=self.batch_size,\n            shuffle=False,\n            drop_last=False,\n            num_workers=self.num_workers,\n        )\n</code></pre>"},{"location":"api/dataloader/#novae.data.NovaeDatamodule.predict_dataloader","title":"<code>predict_dataloader()</code>","text":"<p>Get a Pytorch dataloader for prediction or inference.</p> <p>Returns:</p> Type Description <code>DataLoader</code> <p>The prediction dataloader.</p> Source code in <code>novae/data/datamodule.py</code> <pre><code>def predict_dataloader(self) -&gt; DataLoader:\n    \"\"\"Get a Pytorch dataloader for prediction or inference.\n\n    Returns:\n        The prediction dataloader.\n    \"\"\"\n    self.dataset.training = False\n    return DataLoader(\n        self.dataset,\n        batch_size=self.batch_size,\n        shuffle=False,\n        drop_last=False,\n        num_workers=self.num_workers,\n    )\n</code></pre>"},{"location":"api/dataloader/#novae.data.NovaeDatamodule.train_dataloader","title":"<code>train_dataloader()</code>","text":"<p>Get a Pytorch dataloader for prediction.</p> <p>Returns:</p> Type Description <code>DataLoader</code> <p>The training dataloader.</p> Source code in <code>novae/data/datamodule.py</code> <pre><code>def train_dataloader(self) -&gt; DataLoader:\n    \"\"\"Get a Pytorch dataloader for prediction.\n\n    Returns:\n        The training dataloader.\n    \"\"\"\n    self.dataset.training = True\n    return DataLoader(\n        self.dataset,\n        batch_size=self.batch_size,\n        shuffle=False,\n        drop_last=True,\n        num_workers=self.num_workers,\n    )\n</code></pre>"},{"location":"api/metrics/","title":"Metrics","text":""},{"location":"api/metrics/#novae.monitor.jensen_shannon_divergence","title":"<code>novae.monitor.jensen_shannon_divergence(adatas, obs_key, slide_key=None)</code>","text":"<p>Jensen-Shannon divergence (JSD) over all slides</p> <p>Parameters:</p> Name Type Description Default <code>adatas</code> <code>AnnData | list[AnnData]</code> <p>One or a list of AnnData object(s)</p> required <code>obs_key</code> <code>str</code> <p>Key of <code>adata.obs</code> containing the domains annotation.</p> required <code>slide_key</code> <code>str | None</code> <p>Optional key of <code>adata.obs</code> containing the ID of each slide. Not needed if each <code>adata</code> is a slide.</p> <code>None</code> <p>Returns:</p> Type Description <code>float</code> <p>The Jensen-Shannon divergence score for all slides</p> Source code in <code>novae/monitor/eval.py</code> <pre><code>def jensen_shannon_divergence(adatas: AnnData | list[AnnData], obs_key: str, slide_key: str | None = None) -&gt; float:\n    \"\"\"Jensen-Shannon divergence (JSD) over all slides\n\n    Args:\n        adatas: One or a list of AnnData object(s)\n        obs_key: Key of `adata.obs` containing the domains annotation.\n        slide_key: Optional key of `adata.obs` containing the ID of each slide. Not needed if each `adata` is a slide.\n\n    Returns:\n        The Jensen-Shannon divergence score for all slides\n    \"\"\"\n    all_categories = set()\n    for adata in _iter_uid(adatas, slide_key=slide_key, obs_key=obs_key):\n        all_categories.update(adata.obs[obs_key].cat.categories)\n    all_categories = sorted(all_categories)\n\n    distributions = []\n    for adata in _iter_uid(adatas, slide_key=slide_key, obs_key=obs_key):\n        value_counts = adata.obs[obs_key].value_counts(sort=False)\n        distribution = np.zeros(len(all_categories))\n\n        for i, category in enumerate(all_categories):\n            if category in value_counts:\n                distribution[i] = value_counts[category]\n\n        distributions.append(distribution)\n\n    return _jensen_shannon_divergence(np.array(distributions))\n</code></pre>"},{"location":"api/metrics/#novae.monitor.fide_score","title":"<code>novae.monitor.fide_score(adata, obs_key, n_classes=None)</code>","text":"<p>F1-score of intra-domain edges (FIDE). A high score indicates a great domain continuity.</p> Note <p>The F1-score is computed for every class, then all F1-scores are averaged. If some classes are not predicted, the <code>n_classes</code> argument allows to pad with zeros before averaging the F1-scores.</p> <p>Parameters:</p> Name Type Description Default <code>adata</code> <code>AnnData</code> <p>An <code>AnnData</code> object</p> required <code>obs_key</code> <code>str</code> <p>Key of <code>adata.obs</code> containing the domains annotation.</p> required <code>n_classes</code> <code>int | None</code> <p>Optional number of classes. This can be useful if not all classes are predicted, for a fair comparision.</p> <code>None</code> <p>Returns:</p> Type Description <code>float</code> <p>The FIDE score.</p> Source code in <code>novae/monitor/eval.py</code> <pre><code>def fide_score(adata: AnnData, obs_key: str, n_classes: int | None = None) -&gt; float:\n    \"\"\"F1-score of intra-domain edges (FIDE). A high score indicates a great domain continuity.\n\n    Note:\n        The F1-score is computed for every class, then all F1-scores are averaged. If some classes\n        are not predicted, the `n_classes` argument allows to pad with zeros before averaging the F1-scores.\n\n    Args:\n        adata: An `AnnData` object\n        obs_key: Key of `adata.obs` containing the domains annotation.\n        n_classes: Optional number of classes. This can be useful if not all classes are predicted, for a fair comparision.\n\n    Returns:\n        The FIDE score.\n    \"\"\"\n    i_left, i_right = adata.obsp[Keys.ADJ].nonzero()\n    classes_left, classes_right = adata.obs.iloc[i_left][obs_key].values, adata.obs.iloc[i_right][obs_key].values\n\n    where_valid = ~classes_left.isna() &amp; ~classes_right.isna()\n    classes_left, classes_right = classes_left[where_valid], classes_right[where_valid]\n\n    f1_scores = metrics.f1_score(classes_left, classes_right, average=None)\n\n    if n_classes is None:\n        return f1_scores.mean()\n\n    assert n_classes &gt;= len(f1_scores), f\"Expected {n_classes:=}, but found {len(f1_scores)}, which is greater\"\n\n    return np.pad(f1_scores, (0, n_classes - len(f1_scores))).mean()\n</code></pre>"},{"location":"api/metrics/#novae.monitor.mean_fide_score","title":"<code>novae.monitor.mean_fide_score(adatas, obs_key, slide_key=None, n_classes=None)</code>","text":"<p>Mean FIDE score over all slides. A low score indicates a great domain continuity.</p> <p>Parameters:</p> Name Type Description Default <code>adatas</code> <code>AnnData | list[AnnData]</code> <p>An <code>AnnData</code> object, or a list of <code>AnnData</code> objects.</p> required <code>obs_key</code> <code>str</code> <p>Key of <code>adata.obs</code> containing the domains annotation.</p> required <code>slide_key</code> <code>str | None</code> <p>Optional key of <code>adata.obs</code> containing the ID of each slide. Not needed if each <code>adata</code> is a slide.</p> <code>None</code> <code>n_classes</code> <code>int | None</code> <p>Optional number of classes. This can be useful if not all classes are predicted, for a fair comparision.</p> <code>None</code> <p>Returns:</p> Type Description <code>float</code> <p>The FIDE score averaged for all slides.</p> Source code in <code>novae/monitor/eval.py</code> <pre><code>def mean_fide_score(\n    adatas: AnnData | list[AnnData], obs_key: str, slide_key: str | None = None, n_classes: int | None = None\n) -&gt; float:\n    \"\"\"Mean FIDE score over all slides. A low score indicates a great domain continuity.\n\n    Args:\n        adatas: An `AnnData` object, or a list of `AnnData` objects.\n        obs_key: Key of `adata.obs` containing the domains annotation.\n        slide_key: Optional key of `adata.obs` containing the ID of each slide. Not needed if each `adata` is a slide.\n        n_classes: Optional number of classes. This can be useful if not all classes are predicted, for a fair comparision.\n\n    Returns:\n        The FIDE score averaged for all slides.\n    \"\"\"\n    return np.mean([\n        fide_score(adata, obs_key, n_classes=n_classes)\n        for adata in _iter_uid(adatas, slide_key=slide_key, obs_key=obs_key)\n    ])\n</code></pre>"},{"location":"api/modules/","title":"Modules","text":""},{"location":"api/modules/#novae.module.AttentionAggregation","title":"<code>novae.module.AttentionAggregation</code>","text":"<p>               Bases: <code>Aggregation</code>, <code>LightningModule</code></p> <p>Aggregate the node embeddings using attention.</p> Source code in <code>novae/module/aggregate.py</code> <pre><code>class AttentionAggregation(Aggregation, L.LightningModule):\n    \"\"\"Aggregate the node embeddings using attention.\"\"\"\n\n    def __init__(self, output_size: int):\n        \"\"\"\n\n        Args:\n            output_size: Size of the representations, i.e. the encoder outputs (`O` in the article).\n        \"\"\"\n        super().__init__()\n        self.attention_aggregation = ProjectionLayers(output_size)  # for backward compatibility when loading models\n\n    def forward(\n        self,\n        x: Tensor,\n        index: Tensor | None = None,\n        ptr: None = None,\n        dim_size: None = None,\n        dim: int = -2,\n    ) -&gt; Tensor:\n        \"\"\"Performs attention aggragation.\n\n        Args:\n            x: The nodes embeddings representing `B` total graphs.\n            index: The Pytorch Geometric index used to know to which graph each node belongs.\n\n        Returns:\n            A tensor of shape `(B, O)` of graph embeddings.\n        \"\"\"\n        gate = self.attention_aggregation.gate_nn(x)\n        x = self.attention_aggregation.nn(x)\n\n        gate = softmax(gate, index, dim=dim)\n\n        return self.reduce(gate * x, index, dim=dim)\n\n    def reset_parameters(self):\n        reset(self.attention_aggregation.gate_nn)\n        reset(self.attention_aggregation.nn)\n\n    def __repr__(self) -&gt; str:\n        return f\"{self.__class__.__name__}(gate_nn={self.attention_aggregation.gate_nn}, nn={self.attention_aggregation.nn})\"\n</code></pre>"},{"location":"api/modules/#novae.module.AttentionAggregation.__init__","title":"<code>__init__(output_size)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>output_size</code> <code>int</code> <p>Size of the representations, i.e. the encoder outputs (<code>O</code> in the article).</p> required Source code in <code>novae/module/aggregate.py</code> <pre><code>def __init__(self, output_size: int):\n    \"\"\"\n\n    Args:\n        output_size: Size of the representations, i.e. the encoder outputs (`O` in the article).\n    \"\"\"\n    super().__init__()\n    self.attention_aggregation = ProjectionLayers(output_size)  # for backward compatibility when loading models\n</code></pre>"},{"location":"api/modules/#novae.module.AttentionAggregation.forward","title":"<code>forward(x, index=None, ptr=None, dim_size=None, dim=-2)</code>","text":"<p>Performs attention aggragation.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>Tensor</code> <p>The nodes embeddings representing <code>B</code> total graphs.</p> required <code>index</code> <code>Tensor | None</code> <p>The Pytorch Geometric index used to know to which graph each node belongs.</p> <code>None</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>A tensor of shape <code>(B, O)</code> of graph embeddings.</p> Source code in <code>novae/module/aggregate.py</code> <pre><code>def forward(\n    self,\n    x: Tensor,\n    index: Tensor | None = None,\n    ptr: None = None,\n    dim_size: None = None,\n    dim: int = -2,\n) -&gt; Tensor:\n    \"\"\"Performs attention aggragation.\n\n    Args:\n        x: The nodes embeddings representing `B` total graphs.\n        index: The Pytorch Geometric index used to know to which graph each node belongs.\n\n    Returns:\n        A tensor of shape `(B, O)` of graph embeddings.\n    \"\"\"\n    gate = self.attention_aggregation.gate_nn(x)\n    x = self.attention_aggregation.nn(x)\n\n    gate = softmax(gate, index, dim=dim)\n\n    return self.reduce(gate * x, index, dim=dim)\n</code></pre>"},{"location":"api/modules/#novae.module.CellEmbedder","title":"<code>novae.module.CellEmbedder</code>","text":"<p>               Bases: <code>LightningModule</code></p> <p>Convert a cell into an embedding using a gene embedding matrix.</p> Source code in <code>novae/module/embed.py</code> <pre><code>class CellEmbedder(L.LightningModule):\n    \"\"\"Convert a cell into an embedding using a gene embedding matrix.\"\"\"\n\n    def __init__(\n        self,\n        gene_names: list[str] | dict[str, int],\n        embedding_size: int | None,\n        embedding: torch.Tensor | None = None,\n    ) -&gt; None:\n        \"\"\"\n\n        Args:\n            gene_names: Name of the genes to be used in the embedding, or dictionnary of index to name.\n            embedding_size: Size of the embeddings of the genes (`E` in the article). Optional if `embedding` is provided.\n            embedding: Optional pre-trained embedding matrix. If provided, `embedding_size` shouldn't be provided.\n        \"\"\"\n        super().__init__()\n        assert (embedding_size is None) ^ (embedding is None), \"Either embedding_size or embedding must be provided\"\n\n        if isinstance(gene_names, dict):\n            self.gene_to_index = {gene.lower(): index for gene, index in gene_names.items()}\n            self.gene_names = sorted(self.gene_to_index, key=self.gene_to_index.get)\n            _check_gene_to_index(self.gene_to_index)\n        else:\n            self.gene_names = [gene.lower() for gene in gene_names]\n            self.gene_to_index = {gene: i for i, gene in enumerate(self.gene_names)}\n\n        self.voc_size = len(self.gene_names)\n\n        if embedding is None:\n            self.embedding_size = embedding_size\n            self.embedding = nn.Embedding(self.voc_size, embedding_size)\n        else:\n            self.embedding_size = embedding.size(1)\n            self.embedding = nn.Embedding.from_pretrained(embedding)\n\n        self.linear = nn.Linear(self.embedding_size, self.embedding_size)\n        self._init_linear()\n\n    @torch.no_grad()\n    def _init_linear(self):\n        self.linear.weight.data.copy_(torch.eye(self.embedding_size))\n        self.linear.bias.data.zero_()\n\n    @classmethod\n    def from_scgpt_embedding(cls, scgpt_model_dir: str) -&gt; \"CellEmbedder\":\n        \"\"\"Initialize the CellEmbedder from a scGPT pretrained model directory.\n\n        Args:\n            scgpt_model_dir: Path to a directory containing a scGPT checkpoint, i.e. a `vocab.json` and a `best_model.pt` file.\n\n        Returns:\n            A CellEmbedder instance.\n        \"\"\"\n        scgpt_model_dir = Path(scgpt_model_dir)\n\n        vocab_file = scgpt_model_dir / \"vocab.json\"\n\n        with open(vocab_file) as file:\n            gene_to_index: dict[str, int] = json.load(file)\n\n        checkpoint = torch.load(scgpt_model_dir / \"best_model.pt\", map_location=torch.device(\"cpu\"))\n        embedding = checkpoint[\"encoder.embedding.weight\"]\n\n        return cls(gene_to_index, None, embedding=embedding)\n\n    def genes_to_indices(self, gene_names: pd.Index | list[str], as_torch: bool = True) -&gt; torch.Tensor | np.ndarray:\n        \"\"\"Convert gene names to their corresponding indices.\n\n        Args:\n            gene_names: Names of the gene names to convert.\n            as_torch: Whether to return a `torch` tensor or a `numpy` array.\n\n        Returns:\n            A tensor or array of gene indices.\n        \"\"\"\n        indices = [self.gene_to_index[gene] for gene in utils.lower_var_names(gene_names)]\n\n        if as_torch:\n            return torch.tensor(indices, dtype=torch.long)\n\n        return np.array(indices, dtype=np.int16)\n\n    def forward(self, data: Data) -&gt; Data:\n        \"\"\"Embed the input data.\n\n        Args:\n            data: A Pytorch Geometric `Data` object representing a batch of `B` graphs. The number of node features is variable.\n\n        Returns:\n            data: A Pytorch Geometric `Data` object representing a batch of `B` graphs. Each node now has a size of `E`.\n        \"\"\"\n        genes_embeddings = self.embedding(data.genes_indices[0])\n        genes_embeddings = self.linear(genes_embeddings)\n        genes_embeddings = F.normalize(genes_embeddings, dim=0, p=2)\n\n        data.x = data.x @ genes_embeddings\n        return data\n\n    def pca_init(self, adatas: list[AnnData] | None):\n        \"\"\"Initialize the Noave embeddings with PCA components.\n\n        Args:\n            adatas: A list of `AnnData` objects to use for PCA initialization.\n        \"\"\"\n        if adatas is None:\n            return\n\n        adatas = [adata[:, adata.var[Keys.USE_GENE]] for adata in adatas]\n\n        adata = max(adatas, key=lambda adata: adata.n_vars)\n\n        if adata.X.shape[1] &lt;= self.embedding_size:\n            log.warning(\n                f\"PCA with {self.embedding_size} components can not be run on shape {adata.X.shape}.\\nTo use PCA initialization, set a lower `embedding_size` (&lt;{adata.X.shape[1]}) in novae.Novae().\"\n            )\n            return\n\n        X = adata.X.toarray() if issparse(adata.X) else adata.X\n\n        log.info(\"Running PCA embedding initialization\")\n\n        pca = PCA(n_components=self.embedding_size)\n        pca.fit(X.astype(np.float32))\n\n        indices = self.genes_to_indices(adata.var_names)\n        self.embedding.weight.data[indices] = torch.tensor(pca.components_.T)\n\n        known_var_names = utils.lower_var_names(adata.var_names)\n\n        for other_adata in adatas:\n            other_var_names = utils.lower_var_names(other_adata.var_names)\n            where_in = np.isin(other_var_names, known_var_names)\n\n            if where_in.all():\n                continue\n\n            X = other_adata[:, where_in].X.toarray().T\n            Y = other_adata[:, ~where_in].X.toarray().T\n\n            tree = KDTree(X)\n            _, ind = tree.query(Y, k=1)\n            neighbor_indices = self.genes_to_indices(other_adata[:, where_in].var_names[ind[:, 0]])\n\n            indices = self.genes_to_indices(other_adata[:, ~where_in].var_names)\n            self.embedding.weight.data[indices] = self.embedding.weight.data[neighbor_indices].clone()\n</code></pre>"},{"location":"api/modules/#novae.module.CellEmbedder.__init__","title":"<code>__init__(gene_names, embedding_size, embedding=None)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>gene_names</code> <code>list[str] | dict[str, int]</code> <p>Name of the genes to be used in the embedding, or dictionnary of index to name.</p> required <code>embedding_size</code> <code>int | None</code> <p>Size of the embeddings of the genes (<code>E</code> in the article). Optional if <code>embedding</code> is provided.</p> required <code>embedding</code> <code>Tensor | None</code> <p>Optional pre-trained embedding matrix. If provided, <code>embedding_size</code> shouldn't be provided.</p> <code>None</code> Source code in <code>novae/module/embed.py</code> <pre><code>def __init__(\n    self,\n    gene_names: list[str] | dict[str, int],\n    embedding_size: int | None,\n    embedding: torch.Tensor | None = None,\n) -&gt; None:\n    \"\"\"\n\n    Args:\n        gene_names: Name of the genes to be used in the embedding, or dictionnary of index to name.\n        embedding_size: Size of the embeddings of the genes (`E` in the article). Optional if `embedding` is provided.\n        embedding: Optional pre-trained embedding matrix. If provided, `embedding_size` shouldn't be provided.\n    \"\"\"\n    super().__init__()\n    assert (embedding_size is None) ^ (embedding is None), \"Either embedding_size or embedding must be provided\"\n\n    if isinstance(gene_names, dict):\n        self.gene_to_index = {gene.lower(): index for gene, index in gene_names.items()}\n        self.gene_names = sorted(self.gene_to_index, key=self.gene_to_index.get)\n        _check_gene_to_index(self.gene_to_index)\n    else:\n        self.gene_names = [gene.lower() for gene in gene_names]\n        self.gene_to_index = {gene: i for i, gene in enumerate(self.gene_names)}\n\n    self.voc_size = len(self.gene_names)\n\n    if embedding is None:\n        self.embedding_size = embedding_size\n        self.embedding = nn.Embedding(self.voc_size, embedding_size)\n    else:\n        self.embedding_size = embedding.size(1)\n        self.embedding = nn.Embedding.from_pretrained(embedding)\n\n    self.linear = nn.Linear(self.embedding_size, self.embedding_size)\n    self._init_linear()\n</code></pre>"},{"location":"api/modules/#novae.module.CellEmbedder.forward","title":"<code>forward(data)</code>","text":"<p>Embed the input data.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Data</code> <p>A Pytorch Geometric <code>Data</code> object representing a batch of <code>B</code> graphs. The number of node features is variable.</p> required <p>Returns:</p> Name Type Description <code>data</code> <code>Data</code> <p>A Pytorch Geometric <code>Data</code> object representing a batch of <code>B</code> graphs. Each node now has a size of <code>E</code>.</p> Source code in <code>novae/module/embed.py</code> <pre><code>def forward(self, data: Data) -&gt; Data:\n    \"\"\"Embed the input data.\n\n    Args:\n        data: A Pytorch Geometric `Data` object representing a batch of `B` graphs. The number of node features is variable.\n\n    Returns:\n        data: A Pytorch Geometric `Data` object representing a batch of `B` graphs. Each node now has a size of `E`.\n    \"\"\"\n    genes_embeddings = self.embedding(data.genes_indices[0])\n    genes_embeddings = self.linear(genes_embeddings)\n    genes_embeddings = F.normalize(genes_embeddings, dim=0, p=2)\n\n    data.x = data.x @ genes_embeddings\n    return data\n</code></pre>"},{"location":"api/modules/#novae.module.CellEmbedder.from_scgpt_embedding","title":"<code>from_scgpt_embedding(scgpt_model_dir)</code>  <code>classmethod</code>","text":"<p>Initialize the CellEmbedder from a scGPT pretrained model directory.</p> <p>Parameters:</p> Name Type Description Default <code>scgpt_model_dir</code> <code>str</code> <p>Path to a directory containing a scGPT checkpoint, i.e. a <code>vocab.json</code> and a <code>best_model.pt</code> file.</p> required <p>Returns:</p> Type Description <code>CellEmbedder</code> <p>A CellEmbedder instance.</p> Source code in <code>novae/module/embed.py</code> <pre><code>@classmethod\ndef from_scgpt_embedding(cls, scgpt_model_dir: str) -&gt; \"CellEmbedder\":\n    \"\"\"Initialize the CellEmbedder from a scGPT pretrained model directory.\n\n    Args:\n        scgpt_model_dir: Path to a directory containing a scGPT checkpoint, i.e. a `vocab.json` and a `best_model.pt` file.\n\n    Returns:\n        A CellEmbedder instance.\n    \"\"\"\n    scgpt_model_dir = Path(scgpt_model_dir)\n\n    vocab_file = scgpt_model_dir / \"vocab.json\"\n\n    with open(vocab_file) as file:\n        gene_to_index: dict[str, int] = json.load(file)\n\n    checkpoint = torch.load(scgpt_model_dir / \"best_model.pt\", map_location=torch.device(\"cpu\"))\n    embedding = checkpoint[\"encoder.embedding.weight\"]\n\n    return cls(gene_to_index, None, embedding=embedding)\n</code></pre>"},{"location":"api/modules/#novae.module.CellEmbedder.genes_to_indices","title":"<code>genes_to_indices(gene_names, as_torch=True)</code>","text":"<p>Convert gene names to their corresponding indices.</p> <p>Parameters:</p> Name Type Description Default <code>gene_names</code> <code>Index | list[str]</code> <p>Names of the gene names to convert.</p> required <code>as_torch</code> <code>bool</code> <p>Whether to return a <code>torch</code> tensor or a <code>numpy</code> array.</p> <code>True</code> <p>Returns:</p> Type Description <code>Tensor | ndarray</code> <p>A tensor or array of gene indices.</p> Source code in <code>novae/module/embed.py</code> <pre><code>def genes_to_indices(self, gene_names: pd.Index | list[str], as_torch: bool = True) -&gt; torch.Tensor | np.ndarray:\n    \"\"\"Convert gene names to their corresponding indices.\n\n    Args:\n        gene_names: Names of the gene names to convert.\n        as_torch: Whether to return a `torch` tensor or a `numpy` array.\n\n    Returns:\n        A tensor or array of gene indices.\n    \"\"\"\n    indices = [self.gene_to_index[gene] for gene in utils.lower_var_names(gene_names)]\n\n    if as_torch:\n        return torch.tensor(indices, dtype=torch.long)\n\n    return np.array(indices, dtype=np.int16)\n</code></pre>"},{"location":"api/modules/#novae.module.CellEmbedder.pca_init","title":"<code>pca_init(adatas)</code>","text":"<p>Initialize the Noave embeddings with PCA components.</p> <p>Parameters:</p> Name Type Description Default <code>adatas</code> <code>list[AnnData] | None</code> <p>A list of <code>AnnData</code> objects to use for PCA initialization.</p> required Source code in <code>novae/module/embed.py</code> <pre><code>def pca_init(self, adatas: list[AnnData] | None):\n    \"\"\"Initialize the Noave embeddings with PCA components.\n\n    Args:\n        adatas: A list of `AnnData` objects to use for PCA initialization.\n    \"\"\"\n    if adatas is None:\n        return\n\n    adatas = [adata[:, adata.var[Keys.USE_GENE]] for adata in adatas]\n\n    adata = max(adatas, key=lambda adata: adata.n_vars)\n\n    if adata.X.shape[1] &lt;= self.embedding_size:\n        log.warning(\n            f\"PCA with {self.embedding_size} components can not be run on shape {adata.X.shape}.\\nTo use PCA initialization, set a lower `embedding_size` (&lt;{adata.X.shape[1]}) in novae.Novae().\"\n        )\n        return\n\n    X = adata.X.toarray() if issparse(adata.X) else adata.X\n\n    log.info(\"Running PCA embedding initialization\")\n\n    pca = PCA(n_components=self.embedding_size)\n    pca.fit(X.astype(np.float32))\n\n    indices = self.genes_to_indices(adata.var_names)\n    self.embedding.weight.data[indices] = torch.tensor(pca.components_.T)\n\n    known_var_names = utils.lower_var_names(adata.var_names)\n\n    for other_adata in adatas:\n        other_var_names = utils.lower_var_names(other_adata.var_names)\n        where_in = np.isin(other_var_names, known_var_names)\n\n        if where_in.all():\n            continue\n\n        X = other_adata[:, where_in].X.toarray().T\n        Y = other_adata[:, ~where_in].X.toarray().T\n\n        tree = KDTree(X)\n        _, ind = tree.query(Y, k=1)\n        neighbor_indices = self.genes_to_indices(other_adata[:, where_in].var_names[ind[:, 0]])\n\n        indices = self.genes_to_indices(other_adata[:, ~where_in].var_names)\n        self.embedding.weight.data[indices] = self.embedding.weight.data[neighbor_indices].clone()\n</code></pre>"},{"location":"api/modules/#novae.module.GraphAugmentation","title":"<code>novae.module.GraphAugmentation</code>","text":"<p>               Bases: <code>LightningModule</code></p> <p>Perform graph augmentation for Novae. It adds noise to the data and keeps a subset of the genes.</p> Source code in <code>novae/module/augment.py</code> <pre><code>class GraphAugmentation(L.LightningModule):\n    \"\"\"Perform graph augmentation for Novae. It adds noise to the data and keeps a subset of the genes.\"\"\"\n\n    def __init__(\n        self,\n        panel_subset_size: float,\n        background_noise_lambda: float,\n        sensitivity_noise_std: float,\n        dropout_rate: float,\n    ):\n        \"\"\"\n\n        Args:\n            panel_subset_size: Ratio of genes kept from the panel during augmentation.\n            background_noise_lambda: Parameter of the exponential distribution for the noise augmentation.\n            sensitivity_noise_std: Standard deviation for the multiplicative for for the noise augmentation.\n        \"\"\"\n        super().__init__()\n        self.panel_subset_size = panel_subset_size\n        self.background_noise_lambda = background_noise_lambda\n        self.sensitivity_noise_std = sensitivity_noise_std\n        self.dropout_rate = dropout_rate\n\n        self.background_noise_distribution = Exponential(torch.tensor(float(background_noise_lambda)))\n\n    def noise(self, data: Batch):\n        \"\"\"Add noise (inplace) to the data as detailed in the article.\n\n        Args:\n            data: A Pytorch Geometric `Data` object representing a batch of `B` graphs.\n        \"\"\"\n        sample_shape = (data.batch_size, data.x.shape[1])\n\n        additions = self.background_noise_distribution.sample(sample_shape=sample_shape).to(self.device)\n        gaussian_noise = torch.randn(sample_shape, device=self.device)\n        factors = (1 + gaussian_noise * self.sensitivity_noise_std).clip(0, 2)\n\n        for i in range(data.batch_size):\n            start, stop = data.ptr[i], data.ptr[i + 1]\n            data.x[start:stop] = data.x[start:stop] * factors[i] + additions[i]\n\n    def dropout(self, data: Batch):\n        \"\"\"Set to 0 the expression of some genes (inplace).\n\n        Args:\n            data: A Pytorch Geometric `Data` object representing a batch of `B` graphs.\n        \"\"\"\n        if self.dropout_rate == 0:\n            return\n\n        mask = torch.rand(data.x.shape[1], device=self.device) &lt; self.dropout_rate\n        data.x[:, mask] = 0\n\n    def panel_subset(self, data: Batch):\n        \"\"\"\n        Keep a ratio of `panel_subset_size` of the input genes (inplace operation).\n        Contrary to the dropout, it doesn't set the expression to 0, but removes the genes from the panel.\n\n        Args:\n            data: A Pytorch Geometric `Data` object representing a batch of `B` graphs.\n        \"\"\"\n        n_total = len(data.genes_indices[0])\n        n_subset = int(n_total * self.panel_subset_size)\n\n        gene_subset_indices = torch.randperm(n_total)[:n_subset]\n\n        data.x = data.x[:, gene_subset_indices]\n        data.genes_indices = data.genes_indices[:, gene_subset_indices]\n\n    def forward(self, data: Batch) -&gt; Batch:\n        \"\"\"Perform data augmentation (`noise` and `panel_subset`).\n\n        Args:\n            data: A Pytorch Geometric `Data` object representing a batch of `B` graphs.\n\n        Returns:\n            The augmented `Data` object\n        \"\"\"\n        self.panel_subset(data)\n        self.noise(data)\n        return data\n</code></pre>"},{"location":"api/modules/#novae.module.GraphAugmentation.__init__","title":"<code>__init__(panel_subset_size, background_noise_lambda, sensitivity_noise_std, dropout_rate)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>panel_subset_size</code> <code>float</code> <p>Ratio of genes kept from the panel during augmentation.</p> required <code>background_noise_lambda</code> <code>float</code> <p>Parameter of the exponential distribution for the noise augmentation.</p> required <code>sensitivity_noise_std</code> <code>float</code> <p>Standard deviation for the multiplicative for for the noise augmentation.</p> required Source code in <code>novae/module/augment.py</code> <pre><code>def __init__(\n    self,\n    panel_subset_size: float,\n    background_noise_lambda: float,\n    sensitivity_noise_std: float,\n    dropout_rate: float,\n):\n    \"\"\"\n\n    Args:\n        panel_subset_size: Ratio of genes kept from the panel during augmentation.\n        background_noise_lambda: Parameter of the exponential distribution for the noise augmentation.\n        sensitivity_noise_std: Standard deviation for the multiplicative for for the noise augmentation.\n    \"\"\"\n    super().__init__()\n    self.panel_subset_size = panel_subset_size\n    self.background_noise_lambda = background_noise_lambda\n    self.sensitivity_noise_std = sensitivity_noise_std\n    self.dropout_rate = dropout_rate\n\n    self.background_noise_distribution = Exponential(torch.tensor(float(background_noise_lambda)))\n</code></pre>"},{"location":"api/modules/#novae.module.GraphAugmentation.dropout","title":"<code>dropout(data)</code>","text":"<p>Set to 0 the expression of some genes (inplace).</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Batch</code> <p>A Pytorch Geometric <code>Data</code> object representing a batch of <code>B</code> graphs.</p> required Source code in <code>novae/module/augment.py</code> <pre><code>def dropout(self, data: Batch):\n    \"\"\"Set to 0 the expression of some genes (inplace).\n\n    Args:\n        data: A Pytorch Geometric `Data` object representing a batch of `B` graphs.\n    \"\"\"\n    if self.dropout_rate == 0:\n        return\n\n    mask = torch.rand(data.x.shape[1], device=self.device) &lt; self.dropout_rate\n    data.x[:, mask] = 0\n</code></pre>"},{"location":"api/modules/#novae.module.GraphAugmentation.forward","title":"<code>forward(data)</code>","text":"<p>Perform data augmentation (<code>noise</code> and <code>panel_subset</code>).</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Batch</code> <p>A Pytorch Geometric <code>Data</code> object representing a batch of <code>B</code> graphs.</p> required <p>Returns:</p> Type Description <code>Batch</code> <p>The augmented <code>Data</code> object</p> Source code in <code>novae/module/augment.py</code> <pre><code>def forward(self, data: Batch) -&gt; Batch:\n    \"\"\"Perform data augmentation (`noise` and `panel_subset`).\n\n    Args:\n        data: A Pytorch Geometric `Data` object representing a batch of `B` graphs.\n\n    Returns:\n        The augmented `Data` object\n    \"\"\"\n    self.panel_subset(data)\n    self.noise(data)\n    return data\n</code></pre>"},{"location":"api/modules/#novae.module.GraphAugmentation.noise","title":"<code>noise(data)</code>","text":"<p>Add noise (inplace) to the data as detailed in the article.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Batch</code> <p>A Pytorch Geometric <code>Data</code> object representing a batch of <code>B</code> graphs.</p> required Source code in <code>novae/module/augment.py</code> <pre><code>def noise(self, data: Batch):\n    \"\"\"Add noise (inplace) to the data as detailed in the article.\n\n    Args:\n        data: A Pytorch Geometric `Data` object representing a batch of `B` graphs.\n    \"\"\"\n    sample_shape = (data.batch_size, data.x.shape[1])\n\n    additions = self.background_noise_distribution.sample(sample_shape=sample_shape).to(self.device)\n    gaussian_noise = torch.randn(sample_shape, device=self.device)\n    factors = (1 + gaussian_noise * self.sensitivity_noise_std).clip(0, 2)\n\n    for i in range(data.batch_size):\n        start, stop = data.ptr[i], data.ptr[i + 1]\n        data.x[start:stop] = data.x[start:stop] * factors[i] + additions[i]\n</code></pre>"},{"location":"api/modules/#novae.module.GraphAugmentation.panel_subset","title":"<code>panel_subset(data)</code>","text":"<p>Keep a ratio of <code>panel_subset_size</code> of the input genes (inplace operation). Contrary to the dropout, it doesn't set the expression to 0, but removes the genes from the panel.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Batch</code> <p>A Pytorch Geometric <code>Data</code> object representing a batch of <code>B</code> graphs.</p> required Source code in <code>novae/module/augment.py</code> <pre><code>def panel_subset(self, data: Batch):\n    \"\"\"\n    Keep a ratio of `panel_subset_size` of the input genes (inplace operation).\n    Contrary to the dropout, it doesn't set the expression to 0, but removes the genes from the panel.\n\n    Args:\n        data: A Pytorch Geometric `Data` object representing a batch of `B` graphs.\n    \"\"\"\n    n_total = len(data.genes_indices[0])\n    n_subset = int(n_total * self.panel_subset_size)\n\n    gene_subset_indices = torch.randperm(n_total)[:n_subset]\n\n    data.x = data.x[:, gene_subset_indices]\n    data.genes_indices = data.genes_indices[:, gene_subset_indices]\n</code></pre>"},{"location":"api/modules/#novae.module.GraphEncoder","title":"<code>novae.module.GraphEncoder</code>","text":"<p>               Bases: <code>LightningModule</code></p> <p>Graph encoder of Novae. It uses a graph attention network.</p> Source code in <code>novae/module/encode.py</code> <pre><code>class GraphEncoder(L.LightningModule):\n    \"\"\"Graph encoder of Novae. It uses a graph attention network.\"\"\"\n\n    def __init__(\n        self,\n        embedding_size: int,\n        hidden_size: int,\n        num_layers: int,\n        output_size: int,\n        heads: int,\n        histo_embedding_size: int,\n    ) -&gt; None:\n        \"\"\"\n        Args:\n            embedding_size: Size of the embeddings of the genes (`E` in the article).\n            hidden_size: The size of the hidden layers in the GAT.\n            num_layers: The number of layers in the GAT.\n            output_size: Size of the representations, i.e. the encoder outputs (`O` in the article).\n            heads: The number of attention heads in the GAT.\n        \"\"\"\n        super().__init__()\n        self.gnn = GAT(\n            embedding_size,\n            hidden_channels=hidden_size,\n            num_layers=num_layers,\n            out_channels=output_size,\n            edge_dim=1,\n            v2=True,\n            heads=heads,\n            act=\"ELU\",\n        )\n\n        self.node_aggregation = AttentionAggregation(output_size)\n\n        self.mlp_fusion = nn.Sequential(\n            nn.Linear(histo_embedding_size + output_size, histo_embedding_size + output_size),\n            nn.ReLU(),\n            nn.Linear(histo_embedding_size + output_size, output_size),\n            nn.ReLU(),\n            nn.Linear(output_size, output_size),\n        )\n\n    def forward(self, data: Batch) -&gt; Tensor:\n        \"\"\"Encode the input data.\n\n        Args:\n            data: A Pytorch Geometric `Data` object representing a batch of `B` graphs.\n\n        Returns:\n            A tensor of shape `(B, O)` containing the encoded graphs.\n        \"\"\"\n        out = self.gnn(x=data.x, edge_index=data.edge_index, edge_attr=data.edge_attr)\n        out = self.node_aggregation(out, index=data.batch)\n\n        if hasattr(data, \"histo_embeddings\"):\n            out = self.mlp_fusion(torch.cat([out, data.histo_embeddings], dim=-1))\n\n        return out\n</code></pre>"},{"location":"api/modules/#novae.module.GraphEncoder.__init__","title":"<code>__init__(embedding_size, hidden_size, num_layers, output_size, heads, histo_embedding_size)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>embedding_size</code> <code>int</code> <p>Size of the embeddings of the genes (<code>E</code> in the article).</p> required <code>hidden_size</code> <code>int</code> <p>The size of the hidden layers in the GAT.</p> required <code>num_layers</code> <code>int</code> <p>The number of layers in the GAT.</p> required <code>output_size</code> <code>int</code> <p>Size of the representations, i.e. the encoder outputs (<code>O</code> in the article).</p> required <code>heads</code> <code>int</code> <p>The number of attention heads in the GAT.</p> required Source code in <code>novae/module/encode.py</code> <pre><code>def __init__(\n    self,\n    embedding_size: int,\n    hidden_size: int,\n    num_layers: int,\n    output_size: int,\n    heads: int,\n    histo_embedding_size: int,\n) -&gt; None:\n    \"\"\"\n    Args:\n        embedding_size: Size of the embeddings of the genes (`E` in the article).\n        hidden_size: The size of the hidden layers in the GAT.\n        num_layers: The number of layers in the GAT.\n        output_size: Size of the representations, i.e. the encoder outputs (`O` in the article).\n        heads: The number of attention heads in the GAT.\n    \"\"\"\n    super().__init__()\n    self.gnn = GAT(\n        embedding_size,\n        hidden_channels=hidden_size,\n        num_layers=num_layers,\n        out_channels=output_size,\n        edge_dim=1,\n        v2=True,\n        heads=heads,\n        act=\"ELU\",\n    )\n\n    self.node_aggregation = AttentionAggregation(output_size)\n\n    self.mlp_fusion = nn.Sequential(\n        nn.Linear(histo_embedding_size + output_size, histo_embedding_size + output_size),\n        nn.ReLU(),\n        nn.Linear(histo_embedding_size + output_size, output_size),\n        nn.ReLU(),\n        nn.Linear(output_size, output_size),\n    )\n</code></pre>"},{"location":"api/modules/#novae.module.GraphEncoder.forward","title":"<code>forward(data)</code>","text":"<p>Encode the input data.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Batch</code> <p>A Pytorch Geometric <code>Data</code> object representing a batch of <code>B</code> graphs.</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>A tensor of shape <code>(B, O)</code> containing the encoded graphs.</p> Source code in <code>novae/module/encode.py</code> <pre><code>def forward(self, data: Batch) -&gt; Tensor:\n    \"\"\"Encode the input data.\n\n    Args:\n        data: A Pytorch Geometric `Data` object representing a batch of `B` graphs.\n\n    Returns:\n        A tensor of shape `(B, O)` containing the encoded graphs.\n    \"\"\"\n    out = self.gnn(x=data.x, edge_index=data.edge_index, edge_attr=data.edge_attr)\n    out = self.node_aggregation(out, index=data.batch)\n\n    if hasattr(data, \"histo_embeddings\"):\n        out = self.mlp_fusion(torch.cat([out, data.histo_embeddings], dim=-1))\n\n    return out\n</code></pre>"},{"location":"api/modules/#novae.module.SwavHead","title":"<code>novae.module.SwavHead</code>","text":"<p>               Bases: <code>LightningModule</code></p> Source code in <code>novae/module/swav.py</code> <pre><code>class SwavHead(L.LightningModule):\n    queue: None | Tensor  # (n_slides, QUEUE_SIZE, num_prototypes)\n\n    def __init__(\n        self,\n        mode: utils.Mode,\n        output_size: int,\n        num_prototypes: int,\n        temperature: float,\n    ):\n        \"\"\"SwavHead module, adapted from the paper [\"Unsupervised Learning of Visual Features by Contrasting Cluster Assignments\"](https://arxiv.org/abs/2006.09882).\n\n        Args:\n            output_size: Size of the representations, i.e. the encoder outputs (`O` in the article).\n            num_prototypes: Number of prototypes (`K` in the article).\n            temperature: Temperature used in the cross-entropy loss.\n        \"\"\"\n        super().__init__()\n        self.mode = mode\n        self.output_size = output_size\n        self.num_prototypes = num_prototypes\n        self.temperature = temperature\n\n        self._prototypes = nn.Parameter(torch.empty((self.num_prototypes, self.output_size)))\n        self._prototypes = nn.init.kaiming_uniform_(self._prototypes, a=math.sqrt(5), mode=\"fan_out\")\n        self.normalize_prototypes()\n        self.min_prototypes = 0\n\n        self._kmeans_prototypes: nn.Parameter | None = None\n\n        self.queue = None\n\n        self.reset_clustering()\n\n    def set_min_prototypes(self, min_prototypes_ratio: float):\n        self.min_prototypes = int(self.num_prototypes * min_prototypes_ratio)\n\n    def init_queue(self, slide_ids: list[str]) -&gt; None:\n        \"\"\"Initialize the slide-queue.\n\n        Args:\n            slide_ids: A list of slide ids.\n        \"\"\"\n        del self.queue\n\n        shape = (len(slide_ids), Nums.QUEUE_SIZE, self.num_prototypes)\n        self.register_buffer(\"queue\", torch.full(shape, 1 / self.num_prototypes))\n\n        self.slide_label_encoder = {slide_id: i for i, slide_id in enumerate(slide_ids)}\n\n    @torch.no_grad()\n    def normalize_prototypes(self):\n        self.prototypes.data = F.normalize(self.prototypes.data, dim=1, p=2)\n\n    def forward(self, z1: Tensor, z2: Tensor, slide_id: str | None) -&gt; tuple[Tensor, dict[str, Tensor]]:\n        \"\"\"Compute the SwAV loss for two batches of neighborhood graph views.\n\n        Args:\n            z1: Batch containing graphs representations `(B, output_size)`\n            z2: Batch containing graphs representations `(B, output_size)`\n\n        Returns:\n            The SwAV loss, and the mean entropy normalized (for monitoring).\n        \"\"\"\n        self.normalize_prototypes()\n\n        projections1 = self.projection(z1)  # (B, K)\n        projections2 = self.projection(z2)  # (B, K)\n\n        ilocs = self.prototype_ilocs(projections1, slide_id)\n\n        projections1, projections2 = projections1[:, ilocs], projections2[:, ilocs]\n\n        q1 = self.sinkhorn(projections1)  # (B, K) or (B, len(ilocs))\n        q2 = self.sinkhorn(projections2)  # (B, K) or (B, len(ilocs))\n\n        loss = -0.5 * (self.cross_entropy_loss(q1, projections2) + self.cross_entropy_loss(q2, projections1))\n\n        return loss, _mean_entropy_normalized(q1)\n\n    def cross_entropy_loss(self, q: Tensor, p: Tensor) -&gt; Tensor:\n        return torch.mean(torch.sum(q * F.log_softmax(p / self.temperature, dim=1), dim=1))\n\n    def projection(self, z: Tensor) -&gt; Tensor:\n        \"\"\"Compute the projection of the (normalized) representations over the prototypes.\n\n        Args:\n            z: The representations of one batch, of size `(B, O)`.\n\n        Returns:\n            The projections of size `(B, K)`.\n        \"\"\"\n        z_normalized = F.normalize(z, dim=1, p=2)\n        return z_normalized @ self.prototypes.T\n\n    @torch.no_grad()\n    def prototype_ilocs(self, projections: Tensor, slide_id: str | None = None) -&gt; Tensor:\n        \"\"\"Get the indices of the prototypes to use for the current slide.\n\n        Args:\n            projections: Projections of the (normalized) representations over the prototypes, of size `(B, K)`.\n            slide_id: ID of the slide, or `None`.\n\n        Returns:\n            The indices of the prototypes to use, or an `Ellipsis` if all prototypes.\n        \"\"\"\n        if (self.queue is None) or (slide_id is None) or self.mode.zero_shot:\n            return ...\n\n        slide_index = self.slide_label_encoder[slide_id]\n\n        self.queue[slide_index, 1:] = self.queue[slide_index, :-1].clone()\n        self.queue[slide_index, 0] = projections.topk(3, dim=0).values[-1]  # top3 more robust than max\n\n        weights, thresholds = self.queue_weights()\n        slide_weights = weights[slide_index]\n\n        ilocs = torch.where(slide_weights &gt;= thresholds)[0]\n\n        if len(ilocs) &gt;= self.min_prototypes:\n            return ilocs\n\n        other_locs = torch.where(slide_weights &lt; thresholds)[0]\n        other_locs = other_locs[torch.topk(slide_weights[other_locs], self.min_prototypes - len(ilocs)).indices]\n\n        return torch.cat([ilocs, other_locs])\n\n    def queue_weights(self) -&gt; tuple[Tensor, Tensor]:\n        \"\"\"Convert the queue to a matrix of prototype weight per slide.\n\n        Returns:\n            A tensor of shape `(n_slides, K)`, and a tensor of shape (K,).\n        \"\"\"\n        max_projections = self.queue.max(dim=1).values\n\n        thresholds = max_projections.max(0).values * Nums.QUEUE_WEIGHT_THRESHOLD_RATIO\n        thresholds -= 1 - Nums.QUEUE_WEIGHT_THRESHOLD_RATIO  # ensure that for max-weights &lt; 0 are above the threshold\n\n        return max_projections, thresholds\n\n    @torch.no_grad()\n    def sinkhorn(self, projections: Tensor) -&gt; Tensor:\n        \"\"\"Apply the Sinkhorn-Knopp algorithm to the projections.\n\n        Args:\n            projections: Projections of the (normalized) representations over the prototypes, of size `(B, K)`.\n\n        Returns:\n            The soft codes from the Sinkhorn-Knopp algorithm, with shape `(B, K)`.\n        \"\"\"\n        Q = torch.exp(projections / Nums.SWAV_EPSILON)  # (B, K)\n        Q /= torch.sum(Q)\n\n        B, K = Q.shape\n\n        for _ in range(Nums.SINKHORN_ITERATIONS):\n            Q /= torch.sum(Q, dim=0, keepdim=True)\n            Q /= K\n            Q /= torch.sum(Q, dim=1, keepdim=True)\n            Q /= B\n\n        return Q / Q.sum(dim=1, keepdim=True)  # ensure rows sum to 1 (for cross-entropy loss)\n\n    def compute_kmeans_prototypes(self, latent: np.ndarray) -&gt; nn.Parameter:\n        assert len(latent) &gt;= self.num_prototypes, (\n            f\"The number of valid cells ({len(latent)}) must be greater than the number of prototypes ({self.num_prototypes}).\"\n        )\n\n        kmeans = KMeans(n_clusters=self.num_prototypes, random_state=0, n_init=\"auto\")\n        X = latent / (Nums.EPS + np.linalg.norm(latent, axis=1)[:, None])\n\n        kmeans_prototypes = kmeans.fit(X).cluster_centers_\n        kmeans_prototypes = kmeans_prototypes / (Nums.EPS + np.linalg.norm(kmeans_prototypes, axis=1)[:, None])\n\n        return torch.nn.Parameter(torch.tensor(kmeans_prototypes))\n\n    @property\n    def prototypes(self) -&gt; nn.Parameter:\n        return self._kmeans_prototypes if self.mode.zero_shot else self._prototypes\n\n    @property\n    def clustering(self) -&gt; AgglomerativeClustering:\n        clustering_attr = self.mode.clustering_attr\n\n        if getattr(self, clustering_attr) is None:\n            self.hierarchical_clustering()\n\n        return getattr(self, clustering_attr)\n\n    @property\n    def clusters_levels(self) -&gt; np.ndarray:\n        clusters_levels_attr = self.mode.clusters_levels_attr\n\n        if getattr(self, clusters_levels_attr) is None:\n            self.hierarchical_clustering()\n\n        return getattr(self, clusters_levels_attr)\n\n    def reset_clustering(self, only_zero_shot: bool = False) -&gt; None:\n        attrs = self.mode.zero_shot_clustering_attrs if only_zero_shot else self.mode.all_clustering_attrs\n        for attr in attrs:\n            setattr(self, attr, None)\n\n    def set_clustering(self, clustering: None, clusters_levels: None) -&gt; None:\n        setattr(self, self.mode.clustering_attr, clustering)\n        setattr(self, self.mode.clusters_levels_attr, clusters_levels)\n\n    def hierarchical_clustering(self) -&gt; None:\n        \"\"\"\n        Perform hierarchical clustering on the prototypes. Saves the full tree of clusters.\n        \"\"\"\n        X = self.prototypes.data.numpy(force=True)  # (K, O)\n\n        _clustering = AgglomerativeClustering(\n            n_clusters=None,\n            distance_threshold=0,\n            compute_full_tree=True,\n            metric=\"cosine\",\n            linkage=\"average\",\n        )\n        _clustering.fit(X)\n\n        _clusters_levels = np.zeros((len(X), len(X)), dtype=np.uint16)\n        _clusters_levels[0] = np.arange(len(X))\n\n        for i, (a, b) in enumerate(_clustering.children_):\n            clusters = _clusters_levels[i]\n            _clusters_levels[i + 1] = clusters\n            _clusters_levels[i + 1, np.where((clusters == a) | (clusters == b))] = len(X) + i\n\n        self.set_clustering(_clustering, _clusters_levels)\n\n    def map_leaves_domains(self, series: pd.Series, level: int) -&gt; pd.Series:\n        \"\"\"Map leaves to the parent domain from the corresponding level of the hierarchical tree.\n\n        Args:\n            series: Leaves classes\n            level: Level of the hierarchical clustering tree (or, number of clusters)\n\n        Returns:\n            Series of classes.\n        \"\"\"\n        return series.map(lambda x: f\"D{self.clusters_levels[-level, int(x[1:])]}\" if isinstance(x, str) else x)\n\n    def find_level(self, leaves_indices: np.ndarray, n_domains: int):\n        sub_clusters_levels = self.clusters_levels[:, leaves_indices]\n        for level in range(1, self.num_prototypes):\n            _n_domains = len(np.unique(sub_clusters_levels[-level]))\n            if _n_domains == n_domains:\n                return level\n        raise ValueError(f\"Could not find a level with {n_domains=}\")\n</code></pre>"},{"location":"api/modules/#novae.module.SwavHead.__init__","title":"<code>__init__(mode, output_size, num_prototypes, temperature)</code>","text":"<p>SwavHead module, adapted from the paper \"Unsupervised Learning of Visual Features by Contrasting Cluster Assignments\".</p> <p>Parameters:</p> Name Type Description Default <code>output_size</code> <code>int</code> <p>Size of the representations, i.e. the encoder outputs (<code>O</code> in the article).</p> required <code>num_prototypes</code> <code>int</code> <p>Number of prototypes (<code>K</code> in the article).</p> required <code>temperature</code> <code>float</code> <p>Temperature used in the cross-entropy loss.</p> required Source code in <code>novae/module/swav.py</code> <pre><code>def __init__(\n    self,\n    mode: utils.Mode,\n    output_size: int,\n    num_prototypes: int,\n    temperature: float,\n):\n    \"\"\"SwavHead module, adapted from the paper [\"Unsupervised Learning of Visual Features by Contrasting Cluster Assignments\"](https://arxiv.org/abs/2006.09882).\n\n    Args:\n        output_size: Size of the representations, i.e. the encoder outputs (`O` in the article).\n        num_prototypes: Number of prototypes (`K` in the article).\n        temperature: Temperature used in the cross-entropy loss.\n    \"\"\"\n    super().__init__()\n    self.mode = mode\n    self.output_size = output_size\n    self.num_prototypes = num_prototypes\n    self.temperature = temperature\n\n    self._prototypes = nn.Parameter(torch.empty((self.num_prototypes, self.output_size)))\n    self._prototypes = nn.init.kaiming_uniform_(self._prototypes, a=math.sqrt(5), mode=\"fan_out\")\n    self.normalize_prototypes()\n    self.min_prototypes = 0\n\n    self._kmeans_prototypes: nn.Parameter | None = None\n\n    self.queue = None\n\n    self.reset_clustering()\n</code></pre>"},{"location":"api/modules/#novae.module.SwavHead.forward","title":"<code>forward(z1, z2, slide_id)</code>","text":"<p>Compute the SwAV loss for two batches of neighborhood graph views.</p> <p>Parameters:</p> Name Type Description Default <code>z1</code> <code>Tensor</code> <p>Batch containing graphs representations <code>(B, output_size)</code></p> required <code>z2</code> <code>Tensor</code> <p>Batch containing graphs representations <code>(B, output_size)</code></p> required <p>Returns:</p> Type Description <code>tuple[Tensor, dict[str, Tensor]]</code> <p>The SwAV loss, and the mean entropy normalized (for monitoring).</p> Source code in <code>novae/module/swav.py</code> <pre><code>def forward(self, z1: Tensor, z2: Tensor, slide_id: str | None) -&gt; tuple[Tensor, dict[str, Tensor]]:\n    \"\"\"Compute the SwAV loss for two batches of neighborhood graph views.\n\n    Args:\n        z1: Batch containing graphs representations `(B, output_size)`\n        z2: Batch containing graphs representations `(B, output_size)`\n\n    Returns:\n        The SwAV loss, and the mean entropy normalized (for monitoring).\n    \"\"\"\n    self.normalize_prototypes()\n\n    projections1 = self.projection(z1)  # (B, K)\n    projections2 = self.projection(z2)  # (B, K)\n\n    ilocs = self.prototype_ilocs(projections1, slide_id)\n\n    projections1, projections2 = projections1[:, ilocs], projections2[:, ilocs]\n\n    q1 = self.sinkhorn(projections1)  # (B, K) or (B, len(ilocs))\n    q2 = self.sinkhorn(projections2)  # (B, K) or (B, len(ilocs))\n\n    loss = -0.5 * (self.cross_entropy_loss(q1, projections2) + self.cross_entropy_loss(q2, projections1))\n\n    return loss, _mean_entropy_normalized(q1)\n</code></pre>"},{"location":"api/modules/#novae.module.SwavHead.hierarchical_clustering","title":"<code>hierarchical_clustering()</code>","text":"<p>Perform hierarchical clustering on the prototypes. Saves the full tree of clusters.</p> Source code in <code>novae/module/swav.py</code> <pre><code>def hierarchical_clustering(self) -&gt; None:\n    \"\"\"\n    Perform hierarchical clustering on the prototypes. Saves the full tree of clusters.\n    \"\"\"\n    X = self.prototypes.data.numpy(force=True)  # (K, O)\n\n    _clustering = AgglomerativeClustering(\n        n_clusters=None,\n        distance_threshold=0,\n        compute_full_tree=True,\n        metric=\"cosine\",\n        linkage=\"average\",\n    )\n    _clustering.fit(X)\n\n    _clusters_levels = np.zeros((len(X), len(X)), dtype=np.uint16)\n    _clusters_levels[0] = np.arange(len(X))\n\n    for i, (a, b) in enumerate(_clustering.children_):\n        clusters = _clusters_levels[i]\n        _clusters_levels[i + 1] = clusters\n        _clusters_levels[i + 1, np.where((clusters == a) | (clusters == b))] = len(X) + i\n\n    self.set_clustering(_clustering, _clusters_levels)\n</code></pre>"},{"location":"api/modules/#novae.module.SwavHead.init_queue","title":"<code>init_queue(slide_ids)</code>","text":"<p>Initialize the slide-queue.</p> <p>Parameters:</p> Name Type Description Default <code>slide_ids</code> <code>list[str]</code> <p>A list of slide ids.</p> required Source code in <code>novae/module/swav.py</code> <pre><code>def init_queue(self, slide_ids: list[str]) -&gt; None:\n    \"\"\"Initialize the slide-queue.\n\n    Args:\n        slide_ids: A list of slide ids.\n    \"\"\"\n    del self.queue\n\n    shape = (len(slide_ids), Nums.QUEUE_SIZE, self.num_prototypes)\n    self.register_buffer(\"queue\", torch.full(shape, 1 / self.num_prototypes))\n\n    self.slide_label_encoder = {slide_id: i for i, slide_id in enumerate(slide_ids)}\n</code></pre>"},{"location":"api/modules/#novae.module.SwavHead.map_leaves_domains","title":"<code>map_leaves_domains(series, level)</code>","text":"<p>Map leaves to the parent domain from the corresponding level of the hierarchical tree.</p> <p>Parameters:</p> Name Type Description Default <code>series</code> <code>Series</code> <p>Leaves classes</p> required <code>level</code> <code>int</code> <p>Level of the hierarchical clustering tree (or, number of clusters)</p> required <p>Returns:</p> Type Description <code>Series</code> <p>Series of classes.</p> Source code in <code>novae/module/swav.py</code> <pre><code>def map_leaves_domains(self, series: pd.Series, level: int) -&gt; pd.Series:\n    \"\"\"Map leaves to the parent domain from the corresponding level of the hierarchical tree.\n\n    Args:\n        series: Leaves classes\n        level: Level of the hierarchical clustering tree (or, number of clusters)\n\n    Returns:\n        Series of classes.\n    \"\"\"\n    return series.map(lambda x: f\"D{self.clusters_levels[-level, int(x[1:])]}\" if isinstance(x, str) else x)\n</code></pre>"},{"location":"api/modules/#novae.module.SwavHead.projection","title":"<code>projection(z)</code>","text":"<p>Compute the projection of the (normalized) representations over the prototypes.</p> <p>Parameters:</p> Name Type Description Default <code>z</code> <code>Tensor</code> <p>The representations of one batch, of size <code>(B, O)</code>.</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>The projections of size <code>(B, K)</code>.</p> Source code in <code>novae/module/swav.py</code> <pre><code>def projection(self, z: Tensor) -&gt; Tensor:\n    \"\"\"Compute the projection of the (normalized) representations over the prototypes.\n\n    Args:\n        z: The representations of one batch, of size `(B, O)`.\n\n    Returns:\n        The projections of size `(B, K)`.\n    \"\"\"\n    z_normalized = F.normalize(z, dim=1, p=2)\n    return z_normalized @ self.prototypes.T\n</code></pre>"},{"location":"api/modules/#novae.module.SwavHead.prototype_ilocs","title":"<code>prototype_ilocs(projections, slide_id=None)</code>","text":"<p>Get the indices of the prototypes to use for the current slide.</p> <p>Parameters:</p> Name Type Description Default <code>projections</code> <code>Tensor</code> <p>Projections of the (normalized) representations over the prototypes, of size <code>(B, K)</code>.</p> required <code>slide_id</code> <code>str | None</code> <p>ID of the slide, or <code>None</code>.</p> <code>None</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>The indices of the prototypes to use, or an <code>Ellipsis</code> if all prototypes.</p> Source code in <code>novae/module/swav.py</code> <pre><code>@torch.no_grad()\ndef prototype_ilocs(self, projections: Tensor, slide_id: str | None = None) -&gt; Tensor:\n    \"\"\"Get the indices of the prototypes to use for the current slide.\n\n    Args:\n        projections: Projections of the (normalized) representations over the prototypes, of size `(B, K)`.\n        slide_id: ID of the slide, or `None`.\n\n    Returns:\n        The indices of the prototypes to use, or an `Ellipsis` if all prototypes.\n    \"\"\"\n    if (self.queue is None) or (slide_id is None) or self.mode.zero_shot:\n        return ...\n\n    slide_index = self.slide_label_encoder[slide_id]\n\n    self.queue[slide_index, 1:] = self.queue[slide_index, :-1].clone()\n    self.queue[slide_index, 0] = projections.topk(3, dim=0).values[-1]  # top3 more robust than max\n\n    weights, thresholds = self.queue_weights()\n    slide_weights = weights[slide_index]\n\n    ilocs = torch.where(slide_weights &gt;= thresholds)[0]\n\n    if len(ilocs) &gt;= self.min_prototypes:\n        return ilocs\n\n    other_locs = torch.where(slide_weights &lt; thresholds)[0]\n    other_locs = other_locs[torch.topk(slide_weights[other_locs], self.min_prototypes - len(ilocs)).indices]\n\n    return torch.cat([ilocs, other_locs])\n</code></pre>"},{"location":"api/modules/#novae.module.SwavHead.queue_weights","title":"<code>queue_weights()</code>","text":"<p>Convert the queue to a matrix of prototype weight per slide.</p> <p>Returns:</p> Type Description <code>tuple[Tensor, Tensor]</code> <p>A tensor of shape <code>(n_slides, K)</code>, and a tensor of shape (K,).</p> Source code in <code>novae/module/swav.py</code> <pre><code>def queue_weights(self) -&gt; tuple[Tensor, Tensor]:\n    \"\"\"Convert the queue to a matrix of prototype weight per slide.\n\n    Returns:\n        A tensor of shape `(n_slides, K)`, and a tensor of shape (K,).\n    \"\"\"\n    max_projections = self.queue.max(dim=1).values\n\n    thresholds = max_projections.max(0).values * Nums.QUEUE_WEIGHT_THRESHOLD_RATIO\n    thresholds -= 1 - Nums.QUEUE_WEIGHT_THRESHOLD_RATIO  # ensure that for max-weights &lt; 0 are above the threshold\n\n    return max_projections, thresholds\n</code></pre>"},{"location":"api/modules/#novae.module.SwavHead.sinkhorn","title":"<code>sinkhorn(projections)</code>","text":"<p>Apply the Sinkhorn-Knopp algorithm to the projections.</p> <p>Parameters:</p> Name Type Description Default <code>projections</code> <code>Tensor</code> <p>Projections of the (normalized) representations over the prototypes, of size <code>(B, K)</code>.</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>The soft codes from the Sinkhorn-Knopp algorithm, with shape <code>(B, K)</code>.</p> Source code in <code>novae/module/swav.py</code> <pre><code>@torch.no_grad()\ndef sinkhorn(self, projections: Tensor) -&gt; Tensor:\n    \"\"\"Apply the Sinkhorn-Knopp algorithm to the projections.\n\n    Args:\n        projections: Projections of the (normalized) representations over the prototypes, of size `(B, K)`.\n\n    Returns:\n        The soft codes from the Sinkhorn-Knopp algorithm, with shape `(B, K)`.\n    \"\"\"\n    Q = torch.exp(projections / Nums.SWAV_EPSILON)  # (B, K)\n    Q /= torch.sum(Q)\n\n    B, K = Q.shape\n\n    for _ in range(Nums.SINKHORN_ITERATIONS):\n        Q /= torch.sum(Q, dim=0, keepdim=True)\n        Q /= K\n        Q /= torch.sum(Q, dim=1, keepdim=True)\n        Q /= B\n\n    return Q / Q.sum(dim=1, keepdim=True)  # ensure rows sum to 1 (for cross-entropy loss)\n</code></pre>"},{"location":"api/plot/","title":"Plotting","text":""},{"location":"api/plot/#novae.plot.domains","title":"<code>novae.plot.domains(adata, obs_key=None, slide_name_key=None, cell_size=None, ncols=4, fig_size_per_slide=(5, 5), na_color='#ccc', show=True, library_id=None, **kwargs)</code>","text":"<p>Show the Novae spatial domains for all slides in the <code>AnnData</code> object.</p> Info <p>Make sure you have already your Novae domains assigned to the <code>AnnData</code> object. You can use <code>model.assign_domains(...)</code> to do so.</p> <p>Parameters:</p> Name Type Description Default <code>adata</code> <code>AnnData | list[AnnData]</code> <p>An <code>AnnData</code> object, or a list of <code>AnnData</code> objects.</p> required <code>obs_key</code> <code>str | None</code> <p>Name of the key from <code>adata.obs</code> containing the Novae domains. By default, the last available domain key is shown.</p> <code>None</code> <code>slide_name_key</code> <code>str | None</code> <p>Key of <code>adata.obs</code> that contains the slide names. By default, uses the Novae unique slide ID.</p> <code>None</code> <code>cell_size</code> <code>int | None</code> <p>Size of the cells or spots. By default, it uses the median distance between neighbor cells.</p> <code>None</code> <code>ncols</code> <code>int</code> <p>Number of columns to be shown.</p> <code>4</code> <code>fig_size_per_slide</code> <code>tuple[int, int]</code> <p>Size of the figure for each slide.</p> <code>(5, 5)</code> <code>na_color</code> <code>str</code> <p>Color for cells that does not belong to any domain (i.e. cells with a too small neighborhood).</p> <code>'#ccc'</code> <code>show</code> <code>bool</code> <p>Whether to show the plot.</p> <code>True</code> <code>library_id</code> <code>str | None</code> <p><code>library_id</code> argument for <code>sc.pl.spatial</code>.</p> <code>None</code> <code>**kwargs</code> <code>int</code> <p>Additional arguments for <code>sc.pl.spatial</code>.</p> <code>{}</code> Source code in <code>novae/plot/_spatial.py</code> <pre><code>def domains(\n    adata: AnnData | list[AnnData],\n    obs_key: str | None = None,\n    slide_name_key: str | None = None,\n    cell_size: int | None = None,\n    ncols: int = 4,\n    fig_size_per_slide: tuple[int, int] = (5, 5),\n    na_color: str = \"#ccc\",\n    show: bool = True,\n    library_id: str | None = None,\n    **kwargs: int,\n):\n    \"\"\"Show the Novae spatial domains for all slides in the `AnnData` object.\n\n    Info:\n        Make sure you have already your Novae domains assigned to the `AnnData` object. You can use `model.assign_domains(...)` to do so.\n\n    Args:\n        adata: An `AnnData` object, or a list of `AnnData` objects.\n        obs_key: Name of the key from `adata.obs` containing the Novae domains. By default, the last available domain key is shown.\n        slide_name_key: Key of `adata.obs` that contains the slide names. By default, uses the Novae unique slide ID.\n        cell_size: Size of the cells or spots. By default, it uses the median distance between neighbor cells.\n        ncols: Number of columns to be shown.\n        fig_size_per_slide: Size of the figure for each slide.\n        na_color: Color for cells that does not belong to any domain (i.e. cells with a too small neighborhood).\n        show: Whether to show the plot.\n        library_id: `library_id` argument for `sc.pl.spatial`.\n        **kwargs: Additional arguments for `sc.pl.spatial`.\n    \"\"\"\n    if obs_key is not None:\n        assert str(obs_key).startswith(Keys.DOMAINS_PREFIX), f\"Received {obs_key=}, which is not a valid Novae obs_key\"\n\n    adatas = adata if isinstance(adata, list) else [adata]\n    slide_name_key = utils.check_slide_name_key(adatas, slide_name_key)\n    obs_key = utils.check_available_domains_key(adatas, obs_key)\n\n    for adata in adatas:\n        sanitize_anndata(adata)\n\n    all_domains, colors = get_categorical_color_palette(adatas, obs_key)\n    cell_size = cell_size or _get_default_cell_size(adata)\n\n    fig, axes = _subplots_per_slide(adatas, ncols, fig_size_per_slide)\n\n    for i, adata in enumerate(utils.iter_slides(adatas)):\n        ax = axes[i // ncols, i % ncols]\n        slide_name = adata.obs[slide_name_key].iloc[0]\n        assert len(np.unique(adata.obs[slide_name_key])) == 1\n\n        sc.pl.spatial(\n            adata,\n            spot_size=cell_size,\n            color=obs_key,\n            ax=ax,\n            show=False,\n            library_id=library_id,\n            **kwargs,\n        )\n        sns.despine(ax=ax, offset=10, trim=True)\n        ax.get_legend().remove()\n        ax.set_title(slide_name)\n\n    [fig.delaxes(ax) for ax in axes.flatten() if not ax.has_data()]  # remove unused subplots\n\n    title = f\"Novae domains ({obs_key})\"\n\n    if i == 0:\n        axes[0, 0].set_title(title)\n    else:\n        fig.suptitle(title, fontsize=14, y=1.15)\n\n    handles = [\n        Line2D([0], [0], marker=\"o\", color=\"w\", markerfacecolor=color, markersize=8, linestyle=\"None\")\n        for color in [*colors, na_color]\n    ]\n    fig.legend(\n        handles,\n        [*all_domains, \"NA\"],\n        loc=\"upper center\" if i &gt; 1 else \"center left\",\n        bbox_to_anchor=(0.5, 1.1) if i &gt; 1 else (1.04, 0.5),\n        borderaxespad=0,\n        frameon=False,\n        ncol=len(colors) // (3 if i &gt; 1 else 10) + 1,\n    )\n\n    if show:\n        plt.show()\n</code></pre>"},{"location":"api/plot/#novae.plot.domains_proportions","title":"<code>novae.plot.domains_proportions(adata, obs_key=None, slide_name_key=None, figsize=(2, 5), show=True)</code>","text":"<p>Show the proportion of each domain in the slide(s).</p> <p>Parameters:</p> Name Type Description Default <code>adata</code> <code>AnnData | list[AnnData]</code> <p>One <code>AnnData</code> object, or a list of <code>AnnData</code> objects.</p> required <code>obs_key</code> <code>str | None</code> <p>The key in <code>adata.obs</code> that contains the Novae domains. By default, the last available domain key is shown.</p> <code>None</code> <code>figsize</code> <code>tuple[int, int]</code> <p>Matplotlib figure size.</p> <code>(2, 5)</code> <code>show</code> <code>bool</code> <p>Whether to show the plot.</p> <code>True</code> Source code in <code>novae/plot/_bar.py</code> <pre><code>def domains_proportions(\n    adata: AnnData | list[AnnData],\n    obs_key: str | None = None,\n    slide_name_key: str | None = None,\n    figsize: tuple[int, int] = (2, 5),\n    show: bool = True,\n):\n    \"\"\"Show the proportion of each domain in the slide(s).\n\n    Args:\n        adata: One `AnnData` object, or a list of `AnnData` objects.\n        obs_key: The key in `adata.obs` that contains the Novae domains. By default, the last available domain key is shown.\n        figsize: Matplotlib figure size.\n        show: Whether to show the plot.\n    \"\"\"\n    adatas = [adata] if isinstance(adata, AnnData) else adata\n    slide_name_key = utils.check_slide_name_key(adatas, slide_name_key)\n    obs_key = utils.check_available_domains_key(adatas, obs_key)\n\n    all_domains, colors = get_categorical_color_palette(adatas, obs_key)\n\n    names, series = [], []\n    for adata_slide in utils.iter_slides(adatas):\n        names.append(adata_slide.obs[slide_name_key].iloc[0])\n        series.append(adata_slide.obs[obs_key].value_counts(normalize=True))\n\n    df = pd.concat(series, axis=1)\n    df.columns = names\n\n    df.T.plot(kind=\"bar\", stacked=True, figsize=figsize, color=dict(zip(all_domains, colors)))\n    sns.despine(offset=10, trim=True)\n    plt.legend(bbox_to_anchor=(1.04, 0.5), loc=\"center left\", borderaxespad=0, frameon=False)\n    plt.ylabel(\"Proportion\")\n    plt.xticks(rotation=90)\n\n    if show:\n        plt.show()\n</code></pre>"},{"location":"api/plot/#novae.plot.connectivities","title":"<code>novae.plot.connectivities(adata, ngh_threshold=2, cell_size=2, ncols=4, fig_size_per_slide=(5, 5), linewidths=0.1, line_color='#333', cmap='rocket', color_isolated_cells='orangered', show=True)</code>","text":"<p>Show the graph of the spatial connectivities between cells. By default, the cells which have a number of neighbors inferior to <code>ngh_threshold</code> are shown in red. If <code>ngh_threshold</code> is <code>None</code>, the cells are colored by the number of neighbors.</p> <p>Quality control</p> <p>This plot is useful to check the quality of the spatial connectivities obtained via novae.spatial_neighbors. Make sure few cells (e.g., less than 5%) have a number of neighbors below <code>ngh_threshold</code>. If too many cells are isolated, you may want to increase the <code>radius</code> parameter in novae.spatial_neighbors. Conversely, if there are some less that are really far from each other, but still connected, so may want to decrease the <code>radius</code> parameter to disconnect them.</p> <p>Parameters:</p> Name Type Description Default <code>adata</code> <code>AnnData</code> <p>An AnnData object.</p> required <code>ngh_threshold</code> <code>int | None</code> <p>Only cells with a number of neighbors below this threshold are shown (with color <code>color_isolated_cells</code>). If <code>None</code>, cells are colored by the number of neighbors.</p> <code>2</code> <code>cell_size</code> <code>int</code> <p>Size of the dots for each cell. By default, it uses the median distance between neighbor cells.</p> <code>2</code> <code>ncols</code> <code>int</code> <p>Number of columns to be shown.</p> <code>4</code> <code>fig_size_per_slide</code> <code>tuple[int, int]</code> <p>Size of the figure for each slide.</p> <code>(5, 5)</code> <code>linewidths</code> <code>float</code> <p>Width of the lines/edges connecting the cells.</p> <code>0.1</code> <code>line_color</code> <code>str</code> <p>Color of the lines/edges.</p> <code>'#333'</code> <code>cmap</code> <code>str</code> <p>Name of the colormap to use for the number of neighbors.</p> <code>'rocket'</code> <code>color_isolated_cells</code> <code>str</code> <p>Color for the cells with a number of neighbors below <code>ngh_threshold</code> (if not <code>None</code>).</p> <code>'orangered'</code> <code>show</code> <code>bool</code> <p>Whether to show the plot.</p> <code>True</code> Source code in <code>novae/plot/_graph.py</code> <pre><code>def connectivities(\n    adata: AnnData,\n    ngh_threshold: int | None = 2,\n    cell_size: int = 2,\n    ncols: int = 4,\n    fig_size_per_slide: tuple[int, int] = (5, 5),\n    linewidths: float = 0.1,\n    line_color: str = \"#333\",\n    cmap: str = \"rocket\",\n    color_isolated_cells: str = \"orangered\",\n    show: bool = True,\n):\n    \"\"\"Show the graph of the spatial connectivities between cells. By default,\n    the cells which have a number of neighbors inferior to `ngh_threshold` are shown\n    in red. If `ngh_threshold` is `None`, the cells are colored by the number of neighbors.\n\n    !!! info \"Quality control\"\n        This plot is useful to check the quality of the spatial connectivities obtained via [novae.spatial_neighbors][].\n        Make sure few cells (e.g., less than 5%) have a number of neighbors below `ngh_threshold`.\n        If too many cells are isolated, you may want to increase the `radius` parameter in [novae.spatial_neighbors][].\n        Conversely, if there are some less that are really **far from each other**, but still connected, so may want to decrease the `radius` parameter to **disconnect** them.\n\n    Args:\n        adata: An AnnData object.\n        ngh_threshold: Only cells with a number of neighbors below this threshold are shown (with color `color_isolated_cells`). If `None`, cells are colored by the number of neighbors.\n        cell_size: Size of the dots for each cell. By default, it uses the median distance between neighbor cells.\n        ncols: Number of columns to be shown.\n        fig_size_per_slide: Size of the figure for each slide.\n        linewidths: Width of the lines/edges connecting the cells.\n        line_color: Color of the lines/edges.\n        cmap: Name of the colormap to use for the number of neighbors.\n        color_isolated_cells: Color for the cells with a number of neighbors below `ngh_threshold` (if not `None`).\n        show: Whether to show the plot.\n    \"\"\"\n    adatas = [adata] if isinstance(adata, AnnData) else adata\n\n    fig, axes = _subplots_per_slide(adatas, ncols, fig_size_per_slide)\n\n    for i, adata in enumerate(utils.iter_slides(adatas)):\n        ax = axes[i // ncols, i % ncols]\n\n        utils.check_has_spatial_adjancency(adata)\n\n        X, A = adata.obsm[\"spatial\"], adata.obsp[Keys.ADJ]\n\n        ax.invert_yaxis()\n        ax.axes.set_aspect(\"equal\")\n\n        rows, cols = A.nonzero()\n        mask = rows &lt; cols\n        rows, cols = rows[mask], cols[mask]\n        edge_segments = np.stack([X[rows], X[cols]], axis=1)\n        edges = LineCollection(edge_segments, color=line_color, linewidths=linewidths, zorder=1)\n        ax.add_collection(edges)\n\n        n_neighbors = (A &gt; 0).sum(1).A1\n\n        if ngh_threshold is None:\n            _ = ax.scatter(X[:, 0], X[:, 1], c=n_neighbors, s=cell_size, zorder=2, cmap=cmap)\n            plt.colorbar(_, ax=ax)\n        else:\n            isolated_cells = n_neighbors &lt; ngh_threshold\n            ax.scatter(X[isolated_cells, 0], X[isolated_cells, 1], color=color_isolated_cells, s=cell_size, zorder=2)\n\n        ax.set_title(adata.obs[Keys.SLIDE_ID].iloc[0])\n\n    [fig.delaxes(ax) for ax in axes.flatten() if not ax.has_data()]  # remove unused subplots\n\n    title = \"Node connectivities\" + (f\" (threshold={ngh_threshold} neighbors)\" if ngh_threshold is not None else \"\")\n\n    if i == 0:\n        axes[0, 0].set_title(title)\n    else:\n        fig.suptitle(title, fontsize=14)\n\n    if show:\n        plt.show()\n</code></pre>"},{"location":"api/plot/#novae.plot.pathway_scores","title":"<code>novae.plot.pathway_scores(adata, pathways, obs_key=None, pathway_name=None, slide_name_key=None, return_df=False, figsize=(10, 5), min_pathway_size=4, show=True, **kwargs)</code>","text":"<p>Show a heatmap of either (i) the score of multiple pathways for each domain, or (ii) one pathway score for each domain and for each slide. To use the latter case, provide <code>pathway_name</code>, or make sure to have only one pathway in <code>pathways</code>.</p> Info <p>Currently, this function only supports one AnnData object per call.</p> <p>Parameters:</p> Name Type Description Default <code>adata</code> <code>AnnData</code> <p>An <code>AnnData</code> object.</p> required <code>pathways</code> <code>dict[str, list[str]] | str</code> <p>Either a dictionary of pathways (keys are pathway names, values are lists of gene names), or a path to a GSEA JSON file.</p> required <code>obs_key</code> <code>str | None</code> <p>Key in <code>adata.obs</code> that contains the domains. By default, it will use the last available Novae domain key.</p> <code>None</code> <code>pathway_name</code> <code>str | None</code> <p>If <code>None</code>, all pathways will be shown (first mode). If not <code>None</code>, this specific pathway will be shown, for all domains and all slides (second mode).</p> <code>None</code> <code>slide_name_key</code> <code>str | None</code> <p>Key of <code>adata.obs</code> that contains the slide names. By default, uses the Novae unique slide ID.</p> <code>None</code> <code>return_df</code> <code>bool</code> <p>Whether to return the DataFrame.</p> <code>False</code> <code>figsize</code> <code>tuple[int, int]</code> <p>Matplotlib figure size.</p> <code>(10, 5)</code> <code>min_pathway_size</code> <code>int</code> <p>Minimum number of known genes in the pathway to be considered.</p> <code>4</code> <code>show</code> <code>bool</code> <p>Whether to show the plot.</p> <code>True</code> <p>Returns:</p> Type Description <code>DataFrame | None</code> <p>A DataFrame of scores per domain if <code>return_df</code> is True.</p> Source code in <code>novae/plot/_heatmap.py</code> <pre><code>def pathway_scores(\n    adata: AnnData,\n    pathways: dict[str, list[str]] | str,\n    obs_key: str | None = None,\n    pathway_name: str | None = None,\n    slide_name_key: str | None = None,\n    return_df: bool = False,\n    figsize: tuple[int, int] = (10, 5),\n    min_pathway_size: int = 4,\n    show: bool = True,\n    **kwargs: int,\n) -&gt; pd.DataFrame | None:\n    \"\"\"Show a heatmap of either (i) the score of multiple pathways for each domain, or (ii) one pathway score for each domain and for each slide.\n    To use the latter case, provide `pathway_name`, or make sure to have only one pathway in `pathways`.\n\n    Info:\n        Currently, this function only supports one AnnData object per call.\n\n    Args:\n        adata: An `AnnData` object.\n        pathways: Either a dictionary of pathways (keys are pathway names, values are lists of gene names), or a path to a [GSEA](https://www.gsea-msigdb.org/gsea/msigdb/index.jsp) JSON file.\n        obs_key: Key in `adata.obs` that contains the domains. By default, it will use the last available Novae domain key.\n        pathway_name: If `None`, all pathways will be shown (first mode). If not `None`, this specific pathway will be shown, for all domains and all slides (second mode).\n        slide_name_key: Key of `adata.obs` that contains the slide names. By default, uses the Novae unique slide ID.\n        return_df: Whether to return the DataFrame.\n        figsize: Matplotlib figure size.\n        min_pathway_size: Minimum number of known genes in the pathway to be considered.\n        show: Whether to show the plot.\n\n    Returns:\n        A DataFrame of scores per domain if `return_df` is True.\n    \"\"\"\n    assert isinstance(adata, AnnData), f\"For now, only one AnnData object is supported, received {type(adata)}\"\n\n    obs_key = utils.check_available_domains_key([adata], obs_key)\n\n    if isinstance(pathways, str):\n        pathways = _load_gsea_json(pathways)\n        log.info(f\"Loaded {len(pathways)} pathway(s)\")\n\n    if len(pathways) == 1:\n        pathway_name = next(iter(pathways.keys()))\n\n    if pathway_name is not None:\n        gene_names = pathways[pathway_name]\n        is_valid = _get_pathway_score(adata, gene_names, min_pathway_size)\n        assert is_valid, f\"Pathway '{pathway_name}' has less than {min_pathway_size} genes in the dataset.\"\n    else:\n        scores = {}\n\n        for key, gene_names in pathways.items():\n            is_valid = _get_pathway_score(adata, gene_names, min_pathway_size)\n            if is_valid:\n                scores[key] = adata.obs[TEMP_KEY]\n\n    if pathway_name is not None:\n        log.info(f\"Plot mode: {pathway_name} score per domain per slide\")\n\n        slide_name_key = utils.check_slide_name_key(adata, slide_name_key)\n\n        df = adata.obs.groupby([obs_key, slide_name_key], observed=True)[TEMP_KEY].mean().unstack()\n        df.columns.name = slide_name_key\n\n        assert len(df) &gt; 1, f\"Found {len(df)} valid slide. Minimum 2 required.\"\n    else:\n        log.info(f\"Plot mode: {len(scores)} pathways scores per domain\")\n\n        assert len(scores) &gt; 1, f\"Found {len(scores)} valid pathway. Minimum 2 required.\"\n\n        df = pd.DataFrame(scores)\n        df[obs_key] = adata.obs[obs_key]\n        df = df.groupby(obs_key, observed=True).mean()\n        df.columns.name = \"Pathways\"\n\n    del adata.obs[TEMP_KEY]\n\n    df = df.fillna(0)\n\n    g = sns.clustermap(df, figsize=figsize, **kwargs)\n    plt.setp(g.ax_heatmap.yaxis.get_majorticklabels(), rotation=0)\n\n    if show:\n        plt.show()\n\n    if return_df:\n        return df\n</code></pre>"},{"location":"api/plot/#novae.plot.paga","title":"<code>novae.plot.paga(adata, obs_key=None, show=True, **paga_plot_kwargs)</code>","text":"<p>Plot a PAGA graph.</p> Info <p>Currently, this function only supports one slide per call.</p> <p>Parameters:</p> Name Type Description Default <code>adata</code> <code>AnnData</code> <p>An AnnData object.</p> required <code>obs_key</code> <code>str | None</code> <p>Name of the key from <code>adata.obs</code> containing the Novae domains. By default, the last available domain key is shown.</p> <code>None</code> <code>show</code> <code>bool</code> <p>Whether to show the plot.</p> <code>True</code> <code>**paga_plot_kwargs</code> <code>int</code> <p>Additional arguments for <code>sc.pl.paga</code>.</p> <code>{}</code> Source code in <code>novae/plot/_graph.py</code> <pre><code>def paga(adata: AnnData, obs_key: str | None = None, show: bool = True, **paga_plot_kwargs: int):\n    \"\"\"Plot a PAGA graph.\n\n    Info:\n        Currently, this function only supports one slide per call.\n\n    Args:\n        adata: An AnnData object.\n        obs_key: Name of the key from `adata.obs` containing the Novae domains. By default, the last available domain key is shown.\n        show: Whether to show the plot.\n        **paga_plot_kwargs: Additional arguments for `sc.pl.paga`.\n    \"\"\"\n    assert isinstance(adata, AnnData), f\"For now, only AnnData objects are supported, received {type(adata)}\"\n\n    obs_key = utils.check_available_domains_key([adata], obs_key)\n\n    get_categorical_color_palette([adata], obs_key)\n\n    adata_clean = adata[~adata.obs[obs_key].isna()]\n\n    if \"paga\" not in adata.uns or adata.uns[\"paga\"][\"groups\"] != obs_key:\n        sc.pp.neighbors(adata_clean, use_rep=Keys.REPR)\n        sc.tl.paga(adata_clean, groups=obs_key)\n\n        adata.uns[\"paga\"] = adata_clean.uns[\"paga\"]\n        adata.uns[f\"{obs_key}_sizes\"] = adata_clean.uns[f\"{obs_key}_sizes\"]\n\n    sc.pl.paga(adata_clean, title=f\"PAGA graph ({obs_key})\", show=False, **paga_plot_kwargs)\n    sns.despine(offset=10, trim=True, bottom=True)\n\n    if show:\n        plt.show()\n</code></pre>"},{"location":"api/plot/#novae.plot.spatially_variable_genes","title":"<code>novae.plot.spatially_variable_genes(adata, obs_key=None, top_k=5, cell_size=None, min_positive_ratio=0.05, return_list=False, show=True, **kwargs)</code>","text":"<p>Plot the most spatially variable genes (SVG) for a given <code>AnnData</code> object.</p> <p>Info</p> <p>Currently, this function only supports one slide per call.</p> <p>Parameters:</p> Name Type Description Default <code>adata</code> <code>AnnData</code> <p>An <code>AnnData</code> object corresponding to one slide.</p> required <code>obs_key</code> <code>str | None</code> <p>Key in <code>adata.obs</code> that contains the domains. By default, it will use the last available Novae domain key.</p> <code>None</code> <code>top_k</code> <code>int</code> <p>Number of SVG to be shown.</p> <code>5</code> <code>cell_size</code> <code>int | None</code> <p>Size of the cells or spots (<code>spot_size</code> argument of <code>sc.pl.spatial</code>). By default, it uses the median distance between neighbor cells.</p> <code>None</code> <code>min_positive_ratio</code> <code>float</code> <p>Genes whose \"ratio of cells expressing it\" is lower than this threshold are not considered.</p> <code>0.05</code> <code>return_list</code> <code>bool</code> <p>Whether to return the list of SVG instead of plotting them.</p> <code>False</code> <code>show</code> <code>bool</code> <p>Whether to show the plot.</p> <code>True</code> <code>**kwargs</code> <code>int</code> <p>Additional arguments for <code>sc.pl.spatial</code>.</p> <code>{}</code> <p>Returns:</p> Type Description <code>None | list[str]</code> <p>A list of SVG names if <code>return_list</code> is <code>True</code>.</p> Source code in <code>novae/plot/_spatial.py</code> <pre><code>def spatially_variable_genes(\n    adata: AnnData,\n    obs_key: str | None = None,\n    top_k: int = 5,\n    cell_size: int | None = None,\n    min_positive_ratio: float = 0.05,\n    return_list: bool = False,\n    show: bool = True,\n    **kwargs: int,\n) -&gt; None | list[str]:\n    \"\"\"Plot the most spatially variable genes (SVG) for a given `AnnData` object.\n\n    !!! info\n        Currently, this function only supports one slide per call.\n\n    Args:\n        adata: An `AnnData` object corresponding to one slide.\n        obs_key: Key in `adata.obs` that contains the domains. By default, it will use the last available Novae domain key.\n        top_k: Number of SVG to be shown.\n        cell_size: Size of the cells or spots (`spot_size` argument of `sc.pl.spatial`). By default, it uses the median distance between neighbor cells.\n        min_positive_ratio: Genes whose \"ratio of cells expressing it\" is lower than this threshold are not considered.\n        return_list: Whether to return the list of SVG instead of plotting them.\n        show: Whether to show the plot.\n        **kwargs: Additional arguments for `sc.pl.spatial`.\n\n    Returns:\n        A list of SVG names if `return_list` is `True`.\n    \"\"\"\n    assert isinstance(adata, AnnData), f\"Received adata of type {type(adata)}. Currently only AnnData is supported.\"\n\n    obs_key = utils.check_available_domains_key([adata], obs_key)\n\n    sc.tl.rank_genes_groups(adata, groupby=obs_key)\n    df = pd.concat(\n        [\n            sc.get.rank_genes_groups_df(adata, domain).set_index(\"names\")[\"logfoldchanges\"]\n            for domain in adata.obs[obs_key].cat.categories\n        ],\n        axis=1,\n    )\n\n    where = (adata.X &gt; 0).mean(0) &gt; min_positive_ratio\n    valid_vars = adata.var_names[where.A1 if isinstance(where, np.matrix) else where]\n    assert len(valid_vars) &gt;= top_k, (\n        f\"Only {len(valid_vars)} genes are available. Please decrease `top_k` or `min_positive_ratio`.\"\n    )\n\n    svg = df.std(1).loc[valid_vars].sort_values(ascending=False).head(top_k).index\n\n    if return_list:\n        return svg.tolist()\n\n    sc.pl.spatial(adata, color=svg, spot_size=cell_size or _get_default_cell_size(adata), show=show, **kwargs)\n</code></pre>"},{"location":"api/plot/#novae.plot.loss_curve","title":"<code>novae.plot.loss_curve(log_dir, version=-1, on_epoch=False, **kwargs)</code>","text":"<p>Plot the training loss curve from the CSV logs. This is a basic alternative for monitoring training when Weights &amp; Biases can't be used.</p> <p>Info</p> <p>To use this function, you need to fit or fine_tune Novae with a CSVLogger, for example: <pre><code>from lightning.pytorch.loggers import CSVLogger\n\n# save the logs in a directory called \"logs\"\nmodel.fine_tune(logger=CSVLogger(\"logs\"), log_every_n_steps=10)\n\nnovae.plot.loss_curve(\"logs\")\n</code></pre></p> <p>Parameters:</p> Name Type Description Default <code>log_dir</code> <code>str</code> <p>The name of the directory containing the CSVLogger logs.</p> required <code>version</code> <code>int</code> <p>Version of the run. By default, searches for the latest run.</p> <code>-1</code> <code>on_epoch</code> <code>bool</code> <p>Whether to show the loss per epoch or per step.</p> <code>False</code> <code>**kwargs</code> <code>int</code> <p>Additional keyword arguments passed to <code>seaborn.lineplot</code>.</p> <code>{}</code> Source code in <code>novae/plot/_line.py</code> <pre><code>def loss_curve(log_dir: str, version: int = -1, on_epoch: bool = False, **kwargs: int) -&gt; None:\n    \"\"\"Plot the training loss curve from the CSV logs. This is a basic alternative for monitoring training when Weights &amp; Biases can't be used.\n\n    !!! info\n        To use this function, you need to fit or fine_tune Novae with a CSVLogger, for example:\n        ```python\n        from lightning.pytorch.loggers import CSVLogger\n\n        # save the logs in a directory called \"logs\"\n        model.fine_tune(logger=CSVLogger(\"logs\"), log_every_n_steps=10)\n\n        novae.plot.loss_curve(\"logs\")\n        ```\n\n    Args:\n        log_dir: The name of the directory containing the CSVLogger logs.\n        version: Version of the run. By default, searches for the latest run.\n        on_epoch: Whether to show the loss per epoch or per step.\n        **kwargs: Additional keyword arguments passed to `seaborn.lineplot`.\n    \"\"\"\n    log_dir: Path = Path(log_dir) / \"lightning_logs\"\n\n    if version == -1:\n        version = max(int(d.name.split(\"_\")[-1]) for d in log_dir.iterdir() if d.is_dir())\n\n    df = pd.read_csv(log_dir / f\"version_{version}\" / \"metrics.csv\")\n\n    x = \"epoch\" if on_epoch else \"step\"\n    y = f\"train/loss_{x}\"\n\n    sns.lineplot(df[[x, y]].dropna(), x=x, y=y, **kwargs)\n    sns.despine(offset=10, trim=True)\n</code></pre>"},{"location":"api/utils/","title":"Utils","text":""},{"location":"api/utils/#novae.spatial_neighbors","title":"<code>novae.spatial_neighbors(adata, slide_key=None, radius=None, pixel_size=None, technology=None, coord_type=None, n_neighs=None, delaunay=None, n_rings=1, percentile=None, set_diag=False, reset_slide_ids=True)</code>","text":"<p>Create a Delaunay graph from the spatial coordinates of the cells. The graph is stored in <code>adata.obsp['spatial_connectivities']</code> and <code>adata.obsp['spatial_distances']</code>. The long edges are removed from the graph according to the <code>radius</code> argument (if provided).</p> Info <p>This function was updated from squidpy.</p> <p>Parameters:</p> Name Type Description Default <code>adata</code> <code>AnnData | list[AnnData]</code> <p>An <code>AnnData</code> object, or a list of <code>AnnData</code> objects.</p> required <code>slide_key</code> <code>str | None</code> <p>Optional key in <code>adata.obs</code> indicating the slide ID of each cell. If provided, the graph is computed for each slide separately.</p> <code>None</code> <code>radius</code> <code>tuple[float, float] | float | None</code> <p><code>tuple</code> that prunes the final graph to only contain edges in interval <code>[min(radius), max(radius)]</code>. If <code>float</code>, uses <code>[0, radius]</code>. If <code>None</code>, all edges are kept.</p> <code>None</code> <code>technology</code> <code>str | SpatialTechnology | None</code> <p>Technology or machine used to generate the spatial data. One of <code>\"cosmx\", \"merscope\", \"xenium\", \"visium\", \"visium_hd\"</code>. If <code>None</code>, uses <code>adata.obsm[\"spatial\"]</code>.</p> <code>None</code> <code>coord_type</code> <code>str | CoordType | None</code> <p>Either <code>\"grid\"</code> or <code>\"generic\"</code>. If <code>\"grid\"</code>, the graph is built on a grid. If <code>\"generic\"</code>, the graph is built using the coordinates as they are. By default, uses <code>\"grid\"</code> for Visium/VisiumHD and <code>\"generic\"</code> for other technologies.</p> <code>None</code> <code>n_neighs</code> <code>int | None</code> <p>Number of neighbors to consider. If <code>None</code>, uses <code>6</code> for Visium, <code>4</code> for Visium HD, and <code>None</code> for generic graphs.</p> <code>None</code> <code>delaunay</code> <code>bool | None</code> <p>Whether to use Delaunay triangulation to build the graph. If <code>None</code>, uses <code>False</code> for grid-based graphs and <code>True</code> for generic graphs.</p> <code>None</code> <code>n_rings</code> <code>int</code> <p>See <code>squidpy.gr.spatial_neighbors</code> documentation.</p> <code>1</code> <code>percentile</code> <code>float | None</code> <p>See <code>squidpy.gr.spatial_neighbors</code> documentation.</p> <code>None</code> <code>set_diag</code> <code>bool</code> <p>See <code>squidpy.gr.spatial_neighbors</code> documentation.</p> <code>False</code> <code>reset_slide_ids</code> <code>bool</code> <p>Whether to reset the novae slide ids.</p> <code>True</code> Source code in <code>novae/utils/build.py</code> <pre><code>def spatial_neighbors(\n    adata: AnnData | list[AnnData],\n    slide_key: str | None = None,\n    radius: tuple[float, float] | float | None = None,\n    pixel_size: float | None = None,\n    technology: str | SpatialTechnology | None = None,\n    coord_type: str | CoordType | None = None,\n    n_neighs: int | None = None,\n    delaunay: bool | None = None,\n    n_rings: int = 1,\n    percentile: float | None = None,\n    set_diag: bool = False,\n    reset_slide_ids: bool = True,\n):\n    \"\"\"Create a Delaunay graph from the spatial coordinates of the cells.\n    The graph is stored in `adata.obsp['spatial_connectivities']` and `adata.obsp['spatial_distances']`. The long edges\n    are removed from the graph according to the `radius` argument (if provided).\n\n    Info:\n        This function was updated from [squidpy](https://squidpy.readthedocs.io/en/latest/api/squidpy.gr.spatial_neighbors.html#squidpy.gr.spatial_neighbors).\n\n    Args:\n        adata: An `AnnData` object, or a list of `AnnData` objects.\n        slide_key: Optional key in `adata.obs` indicating the slide ID of each cell. If provided, the graph is computed for each slide separately.\n        radius: `tuple` that prunes the final graph to only contain edges in interval `[min(radius), max(radius)]`. If `float`, uses `[0, radius]`. If `None`, all edges are kept.\n        technology: Technology or machine used to generate the spatial data. One of `\"cosmx\", \"merscope\", \"xenium\", \"visium\", \"visium_hd\"`. If `None`, uses `adata.obsm[\"spatial\"]`.\n        coord_type: Either `\"grid\"` or `\"generic\"`. If `\"grid\"`, the graph is built on a grid. If `\"generic\"`, the graph is built using the coordinates as they are. By default, uses `\"grid\"` for Visium/VisiumHD and `\"generic\"` for other technologies.\n        n_neighs: Number of neighbors to consider. If `None`, uses `6` for Visium, `4` for Visium HD, and `None` for generic graphs.\n        delaunay: Whether to use Delaunay triangulation to build the graph. If `None`, uses `False` for grid-based graphs and `True` for generic graphs.\n        n_rings: See `squidpy.gr.spatial_neighbors` documentation.\n        percentile: See `squidpy.gr.spatial_neighbors` documentation.\n        set_diag: See `squidpy.gr.spatial_neighbors` documentation.\n        reset_slide_ids: Whether to reset the novae slide ids.\n    \"\"\"\n    if reset_slide_ids:\n        _set_unique_slide_ids(adata, slide_key=slide_key)\n\n    if isinstance(adata, list):\n        for adata_ in adata:\n            spatial_neighbors(\n                adata_,\n                slide_key=slide_key,\n                radius=radius,\n                pixel_size=pixel_size,\n                technology=technology,\n                coord_type=coord_type,\n                n_neighs=n_neighs,\n                delaunay=delaunay,\n                n_rings=n_rings,\n                percentile=percentile,\n                set_diag=set_diag,\n                reset_slide_ids=False,\n            )\n        return\n\n    if isinstance(radius, (float, int)):\n        radius = [0.0, float(radius)]\n\n    assert radius is None or len(radius) == 2, \"Radius is expected to be a tuple (min_radius, max_radius)\"\n\n    assert pixel_size is None or technology is None, \"You must choose argument between `pixel_size` and `technology`\"\n\n    if technology == \"visium\":\n        n_neighs = 6 if n_neighs is None else n_neighs\n        coord_type, delaunay = CoordType.GRID, False\n    elif technology == \"visium_hd\":\n        n_neighs = 8 if n_neighs is None else n_neighs\n        coord_type, delaunay = CoordType.GRID, False\n    elif technology is not None:\n        adata.obsm[\"spatial\"] = _technology_coords(adata, technology)\n\n    assert \"spatial\" in adata.obsm, (\n        \"Key 'spatial' not found in adata.obsm. This should contain the 2D spatial coordinates of the cells\"\n    )\n\n    coord_type = CoordType(coord_type or \"generic\")\n    delaunay = True if delaunay is None else delaunay\n    n_neighs = 6 if (n_neighs is None and not delaunay) else n_neighs\n\n    log.info(\n        f\"Computing graph on {adata.n_obs:,} cells (coord_type={coord_type.value}, {delaunay=}, {radius=}, {n_neighs=})\"\n    )\n\n    slides = adata.obs[Keys.SLIDE_ID].cat.categories\n    make_index_unique(adata.obs_names)\n\n    _build_fun = partial(\n        _spatial_neighbor,\n        coord_type=coord_type,\n        n_neighs=n_neighs,\n        radius=radius,\n        delaunay=delaunay,\n        n_rings=n_rings,\n        set_diag=set_diag,\n        percentile=percentile,\n    )\n\n    if len(slides) &gt; 1:\n        mats: list[tuple[spmatrix, spmatrix]] = []\n        ixs = []  # type: ignore[var-annotated]\n        for slide in slides:\n            ixs.extend(np.where(adata.obs[Keys.SLIDE_ID] == slide)[0])\n            mats.append(_build_fun(adata[adata.obs[Keys.SLIDE_ID] == slide]))\n        ixs = np.argsort(ixs)  # type: ignore[assignment] # invert\n        Adj = block_diag([m[0] for m in mats], format=\"csr\")[ixs, :][:, ixs]\n        Dst = block_diag([m[1] for m in mats], format=\"csr\")[ixs, :][:, ixs]\n    else:\n        Adj, Dst = _build_fun(adata)\n\n    adata.obsp[\"spatial_connectivities\"] = Adj\n    adata.obsp[\"spatial_distances\"] = Dst\n\n    adata.uns[\"spatial_neighbors\"] = {\n        \"connectivities_key\": \"spatial_connectivities\",\n        \"distances_key\": \"spatial_distances\",\n        \"params\": {\"radius\": radius, \"set_diag\": set_diag, \"n_neighbors\": n_neighs, \"coord_type\": coord_type.value},\n    }\n\n    _sanity_check_spatial_neighbors(adata)\n</code></pre>"},{"location":"api/utils/#novae.batch_effect_correction","title":"<code>novae.batch_effect_correction(adatas, obs_key)</code>","text":"Source code in <code>novae/utils/correct.py</code> <pre><code>def batch_effect_correction(adatas: list[AnnData], obs_key: str) -&gt; None:\n    for adata in adatas:\n        assert obs_key in adata.obs, f\"Did not found `adata.obs['{obs_key}']`\"\n        assert Keys.REPR in adata.obsm, (\n            f\"Did not found `adata.obsm['{Keys.REPR}']`. Please run `model.compute_representations(...)` first\"\n        )\n\n    adata_indices, slides_obs_indices = _slides_indices(adatas)\n\n    domains_counts_per_slide = _domains_counts_per_slide(adatas, obs_key)\n    domains = domains_counts_per_slide.columns[:-1]\n    ref_slide_ids: pd.Series = domains_counts_per_slide[domains].idxmax(axis=0)\n\n    def _centroid_reference(domain: str, slide_id: str, obs_key: str):\n        adata_ref_index: int = domains_counts_per_slide[Keys.ADATA_INDEX].loc[slide_id]\n        adata_ref = adatas[adata_ref_index]\n        where = (adata_ref.obs[Keys.SLIDE_ID] == slide_id) &amp; (adata_ref.obs[obs_key] == domain)\n        return adata_ref.obsm[Keys.REPR][where].mean(0)\n\n    centroids_reference = pd.DataFrame({\n        domain: _centroid_reference(domain, slide_id, obs_key) for domain, slide_id in ref_slide_ids.items()\n    })\n\n    for adata in adatas:\n        adata.obsm[Keys.REPR_CORRECTED] = adata.obsm[Keys.REPR].copy()\n\n    for adata_index, obs_indices in zip(adata_indices, slides_obs_indices):\n        adata = adatas[adata_index]\n\n        for domain in domains:\n            if adata.obs[Keys.SLIDE_ID].iloc[obs_indices[0]] == ref_slide_ids.loc[domain]:\n                continue  # reference for this domain\n\n            indices_domain = obs_indices[adata.obs.iloc[obs_indices][obs_key] == domain]\n            if len(indices_domain) == 0:\n                continue\n\n            centroid_reference = centroids_reference[domain].values\n            centroid = adata.obsm[Keys.REPR][indices_domain].mean(0)\n\n            adata.obsm[Keys.REPR_CORRECTED][indices_domain] += centroid_reference - centroid\n</code></pre>"},{"location":"api/utils/#novae.utils.prepare_adatas","title":"<code>novae.utils.prepare_adatas(adata, var_names=None)</code>","text":"<p>Ensure the AnnData objects are ready to be used by the model.</p> Note <p>It performs the following operations:</p> <ul> <li>Preprocess the data if needed (e.g. normalize, log1p), in which case raw counts are saved in <code>adata.layers['counts']</code></li> <li>Compute the mean and std of each gene</li> <li>Save which genes are highly variable, in case the number of genes is too high</li> <li>If using a pretrained model, save which genes are known by the model</li> </ul> <p>Parameters:</p> Name Type Description Default <code>adata</code> <code>AnnData | list[AnnData] | None</code> <p>An <code>AnnData</code> object, or a list of <code>AnnData</code> objects. Optional if the model was initialized with <code>adata</code>.</p> required <code>var_names</code> <code>set | list[str] | None</code> <p>Only used when loading a pretrained model, or to select a subset of vars to use.</p> <code>None</code> <p>Returns:</p> Type Description <code>tuple[list[AnnData], list[str]]</code> <p>A list of <code>AnnData</code> objects ready to be used by the model. If only one <code>adata</code> object is provided, it will be wrapped in a list.</p> Source code in <code>novae/utils/_validate.py</code> <pre><code>def prepare_adatas(\n    adata: AnnData | list[AnnData] | None,\n    var_names: set | list[str] | None = None,\n) -&gt; tuple[list[AnnData], list[str]]:\n    \"\"\"Ensure the AnnData objects are ready to be used by the model.\n\n    Note:\n        It performs the following operations:\n\n        - Preprocess the data if needed (e.g. normalize, log1p), in which case raw counts are saved in `adata.layers['counts']`\n        - Compute the mean and std of each gene\n        - Save which genes are highly variable, in case the number of genes is too high\n        - If using a pretrained model, save which genes are known by the model\n\n    Args:\n        adata: An `AnnData` object, or a list of `AnnData` objects. Optional if the model was initialized with `adata`.\n        var_names: Only used when loading a pretrained model, or to select a subset of vars to use.\n\n    Returns:\n        A list of `AnnData` objects ready to be used by the model. If only one `adata` object is provided, it will be wrapped in a list.\n    \"\"\"\n    assert adata is not None or var_names is not None, \"One of `adata` and `var_names` must not be None\"\n    var_names = lower_var_names(var_names) if var_names is not None else None\n\n    if adata is None:\n        return None, var_names\n\n    if isinstance(adata, AnnData):\n        adatas = [adata]\n    elif isinstance(adata, list):\n        adatas = adata\n    else:\n        raise TypeError(f\"Invalid type for `adata`: {type(adata)}\")\n\n    assert len(adatas) &gt; 0, \"No `adata` object found. Please provide an AnnData object, or a list of AnnData objects.\"\n\n    assert all(Keys.ADJ in adata.obsp for adata in adatas), (\n        \"You need to first run `novae.spatial_neighbors` to compute cell neighbors.\"\n    )\n\n    _check_has_slide_id(adatas)\n    _standardize_adatas(adatas)  # log1p + spatial_neighbors\n\n    if settings.auto_preprocessing:\n        _lookup_highly_variable_genes(adatas)\n    if not settings.disable_multimodal:\n        _check_he_embeddings(adatas)\n\n    _select_novae_genes(adatas, var_names)\n\n    if var_names is None:\n        var_names = _genes_union(adatas, among_used=True)\n\n    return adatas, var_names\n</code></pre>"},{"location":"tutorials/he_usage/","title":"Adding H&amp;E information","text":"In\u00a0[\u00a0]: Copied! <pre>import sopa\n\nimport novae\n</pre> import sopa  import novae In\u00a0[\u00a0]: Copied! <pre># if you want to run cell segmentation with Sopa, remove cells_table and cells_boundaries\nsdata = sopa.io.xenium(\"Xenium_Prime_Human_Lung_Cancer_FFPE_outs\", cells_table=True, cells_boundaries=True)\n</pre> # if you want to run cell segmentation with Sopa, remove cells_table and cells_boundaries sdata = sopa.io.xenium(\"Xenium_Prime_Human_Lung_Cancer_FFPE_outs\", cells_table=True, cells_boundaries=True) <p>You see that you have your Xenium image, an H&amp;E image, cell boundaries with the corresponding cell-by-gene table, and transcripts.</p> <p>\u26a0\ufe0f If you don't already have aligned H&amp;E, see this Sopa tutorial to align it.</p> In\u00a0[43]: Copied! <pre>sdata\n</pre> sdata Out[43]: <pre>SpatialData object\n\u251c\u2500\u2500 Images\n\u2502     \u251c\u2500\u2500 'he_image': DataTree[cyx] (3, 43270, 26720), (3, 21635, 13360), (3, 10817, 6680), (3, 5408, 3340), (3, 2704, 1670)\n\u2502     \u2514\u2500\u2500 'morphology_focus': DataTree[cyx] (4, 37348, 54086), (4, 18674, 27043), (4, 9337, 13521), (4, 4668, 6760), (4, 2334, 3380)\n\u251c\u2500\u2500 Points\n\u2502     \u2514\u2500\u2500 'transcripts': DataFrame with shape: (&lt;Delayed&gt;, 13) (3D points)\n\u251c\u2500\u2500 Shapes\n\u2502     \u2514\u2500\u2500 'cell_boundaries': GeoDataFrame shape: (278328, 1) (2D shapes)\n\u2514\u2500\u2500 Tables\n      \u2514\u2500\u2500 'table': AnnData (278328, 5001)\nwith coordinate systems:\n    \u25b8 'global', with elements:\n        he_image (Images), morphology_focus (Images), transcripts (Points), cell_boundaries (Shapes)</pre> <p>For efficiency, you can save your <code>SpatialData</code> object and re-open it. Future computations will be faster.</p> In\u00a0[\u00a0]: Copied! <pre>import spatialdata\n\n# save it as a zarr diectory\nsdata.write(\"Xenium_Prime_Human_Lung_Cancer_FFPE_outs.zarr\")\n\n# and read it back\nsdata = spatialdata.read_zarr(\"Xenium_Prime_Human_Lung_Cancer_FFPE_outs.zarr\")\n</pre> import spatialdata  # save it as a zarr diectory sdata.write(\"Xenium_Prime_Human_Lung_Cancer_FFPE_outs.zarr\")  # and read it back sdata = spatialdata.read_zarr(\"Xenium_Prime_Human_Lung_Cancer_FFPE_outs.zarr\") In\u00a0[\u00a0]: Copied! <pre>novae.compute_histo_embeddings(sdata, model=\"conch\", device=\"cuda\")\n</pre> novae.compute_histo_embeddings(sdata, model=\"conch\", device=\"cuda\") In\u00a0[\u00a0]: Copied! <pre>novae.compute_histo_pca(sdata)\n</pre> novae.compute_histo_pca(sdata) In\u00a0[\u00a0]: Copied! <pre>import scanpy as sc\n\n# dimension number 0 of the CONCH embeddings\nsc.pl.spatial(sdata[\"conch_embeddings\"], color=\"0\", spot_size=10)\n</pre> import scanpy as sc  # dimension number 0 of the CONCH embeddings sc.pl.spatial(sdata[\"conch_embeddings\"], color=\"0\", spot_size=10) <p>You can also show the same embeddings but once projected over the cells. It can be found inside the <code>table</code> AnnData object, under the <code>adata.obsm[\"histo_embeddings\"]</code>.</p> <p>Note: the image show a different orientation, which is because the one above is shown on the H&amp;E coordinate system, while the one below is using the micron coordinate system of the Xenium. Since we use <code>SpatialData</code>, we can transform any object to another coordinate systems if desired.</p> In\u00a0[\u00a0]: Copied! <pre>adata = sdata[\"table\"]\n\nadata.obs[\"pca_dim0_cells\"] = adata.obsm[\"histo_embeddings\"][:, 0]\n\nsc.pl.spatial(adata, color=\"pca_dim0_cells\", spot_size=10)\n</pre> adata = sdata[\"table\"]  adata.obs[\"pca_dim0_cells\"] = adata.obsm[\"histo_embeddings\"][:, 0]  sc.pl.spatial(adata, color=\"pca_dim0_cells\", spot_size=10) In\u00a0[62]: Copied! <pre>adata = sdata[\"table\"]\n</pre> adata = sdata[\"table\"] <p>We see that we now have <code>histo_embeddings</code> in <code>adata.obsm</code>:</p> In\u00a0[51]: Copied! <pre>adata.obsm\n</pre> adata.obsm Out[51]: <pre>AxisArrays with keys: intensities, spatial, histo_embeddings</pre> <p>As is the other tutorials, we compute the <code>spatial_neighbors</code>:</p> In\u00a0[64]: Copied! <pre>novae.spatial_neighbors(adata, radius=80)  # try other radius if you see too many unconnected cells\n</pre> novae.spatial_neighbors(adata, radius=80)  # try other radius if you see too many unconnected cells <pre>[INFO] (novae.utils.build) Computing graph on 278,328 cells (coord_type=generic, delaunay=True, radius=[0.0, 80.0], n_neighs=None)\n</pre> <p>And we can check the connectivities, as in the other tutorials:</p> In\u00a0[65]: Copied! <pre>novae.plot.connectivities(adata)\n</pre> novae.plot.connectivities(adata) <p>You can then create a new Novae model.</p> <p>Note: By default it will initialize the gene embeddings via a PCA. You can also provide a <code>scgpt_model_dir</code> (see the docs here) to replace the PCA.</p> <p>Note 2: You can also fine-tune a pretrained model as in the other tutorials. It will automatically detect it has to use the multimodal mode, but this has not been extensively tested.</p> In\u00a0[54]: Copied! <pre>model = novae.Novae(adata)\n</pre> model = novae.Novae(adata) <pre>[INFO] (novae.module.embed) Running PCA embedding initialization\n</pre> <p>Normally, showing the model now shows <code>Multimodal: True</code>. Note that <code>Trained: False</code> indicated the model is still not trained.</p> In\u00a0[55]: Copied! <pre>model\n</pre> model Out[55]: <pre>Novae model\n   \u251c\u2500\u2500 Known genes: 250\n   \u251c\u2500\u2500 Parameters: 523.4K\n   \u251c\u2500\u2500 Model name: None\n   \u251c\u2500\u2500 Trained: False\n   \u2514\u2500\u2500 Multimodal: True</pre> <p>Then, you can <code>fit</code> the Novae model. Here, we used a <code>cuda</code> to accelerate the training (recommanded).</p> <p>Note: we also decreased the learning rate and increased the total number of epochs allowed. This is optional, you can also keep the default parameters (it would be faster).</p> In\u00a0[\u00a0]: Copied! <pre>model.fit(adata, accelerator=\"cuda\", num_workers=4, lr=2e-4, max_epochs=40)\n</pre> model.fit(adata, accelerator=\"cuda\", num_workers=4, lr=2e-4, max_epochs=40) <p>The other steps are the same as in the other tutorials. I.e., we first compute the representations (here we use <code>cuda</code> again).</p> In\u00a0[\u00a0]: Copied! <pre>model.compute_representations(adata, accelerator=\"cuda\", num_workers=4)\n</pre> model.compute_representations(adata, accelerator=\"cuda\", num_workers=4) <p>Then assign the domains to the cells:</p> In\u00a0[58]: Copied! <pre>model.assign_domains(adata, level=8)\n</pre> model.assign_domains(adata, level=8) Out[58]: <pre>'novae_domains_8'</pre> <p>And, finally, we plot the spatial domains:</p> In\u00a0[78]: Copied! <pre>novae.plot.domains(adata)\n</pre> novae.plot.domains(adata) <pre>[INFO] (novae.utils._validate) Using obs_key='novae_domains_8' by default.\n</pre>"},{"location":"tutorials/he_usage/#adding-he-information","title":"Adding H&amp;E information\u00b6","text":"<p>In case you have an H&amp;E slide aligned with your Spatial Transcriptomics data, you can train a new <code>Novae</code> model in multimodal mode.</p> <p>To handle Spatial Transcriptomics combined with H&amp;E data, <code>novae</code> uses <code>sopa</code> and <code>spatialdata</code> as a backend. To use these libraries, install <code>novae</code> with the <code>multimodal</code> extra, for instance:</p> <pre># just the multimodal extra\npip install 'novae[multimodal]'\n\n# with the CONCH extra, if you want CONCH embeddings\npip install 'novae[multimodal,conch]'\n</pre>"},{"location":"tutorials/he_usage/#create-a-spatialdata-object","title":"Create a SpatialData object\u00b6","text":"<p>You can open the data of one sample with one of the readers from <code>sopa.io</code>.</p> <p>If you don't have your own data, you can also download this Xenium sample from 10X Genomics (in the \"Output\" panel, select \"Xenium Prime 5K\"). You can also directly download this sample via the command line as shown in this script. You can also use <code>sdata = sopa.io.toy_dataset(as_output=True, genes=500)</code> for testing purposes.</p> <p>Note: you can also remove the <code>cells_table</code> and <code>cells_boundaries</code> argument, and re-run cell segmentation with Sopa.</p>"},{"location":"tutorials/he_usage/#prepare-the-he-embeddings","title":"Prepare the H&amp;E embeddings\u00b6","text":""},{"location":"tutorials/he_usage/#1-computing-patch-embeddings","title":"1. Computing patch embeddings\u00b6","text":"<p>We can define patches and use a computer vision model to extract embeddings from each patch. Here, to make it faster, we only compute patches which touches at least one cell, which may considerably reduce the number of patches.</p> <p>By default, we use CONCH, which requires the two following step:</p> <ol> <li>If not done yet, install the CONCH extra with <code>pip install 'novae[multimodal,conch]'</code></li> <li>Log in Hugging Face and approve their License, see here.</li> </ol> <p>\u26a0\ufe0f You can use other models, see the sopa documentation for more details.</p> <p>This can be done via <code>compute_histo_embeddings</code>, as below. Note that we used <code>device=\"cuda\"</code> to accelerate the embeddings computation.</p>"},{"location":"tutorials/he_usage/#2-assigning-the-embeddings-to-the-cells","title":"2. Assigning the embeddings to the cells\u00b6","text":"<p>Now that we have one embedding per patch, we can compute a PCA of these embeddings add assign to each cell the embedding of the closest patch. This can be done via <code>compute_histo_pca</code> as below.</p> <p>We will have one patch embedding per cell (multiple cells may share the same embedding). This embedding is an H&amp;E representation of the cell neighborhood, not just the cell itself.</p> <p>\u26a0\ufe0f If you have multiple slides, run the previous <code>compute_histo_embeddings</code> function for each <code>sdata</code> object/slide, but run the below <code>compute_histo_pca</code> function with all the slides to have a shared embedding. Just pass a list of <code>SpatialData</code> objects instead of one.</p>"},{"location":"tutorials/he_usage/#optional-show-the-conch-embeddings","title":"(Optional) show the CONCH embeddings\u00b6","text":"<p>The CONCH embeddings are added as an AnnData table to the <code>SpatialData</code> object. You can show any dimension of these embeddings spatially as below.</p> <p>These are the patch embeddings, not the embeddings per cell.</p>"},{"location":"tutorials/he_usage/#training-novae","title":"Training Novae\u00b6","text":"<p>Now, we can go back to our cell-by-gene <code>AnnData</code> object. It's stored inside the <code>SpatialData</code> object:</p>"},{"location":"tutorials/input_modes/","title":"Different input modes","text":"<p>Depending on your data and preferences, you can use 4 types of inputs. Specifically, it depends on whether (i) you have one or multiple slides and (ii) you prefer to concatenate your data.</p> <p>Info</p> <p>In all cases, the data structure is AnnData. We may support MuData in the future.</p>"},{"location":"tutorials/input_modes/#1-one-slide-mode","title":"1. One slide mode","text":"<p>This case is the easiest one. You simply have one <code>AnnData</code> object corresponding to one slide.</p> <p>You can follow the first section of the main usage tutorial.</p>"},{"location":"tutorials/input_modes/#2-multiple-slides-one-anndata-object","title":"2. Multiple slides, one AnnData object","text":"<p>If you have multiple slides with the same gene panel, you can concatenate them into one <code>AnnData</code> object. In that case, make sure you keep a column in <code>adata.obs</code> that denotes which cell corresponds to which slide.</p> <p>Then, remind this column, and pass it to <code>novae.spatial_neighbors</code>.</p> <p>Example</p> <p>For instance, you can do: <pre><code>novae.spatial_neighbors(adata, slide_key=\"my-slide-id-column\")\n</code></pre></p>"},{"location":"tutorials/input_modes/#3-multiple-slides-one-anndata-object-per-slide","title":"3. Multiple slides, one AnnData object per slide","text":"<p>If you have multiple slides, you may prefer to keep one <code>AnnData</code> object for each slide. This is also convenient if you have different gene panels and can't concatenate your data.</p> <p>That case is pretty easy, since most functions and methods of Novae also support a list of <code>AnnData</code> objects as inputs. Therefore, simply pass a list of <code>AnnData</code> object, as below:</p> <p>Example</p> <pre><code>adatas = [adata_1, adata_2, ...]\n\nnovae.spatial_neighbors(adatas)\n\nmodel.compute_representations(adatas, zero_shot=True)\n</code></pre>"},{"location":"tutorials/input_modes/#4-multiple-slides-multiple-slides-per-anndata-object","title":"4. Multiple slides, multiple slides per AnnData object","text":"<p>If you have multiple slides and multiple panels, instead of the above option, you could have one <code>AnnData</code> object per panel, and multiple slides inside each <code>AnnData</code> object. In that case, make sure you keep a column in <code>adata.obs</code> that denotes which cell corresponds to which slide.</p> <p>Then, remind this column, and pass it to <code>novae.spatial_neighbors</code>. The other functions don't need this argument.</p> <p>Example</p> <p>For instance, you can do: <pre><code>adatas = [adata_1, adata_2, ...]\n\nnovae.spatial_neighbors(adatas, slide_key=\"my-slide-id-column\")\n\nmodel.compute_representations(adatas, zero_shot=True)\n</code></pre></p>"},{"location":"tutorials/main_usage/","title":"Main usage of Novae","text":"In\u00a0[65]: Copied! <pre>import novae\n</pre> import novae In\u00a0[\u00a0]: Copied! <pre>adata = novae.load_dataset(tissue=\"colon\", species=\"human\", pattern=\".*P2.*\")[0]\nadata\n</pre> adata = novae.load_dataset(tissue=\"colon\", species=\"human\", pattern=\".*P2.*\")[0] adata <pre>[INFO] (novae.utils._data) Found 1 h5ad file(s) matching the filters.\n</pre> Out[\u00a0]: <pre>AnnData object with n_obs \u00d7 n_vars = 340837 \u00d7 422\n    obs: 'cell_id', 'transcript_counts', 'control_probe_counts', 'control_codeword_counts', 'unassigned_codeword_counts', 'deprecated_codeword_counts', 'total_counts', 'cell_area', 'nucleus_area', 'region', 'slide_id', 'technology'\n    var: 'gene_ids', 'feature_types', 'genome', 'n_cells'\n    uns: 'log1p', 'neighbors', 'spatial_neighbors', 'spatialdata_attrs', 'umap'\n    obsm: 'X_pca', 'X_umap', 'spatial'\n    layers: 'counts'\n    obsp: 'connectivities', 'distances', 'spatial_connectivities', 'spatial_distances'</pre> <p>Then, preprocessing is not mandatory, as Novae can handle it automatically. Here is some extra information:</p> <ul> <li>You can have either \"log1p data\" or \"raw counts\" in <code>adata.X</code>. In the latter case, Novae will preprocess it and save the counts in <code>adata.obsm</code>.</li> <li>We automatically select the genes that Novae should use. We use the highly variable genes (or eventually other genes, if not enough HVG).</li> </ul> <p>NB: You can disable the automatic preprocessing with <code>novae.settings.auto_preprocessing = False</code></p> In\u00a0[5]: Copied! <pre># if you have multiple samples in the same adata object, specify `slide_key`\nnovae.spatial_neighbors(adata, radius=80)\n</pre> # if you have multiple samples in the same adata object, specify `slide_key` novae.spatial_neighbors(adata, radius=80) <pre>[INFO] (novae.utils._build) Computing graph on 340,837 cells (coord_type=generic, delaunay=True, radius=[0.0, 80.0], n_neighs=None)\n</pre> <p>We can also show the graph of connectivities, which is a good quality control. Nodes in red are cells that are connected to very few other cells (<code>ngh_threshold=2</code>, by default). In particular:</p> <ol> <li>You should have a relatively low amount of \"red\" cells. If so, decrease the <code>radius</code> parameter.</li> <li>Regions that are far apart should not be connected. If so, increase the <code>radius</code> parameter.</li> </ol> <p>If the graph is not looking right, check the docs of <code>novae.spatial_neighbors</code> to adapt it.</p> In\u00a0[6]: Copied! <pre>novae.plot.connectivities(adata)\n</pre> novae.plot.connectivities(adata) In\u00a0[7]: Copied! <pre>model = novae.Novae.from_pretrained(\"MICS-Lab/novae-human-0\")\nmodel\n</pre> model = novae.Novae.from_pretrained(\"MICS-Lab/novae-human-0\") model Out[7]: <pre>Novae model\n   \u251c\u2500\u2500 Known genes: 60697\n   \u251c\u2500\u2500 Parameters: 32.0M\n   \u2514\u2500\u2500 Model name: MICS-Lab/novae-human-0</pre> <p>Now, we can compute the spatial representations for each cell. In the first option below, we pass the argument <code>zero_shot=True</code> to run only inference (i.e., the model is not re-trained).</p> <p>Instead of zero-shot, if you want to fine-tune the model, you can use the <code>fine_tune</code> method, and then call <code>compute_representations</code> without the <code>zero_shot</code> argument (see \"option 2\").</p> <p>\u26a0\ufe0f If you have a GPU, you can pass <code>accelerator=\"gpu\", num_workers=4</code> to the functions below (both <code>fine_tune</code> and <code>compute_representations</code>) to make it faster.</p> In\u00a0[\u00a0]: Copied! <pre># Option 1: zero-shot\nmodel.compute_representations(adata, zero_shot=True)\n\n# Option 2: fine-tuning\nmodel.fine_tune(adata)\nmodel.compute_representations(adata)\n</pre> # Option 1: zero-shot model.compute_representations(adata, zero_shot=True)  # Option 2: fine-tuning model.fine_tune(adata) model.compute_representations(adata) <p>To assign domains, you can use the <code>assign_domains</code> method, as below. By default, it creates 7 domains, but you can choose the number of domains you want with the <code>level</code> argument.</p> <p>The function will save the domains in <code>adata.obs</code>, and return the name of the column in which it was saved (in this case, <code>adata.obs[\"novae_domains_7\"]</code>)</p> In\u00a0[9]: Copied! <pre>model.assign_domains(adata)\n</pre> model.assign_domains(adata) Out[9]: <pre>'novae_domains_7'</pre> <p>Then, to show the results, you can use <code>novae.plot.domains</code>.</p> <p>You can also use scanpy.pl.spatial. Actually, <code>novae.plot.domains</code> uses Scanpy internally but adds extra functionalities related to Novae.</p> <p>If you run <code>model.assign_domains</code> multiple times, you can also decide the resolution you want to show, by passing the <code>obs_key</code> argument to <code>novae.plot.domains</code>.</p> In\u00a0[10]: Copied! <pre>novae.plot.domains(adata)\n</pre> novae.plot.domains(adata) <pre>[INFO] (novae.utils._validate) Using obs_key='novae_domains_7' as default.\n</pre> <p>Novae has a hierarchical organization of the spatial domains. That is, if you run multiple times <code>assign_domains</code> with different <code>level</code> parameters, the domains at different resolutions will be nested inside each other.</p> <p>To plot the hierarchy of the domains, you can use the <code>plot_domains_hierarchy</code> method of Novae, as below:</p> In\u00a0[11]: Copied! <pre>model.plot_domains_hierarchy()\n</pre> model.plot_domains_hierarchy() In\u00a0[\u00a0]: Copied! <pre>adatas = novae.load_dataset(tissue=\"brain\", species=\"mouse\")\n</pre> adatas = novae.load_dataset(tissue=\"brain\", species=\"mouse\") <pre>[INFO] (novae.utils._data) Found 6 h5ad file(s) matching the filters.\n</pre> In\u00a0[67]: Copied! <pre># adata object of the first slide\nadatas[0]\n</pre> # adata object of the first slide adatas[0] Out[67]: <pre>AnnData object with n_obs \u00d7 n_vars = 53913 \u00d7 346\n    obs: 'cell_id', 'transcript_counts', 'control_probe_counts', 'control_codeword_counts', 'unassigned_codeword_counts', 'total_counts', 'cell_area', 'nucleus_area', 'region', 'slide_id', 'technology'\n    var: 'gene_ids', 'feature_types', 'genome', 'n_cells'\n    uns: 'log1p', 'neighbors', 'novae_tissue', 'spatial_neighbors', 'spatialdata_attrs', 'umap'\n    obsm: 'X_pca', 'X_umap', 'spatial'\n    layers: 'counts'\n    obsp: 'connectivities', 'distances', 'spatial_connectivities', 'spatial_distances'</pre> In\u00a0[69]: Copied! <pre># Option 1: Multiple AnnData objects (one per slide)\nnovae.spatial_neighbors(adatas, radius=80)\n\n# Option 2: One AnnData object with multiple slides\n# In that case, you need to precise the name of the column in adata.obs\n# that contains the slide identifiers using `slide_key`.\nnovae.spatial_neighbors(adata, radius=80, slide_key=\"my-slide-column\")\n\n# Option 3: Multiple AnnData objects, each containing multiple slides\n# Similarly, you can pass a list of AnnData objects, and precise the slide_key\nnovae.spatial_neighbors(adatas, radius=80, slide_key=\"my-slide-column\")\n</pre> # Option 1: Multiple AnnData objects (one per slide) novae.spatial_neighbors(adatas, radius=80)  # Option 2: One AnnData object with multiple slides # In that case, you need to precise the name of the column in adata.obs # that contains the slide identifiers using `slide_key`. novae.spatial_neighbors(adata, radius=80, slide_key=\"my-slide-column\")  # Option 3: Multiple AnnData objects, each containing multiple slides # Similarly, you can pass a list of AnnData objects, and precise the slide_key novae.spatial_neighbors(adatas, radius=80, slide_key=\"my-slide-column\") <pre>[INFO] (novae.utils._build) Computing graph on 53,913 cells (coord_type=generic, delaunay=True, radius=[0.0, 80.0], n_neighs=None)\n[INFO] (novae.utils._build) Computing graph on 58,682 cells (coord_type=generic, delaunay=True, radius=[0.0, 80.0], n_neighs=None)\n[INFO] (novae.utils._build) Computing graph on 62,268 cells (coord_type=generic, delaunay=True, radius=[0.0, 80.0], n_neighs=None)\n[INFO] (novae.utils._build) Computing graph on 58,685 cells (coord_type=generic, delaunay=True, radius=[0.0, 80.0], n_neighs=None)\n[INFO] (novae.utils._build) Computing graph on 58,231 cells (coord_type=generic, delaunay=True, radius=[0.0, 80.0], n_neighs=None)\n[INFO] (novae.utils._build) Computing graph on 59,935 cells (coord_type=generic, delaunay=True, radius=[0.0, 80.0], n_neighs=None)\n</pre> <p>Again, we can show the cells connectivites. See the above explanations to understand how to perform quality controls based on this plot.</p> In\u00a0[70]: Copied! <pre>novae.plot.connectivities(adatas)\n</pre> novae.plot.connectivities(adatas) <p>Since we are now working on mouse brain data, we'll load the brain model, as shown below.</p> <p>Reminder: for human tissues, you can use the <code>\"MICS-Lab/novae-human-0\"</code> model. Again, other model names can be found here.</p> In\u00a0[71]: Copied! <pre>model = novae.Novae.from_pretrained(\"MICS-Lab/novae-brain-0\")\nmodel\n</pre> model = novae.Novae.from_pretrained(\"MICS-Lab/novae-brain-0\") model Out[71]: <pre>Novae model\n   \u251c\u2500\u2500 Known genes: 60697\n   \u251c\u2500\u2500 Parameters: 32.0M\n   \u2514\u2500\u2500 Model name: MICS-Lab/novae-brain-0</pre> <p>Then, the usage of Novae is similar to above, and you can again use zero-shot or fine-tuning (see the first section of this tutorial for more details).</p> In\u00a0[72]: Copied! <pre># Option 1: zero-shot\nmodel.compute_representations(adatas, zero_shot=True)\n\n# Option 2: fine-tuning\nmodel.fine_tune(adatas)\nmodel.compute_representations(adatas)\n</pre> # Option 1: zero-shot model.compute_representations(adatas, zero_shot=True)  # Option 2: fine-tuning model.fine_tune(adatas) model.compute_representations(adatas) <pre>Computing representations:   0%|          | 0/106 [00:00&lt;?, ?it/s]</pre> <pre>Computing representations:   0%|          | 0/115 [00:00&lt;?, ?it/s]</pre> <pre>Computing representations:   0%|          | 0/122 [00:00&lt;?, ?it/s]</pre> <pre>Computing representations:   0%|          | 0/115 [00:00&lt;?, ?it/s]</pre> <pre>Computing representations:   0%|          | 0/114 [00:00&lt;?, ?it/s]</pre> <pre>Computing representations:   0%|          | 0/117 [00:00&lt;?, ?it/s]</pre> <p>Again, the command line to assign domains is the same. Here, we assigned 15 domains.</p> In\u00a0[73]: Copied! <pre>model.assign_domains(adatas, level=15)\n</pre> model.assign_domains(adatas, level=15) Out[73]: <pre>'novae_domains_15'</pre> <p>And, again, we can show the domains:</p> <p>Here, we added the <code>slide_name_key</code> argument, which is optional and used to display the name of each slide ( <code>slide_name_key</code> should be a column name of <code>adata.obs</code>).</p> In\u00a0[75]: Copied! <pre>novae.plot.domains(adatas, slide_name_key=\"slide_id\", cell_size=20)\n</pre> novae.plot.domains(adatas, slide_name_key=\"slide_id\", cell_size=20) <pre>[INFO] (novae.utils._validate) Using obs_key='novae_domains_15' as default.\n</pre> In\u00a0[76]: Copied! <pre>model.batch_effect_correction(adatas)\n</pre> model.batch_effect_correction(adatas) <pre>[INFO] (novae.utils._validate) Using obs_key='novae_domains_15' as default.\n</pre> <p>This saved the corrected representations inside <code>adata.obsm[\"novae_latent_corrected\"]</code>. You can use these corrected representations for further analysis.</p> <p>Note that this representation is a spatial domain representation of each cell, not a cell expression representation. Indeed, it contains information on the local neighborhoods of the cells.</p> In\u00a0[77]: Copied! <pre>novae.plot.domains_proportions(adatas, obs_key=\"novae_domains_15\")\n</pre> novae.plot.domains_proportions(adatas, obs_key=\"novae_domains_15\") In\u00a0[78]: Copied! <pre>novae.plot.paga(adatas[0])\n</pre> novae.plot.paga(adatas[0]) <pre>[INFO] (novae.utils._validate) Using obs_key='novae_domains_15' as default.\n</pre> In\u00a0[79]: Copied! <pre>novae.plot.spatially_variable_genes(adatas[0], top_k=3, vmax=\"p95\", cell_size=20)\n</pre> novae.plot.spatially_variable_genes(adatas[0], top_k=3, vmax=\"p95\", cell_size=20) <pre>[INFO] (novae.utils._validate) Using obs_key='novae_domains_15' as default.\n</pre> In\u00a0[80]: Copied! <pre>novae.plot.pathway_scores(adatas[0], pathways=\"mouse_hallmarks.json\", figsize=(10, 7))\n</pre> novae.plot.pathway_scores(adatas[0], pathways=\"mouse_hallmarks.json\", figsize=(10, 7)) <pre>[INFO] (novae.utils._validate) Using obs_key='novae_domains_15' as default.\n[INFO] (novae.plot._heatmap) Loaded 50 pathway(s)\n[INFO] (novae.plot._heatmap) Plot mode: 24 pathways scores per domain\n</pre> In\u00a0[81]: Copied! <pre>import anndata\n\nadata_conc = anndata.concat(adatas)\n</pre> import anndata  adata_conc = anndata.concat(adatas) <p>Since the JSON file below contains only one pathway, it will detect that it must plot this pathway score per domain and slide. You can also force this behavior by providing the <code>pathway_name</code> argument.</p> In\u00a0[87]: Copied! <pre>novae.plot.pathway_scores(\n    adata_conc, pathways=\"LEE_AGING_CEREBELLUM_UP.json\", figsize=(4, 8), slide_name_key=\"slide_id\"\n)\n</pre> novae.plot.pathway_scores(     adata_conc, pathways=\"LEE_AGING_CEREBELLUM_UP.json\", figsize=(4, 8), slide_name_key=\"slide_id\" ) <pre>[INFO] (novae.utils._validate) Using obs_key='novae_domains_15' as default.\n[INFO] (novae.plot._heatmap) Loaded 1 pathway(s)\n[INFO] (novae.plot._heatmap) Plot mode: LEE_AGING_CEREBELLUM_UP score per domain per slide\n</pre>"},{"location":"tutorials/main_usage/#main-usage-of-novae","title":"Main usage of Novae\u00b6","text":"<p>This tutorial shows how to load a Novae model, apply it to your spatial data, and plot results. We show Noave's usage for spatial data with single-cell resolution (e.g., Xenium, MERSCOPE), but we will also soon make a tutorial for spot resolution data (e.g., Visium).</p> <p>Make sure you have installed Novae, e.g. using <code>pip install novae</code>, as detailed in the installation guide.</p>"},{"location":"tutorials/main_usage/#create-and-process-your-anndata-objects","title":"Create and process your AnnData object(s)\u00b6","text":"<p>Novae's input is one or multiple <code>AnnData</code> object(s). Having multiple <code>AnnData</code> objects can be useful when you have multiple gene panels, or when you don't want to concatenate your slides. See here for more details on all four possible input modes for Novae.</p> <p>For this tutorial, we first show an example using one <code>AnnData</code> object representing a colon slide. We load it with the <code>load_dataset</code> function.</p>"},{"location":"tutorials/main_usage/#one-slide-inference","title":"One-slide inference\u00b6","text":""},{"location":"tutorials/main_usage/#compute-the-cells-neighbors","title":"Compute the cells neighbors\u00b6","text":"<p>Novae runs on graphs of cells connected by physical proximity. To do so, we use <code>novae.spatial_neighbors</code>, which will connect the cells based on their locations (in <code>adata.obsm[\"spatial\"]</code>).</p> <p>Here, we use <code>radius=80</code> to drop edges longer than 80 microns (optional).</p>"},{"location":"tutorials/main_usage/#use-a-pretrained-model","title":"Use a pretrained model\u00b6","text":"<p>Now, we need to load a pretrained Novae model.</p> <p>Since we have a human colon slide, we load the <code>\"MICS-Lab/novae-human-0\"</code> model, which can be used on any human tissue for spatial data with single-cell resolution. Other model names can be found here (spot-resolution models, e.g., for Visium data, will come soon).</p>"},{"location":"tutorials/main_usage/#multi-slide-or-multi-panel","title":"Multi-slide or multi-panel\u00b6","text":"<p>You can use Novae on multiple slides or multiple panels. In that case, the input slightly changes: you can, for instance, have one <code>AnnData</code> object with a column that indicates the slide ID (if they share the same gene panel) or have a list of <code>AnnData</code> objects (one for each slide, or for each panel). For more details, refer to this tutorial.</p> <p>Here, we load 6 mouse brain slides. <code>adatas</code> is therefore a list of 6 <code>AnnData</code> objects.</p>"},{"location":"tutorials/main_usage/#multi-slide-neighbors","title":"Multi-slide neighbors\u00b6","text":"<p>When having multiple slides, computing the cells neighbors with <code>novae.spatial_neighbors</code> is slightly different. The multiple options are listed below and explained in more detail in this tutorial.</p> <p>For this specific example, we use option 1, i.e., a list of AnnData objects, each corresponding to one slide.</p>"},{"location":"tutorials/main_usage/#multi-slide-inference","title":"Multi-slide inference\u00b6","text":""},{"location":"tutorials/main_usage/#batch-effect-correction-of-the-spatial-representations","title":"Batch-effect correction of the spatial representations\u00b6","text":"<p>The spatial representations of each cell are stored in <code>adata.obsm[\"novae_latent\"]</code>, and they are not batch-effect corrected by default. Yet, the (categorical) spatial domains are corrected. Therefore, we can use the categorical spatial domains to correct the representations, using the <code>batch_effect_correction</code> method, as below:</p>"},{"location":"tutorials/main_usage/#downstream-analysis","title":"Downstream analysis\u00b6","text":"<p>Novae can also perform downstream analysis. We illustrated it below.</p>"},{"location":"tutorials/main_usage/#domains-proportion-per-slide","title":"Domains proportion per slide\u00b6","text":"<p>A first simple thing to do is to look at the proportion of each domain for each slide. For instance, you may be interested in finding domains that are more or less present under certain conditions or diseases.</p> <p>Again, the <code>slide_name_key</code> is optional and is only used to show the slide's names.</p> <p>Here, on our mouse brain slides, we see homogeneous domain proportions (which is expected in this very specific case).</p>"},{"location":"tutorials/main_usage/#slide-architecture","title":"Slide architecture\u00b6","text":"<p>We run trajectory inference (PAGA) on the spatial domains to extract a graph representing the \"architecture\" of a slide, or the \"spatial domains organization\".</p> <p>Currently, this function only supports one slide per call.</p>"},{"location":"tutorials/main_usage/#spatially-variable-genes-svg","title":"Spatially Variable Genes (SVG)\u00b6","text":"<p>To extract SVG, we run DEGs on the categorical spatial domains. The function below shows the 3 most variable genes.</p>"},{"location":"tutorials/main_usage/#spatial-pathway-analysis","title":"Spatial pathway analysis\u00b6","text":""},{"location":"tutorials/main_usage/#scores-per-domain","title":"Scores per domain\u00b6","text":"<p>We can score pathways for each domain using <code>scanpy.tl.score_genes</code>.</p> <p>The pathways input should be one of the following:</p> <ul> <li>a JSON file downloaded from the GSEA website.</li> <li>a <code>dict</code> whose keys are pathway names, and values are lists of genes (case insensitive).</li> </ul> <p>Currently, this function only supports one slide per call.</p>"},{"location":"tutorials/main_usage/#scores-per-slide-per-domain","title":"Scores per slide per domain\u00b6","text":"<p>We can also show the score of one pathway, for each slide and each domain, as in the article.</p> <p>Here, we need to concatenate our AnnData object into a single one. If you already have one <code>AnnData</code> object with multiple slides, you can skip this step (just ensure you provided <code>slide_key</code> in <code>novae.utils.spatial_neioghbors</code>).</p>"},{"location":"tutorials/proteins/","title":"Usage on proteins","text":"In\u00a0[1]: Copied! <pre>import novae\n</pre> import novae In\u00a0[\u00a0]: Copied! <pre>adatas = novae.load_dataset(\n    top_k=2,\n    tissue=\"head_and_neck\",\n    custom_filter=lambda df: df[\"n_proteins\"] &gt; 0,\n)\n</pre> adatas = novae.load_dataset(     top_k=2,     tissue=\"head_and_neck\",     custom_filter=lambda df: df[\"n_proteins\"] &gt; 0, ) <pre>[INFO] (novae.utils._data) Found 2 h5ad file(s) matching the filters.\n</pre> <pre>10H064210813H0208914_down.h5ad:   0%|          | 0.00/230M [00:00&lt;?, ?B/s]</pre> <pre>10H064210813H0208914_up.h5ad:   0%|          | 0.00/184M [00:00&lt;?, ?B/s]</pre> In\u00a0[5]: Copied! <pre>adatas\n</pre> adatas Out[5]: <pre>[AnnData object with n_obs \u00d7 n_vars = 140139 \u00d7 63\n     obs: 'annot_level1', 'ID', 'annot_level0', 'novae_sid'\n     uns: 'annot_level0_colors', 'annot_level1_colors', 'spatial_neighbors'\n     obsm: 'X_pca', 'X_umap', 'spatial'\n     layers: 'counts'\n     obsp: 'spatial_connectivities', 'spatial_distances',\n AnnData object with n_obs \u00d7 n_vars = 112155 \u00d7 63\n     obs: 'annot_level1', 'ID', 'annot_level0', 'novae_sid'\n     uns: 'annot_level0_colors', 'annot_level1_colors', 'spatial_neighbors'\n     obsm: 'X_pca', 'X_umap', 'spatial'\n     layers: 'counts'\n     obsp: 'spatial_connectivities', 'spatial_distances']</pre> In\u00a0[23]: Copied! <pre>novae.spatial_neighbors(adatas, radius=300)\n</pre> novae.spatial_neighbors(adatas, radius=300) <pre>[INFO] (novae.utils._build) Computing graph on 140,139 cells (coord_type=generic, delaunay=True, radius=[0.0, 300.0], n_neighs=None)\n[INFO] (novae.utils._build) Computing graph on 112,155 cells (coord_type=generic, delaunay=True, radius=[0.0, 300.0], n_neighs=None)\n</pre> <p>We can show the graph of connectivities, which is a good quality control. Nodes in red are cells that are connected to very few other cells (<code>ngh_threshold=2</code>, by default). In particular:</p> <ol> <li>You should have a relatively low amount of \"red\" cells. If so, decrease the <code>radius</code> parameter.</li> <li>Regions that are far apart should not be connected. If so, increase the <code>radius</code> parameter.</li> </ol> <p>If the graph is not looking right, check the docs of <code>novae.spatial_neighbors</code> to adapt it.</p> In\u00a0[24]: Copied! <pre>novae.plot.connectivities(adatas)\n</pre> novae.plot.connectivities(adatas) In\u00a0[\u00a0]: Copied! <pre>novae.settings.auto_preprocessing = False  # prevent Novae from running normalize_total / log1p\n\nnovae.data.quantile_scaling(adatas)\n</pre> novae.settings.auto_preprocessing = False  # prevent Novae from running normalize_total / log1p  novae.data.quantile_scaling(adatas) In\u00a0[20]: Copied! <pre>embedding_size = adatas[0].n_vars - 1\nembedding_size\n</pre> embedding_size = adatas[0].n_vars - 1 embedding_size Out[20]: <pre>62</pre> <p>We create a new Novae model. Since it doesn't have any embedding for the proteins, it will run a PCA to initialize the embeddings of the proteins.</p> In\u00a0[12]: Copied! <pre>model = novae.Novae(adatas, embedding_size=embedding_size)\n</pre> model = novae.Novae(adatas, embedding_size=embedding_size) <pre>[INFO] (novae.module.embed) Running PCA embedding initialization\n</pre> <p>Then, we train it (here, 4 epochs only).</p> In\u00a0[13]: Copied! <pre>model.fit(max_epochs=4)\n</pre> model.fit(max_epochs=4) <pre>GPU available: True (mps), used: False\nTPU available: False, using: 0 TPU cores\nHPU available: False, using: 0 HPUs\n/Users/quentinblampey/Library/Caches/pypoetry/virtualenvs/novae-ezkWKrh6-py3.10/lib/python3.10/site-packages/lightning/pytorch/trainer/setup.py:177: GPU available but not used. You can set it by doing `Trainer(accelerator='gpu')`.\n\n  | Name          | Type              | Params | Mode \n------------------------------------------------------------\n0 | cell_embedder | CellEmbedder      | 7.8 K  | train\n1 | encoder       | GraphEncoder      | 114 K  | train\n2 | augmentation  | GraphAugmentation | 0      | train\n3 | swav_head     | SwavHead          | 16.4 K | train\n------------------------------------------------------------\n138 K     Trainable params\n0         Non-trainable params\n138 K     Total params\n0.555     Total estimated model params size (MB)\n76        Modules in train mode\n0         Modules in eval mode\n/Users/quentinblampey/Library/Caches/pypoetry/virtualenvs/novae-ezkWKrh6-py3.10/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=9` in the `DataLoader` to improve performance.\n</pre> <pre>Training: |          | 0/? [00:00&lt;?, ?it/s]</pre> <pre>`Trainer.fit` stopped: `max_epochs=4` reached.\n</pre> <p>We compute the cells latent space.</p> In\u00a0[14]: Copied! <pre>model.compute_representations()\n</pre> model.compute_representations() <pre>Computing representations:   0%|          | 0/548 [00:00&lt;?, ?it/s]</pre> <pre>Computing representations:   0%|          | 0/439 [00:00&lt;?, ?it/s]</pre> <p>And we assign the domains.</p> In\u00a0[15]: Copied! <pre>model.assign_domains()\n</pre> model.assign_domains() Out[15]: <pre>'novae_domains_7'</pre> <p>Now, we can show the domains:</p> In\u00a0[17]: Copied! <pre>novae.plot.domains(adatas, cell_size=100)\n</pre> novae.plot.domains(adatas, cell_size=100) <pre>[INFO] (novae.utils._validate) Using obs_key='novae_domains_7' by default.\n</pre>"},{"location":"tutorials/proteins/#usage-on-proteins","title":"Usage on proteins\u00b6","text":"<p>Although Novae was mainly designed for spatial transcriptomics, it can also be used for spatial proteomics.</p> <p>The main difference with the normal tutorial is that we will not be able to use the pretrained model, so we'll re-train a Novae model from scratch.</p>"},{"location":"tutorials/proteins/#loading-the-data-objects","title":"Loading the data objects\u00b6","text":"<p>Similarly as in the other tutorials, we need to load one or multiple AnnData object(s). Here, we load the first 2 head&amp;neck slides which have protein information.</p> <p>See here for more details on all four possible input modes for Novae.</p>"},{"location":"tutorials/proteins/#compute-the-neighbors-graph","title":"Compute the neighbors graph\u00b6","text":"<p>Again, this step is similar to the spatial transcriptomics tutorial. The only difference is that, in our specific case, the coordinate system is in pixels (not microns), so <code>radius</code> is much higher that what we usually set.</p> <p>Please adjust <code>radius</code> based on your coordinate system, and make sure the plot below looks correct.</p>"},{"location":"tutorials/proteins/#preprocessing","title":"Preprocessing\u00b6","text":"<p>This is the first main difference. For spatial proteomics, we recommend using the preprocessing below.</p> <p>Check the docs of <code>novae.data.quantile_scaling</code> for more details.</p>"},{"location":"tutorials/proteins/#optional-remove-low-quality-proteins","title":"(Optional) Remove low quality proteins\u00b6","text":"<p>You can check your proteins intensity, e.g., using <code>sc.pl.spatial(adata, color=adata.var_names, vmax=\"p95\", spot_size=20)</code></p> <p>If you have proteins whose intensity highly depends on the Field-Of-View (typically, when you see a grid-like pattern) then you should not provide these to Novae. Otherwise, since you'll have FOV-specific intensities, Novae will detect the FOVs as specific domains.</p> <p>Practically, you can either (i) subset your <code>AnnData</code> object, or (ii) provide <code>var_names=&lt;list-of-proteins-to-keep&gt;</code> to <code>novae.Novae</code> when initializing the model (see next section). In the latter case, make sure to update <code>embedding_size</code> to be lower than the number of proteins you have chosen.</p>"},{"location":"tutorials/proteins/#training-a-new-model","title":"Training a new model\u00b6","text":"<p>Since we have here 63 proteins, we will use 62 (<code>n_proteins</code> - 1) as an embedding size.</p>"},{"location":"tutorials/resolutions/","title":"Spot or bin resolutions","text":"In\u00a0[13]: Copied! <pre>import scanpy as sc\n\nimport novae\n</pre> import scanpy as sc  import novae <p>You can load the output of Space Ranger as below. You can skip this step for the tutorial, as we'll load an existing dataset afterward.</p> <p>NB: <code>spatialdata_io</code> can be installed via <code>pip install spatialdata-io</code></p> In\u00a0[\u00a0]: Copied! <pre>import spatialdata_io\n\n# open the output of Space Ranger as a spatialdata object\nsdata = spatialdata_io.visium_hd(\"/path/to/spaceranger_output_dir\")\n\n# get the AnnData object corresponding to the 8 microns bins\nadata = sdata[\"square_008um\"]\n</pre> import spatialdata_io  # open the output of Space Ranger as a spatialdata object sdata = spatialdata_io.visium_hd(\"/path/to/spaceranger_output_dir\")  # get the AnnData object corresponding to the 8 microns bins adata = sdata[\"square_008um\"] <p>For the sake of this tutorial, we'll directly load the first 8um-bins <code>AnnData</code> object from the Novae database:</p> In\u00a0[\u00a0]: Copied! <pre>adata = novae.load_dataset(technology=\"visium_hd\")[0]\n</pre> adata = novae.load_dataset(technology=\"visium_hd\")[0] <p>We can run some basic filtering, e.g. we remove the bins with less than 10 counts, and we filter low-expressed genes.</p> In\u00a0[\u00a0]: Copied! <pre>sc.pp.filter_cells(adata, min_counts=10)\nsc.pp.filter_genes(adata, min_cells=1_000)\n</pre> sc.pp.filter_cells(adata, min_counts=10) sc.pp.filter_genes(adata, min_cells=1_000) <p>Then, we create the graph of spatial neighbors. We specify <code>technology=\"visium_hd\"</code> to use the grid structure of the 8um bins.</p> In\u00a0[4]: Copied! <pre>novae.utils.spatial_neighbors(adata, technology=\"visium_hd\")\n</pre> novae.utils.spatial_neighbors(adata, technology=\"visium_hd\") <pre>[INFO] (novae.utils._build) Computing graph on 600,414 cells (coord_type=grid, delaunay=False, radius=None, n_neighs=8)\n</pre> <p>We see that the graph is highly connected, except for some regions on the right (see the bins in red):</p> In\u00a0[5]: Copied! <pre>novae.plot.connectivities(adata)\n</pre> novae.plot.connectivities(adata) <p>Then we create a new Novae model.</p> In\u00a0[6]: Copied! <pre>model = novae.Novae(adata)\nmodel\n</pre> model = novae.Novae(adata) model <pre>[INFO] (novae.utils._validate) Preprocessed 1 adata object(s) with sc.pp.normalize_total and sc.pp.log1p (raw counts were saved in adata.layers['counts'])\nOMP: Info #276: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead.\n[INFO] (novae.module.embed) Running PCA embedding initialization\n</pre> Out[6]: <pre>Novae model\n   \u251c\u2500\u2500 Known genes: 672\n   \u251c\u2500\u2500 Parameters: 573.7K\n   \u2514\u2500\u2500 Model name: None</pre> <p>Then, we can train the model with the <code>fit</code> method:</p> <p>Refer to the API to use a GPU.</p> In\u00a0[\u00a0]: Copied! <pre>model.fit(max_epochs=10)  # or more epochs\n</pre> model.fit(max_epochs=10)  # or more epochs <p>Then, the usage of Novae is similar to the other tutorials.</p> <p>That is, we start by computing the bins representations via <code>compute_representations</code>:</p> In\u00a0[\u00a0]: Copied! <pre>model.compute_representations()\n</pre> model.compute_representations() <p>Then, we assign each bin representation to a spatial domain using the <code>assign_domains</code> method:</p> In\u00a0[\u00a0]: Copied! <pre>model.assign_domains(level=8)  # or more domains\n</pre> model.assign_domains(level=8)  # or more domains <p>Finally, we can plot these domains using <code>novae.plot.domains</code>:</p> In\u00a0[42]: Copied! <pre>novae.plot.domains(adata, cell_size=35)\n</pre> novae.plot.domains(adata, cell_size=35) <pre>[INFO] (novae.utils._validate) Using obs_key='novae_domains_8' by default.\n</pre> In\u00a0[1]: Copied! <pre>import scanpy as sc\n\nimport novae\n</pre> import scanpy as sc  import novae In\u00a0[\u00a0]: Copied! <pre>adatas = novae.load_dataset(technology=\"visium\")\n\nadata = sc.concat(adatas, index_unique=\"-\")\n</pre> adatas = novae.load_dataset(technology=\"visium\")  adata = sc.concat(adatas, index_unique=\"-\") <pre>[INFO] (novae.utils._data) Found 3 h5ad file(s) matching the filters.\n</pre> <p>Now, we can create the graph of spot neighbors.</p> <p>Here, since we merged the <code>AnnData</code> into a single <code>adata</code>, we need to precise <code>slide_key=\"slide_id\"</code>, where slide_id is the name of the column in <code>adata.obs</code> containing the ID of each slide.</p> In\u00a0[3]: Copied! <pre>novae.spatial_neighbors(adata, technology=\"visium\", slide_key=\"slide_id\")\n</pre> novae.spatial_neighbors(adata, technology=\"visium\", slide_key=\"slide_id\") <pre>[INFO] (novae.utils._build) Computing graph on 10,904 cells (coord_type=grid, delaunay=False, radius=None, n_neighs=6)\n</pre> <p>We can show which spots (in red) are not connected to enough neighbors:</p> In\u00a0[4]: Copied! <pre>novae.plot.connectivities(adata)\n</pre> novae.plot.connectivities(adata) <p>Then, we perform basic preprocessing: here, we keep only the top 3,000 highly variable genes.</p> In\u00a0[\u00a0]: Copied! <pre>sc.pp.highly_variable_genes(adata, flavor=\"seurat_v3\", n_top_genes=3000)\nadata = adata[:, adata.var[\"highly_variable\"]].copy()\n</pre> sc.pp.highly_variable_genes(adata, flavor=\"seurat_v3\", n_top_genes=3000) adata = adata[:, adata.var[\"highly_variable\"]].copy() <p>Then we create a new Novae model.</p> <p>Importantly, since the Visium resolution is lower, we set <code>n_hops_local=1, n_hops_view=1</code>, which are the hyperparameters used to define the neighborhoods. I.e., the spot neighbors will be only composed of their direct spot neighbors.</p> In\u00a0[6]: Copied! <pre>model = novae.Novae(adata, n_hops_local=1, n_hops_view=1, panel_subset_size=0.6)\nmodel\n</pre> model = novae.Novae(adata, n_hops_local=1, n_hops_view=1, panel_subset_size=0.6) model <pre>[INFO] (novae.utils._validate) Preprocessed 1 adata object(s) with sc.pp.normalize_total and sc.pp.log1p (raw counts were saved in adata.layers['counts'])\n[INFO] (novae.module.embed) Running PCA embedding initialization\n</pre> Out[6]: <pre>Novae model\n   \u251c\u2500\u2500 Known genes: 3000\n   \u251c\u2500\u2500 Parameters: 806.5K\n   \u2514\u2500\u2500 Model name: None</pre> <p>Then, we can train the model with the <code>fit</code> method:</p> <p>Refer to the API to use a GPU.</p> In\u00a0[\u00a0]: Copied! <pre>model.fit()\n</pre> model.fit() <p>Then, the usage of Novae is similar to the other tutorials.</p> <p>That is, we start by computing the spots representations via <code>compute_representations</code>:</p> In\u00a0[8]: Copied! <pre>model.compute_representations()\n</pre> model.compute_representations() <pre>Computing representations:   0%|          | 0/43 [00:00&lt;?, ?it/s]</pre> <p>Then, we assign each spot representation to a spatial domain using the <code>assign_domains</code> method:</p> In\u00a0[9]: Copied! <pre>model.assign_domains()\n</pre> model.assign_domains() Out[9]: <pre>'novae_domains_7'</pre> <p>Finally, we can plot these domains using <code>novae.plot.domains</code>:</p> In\u00a0[10]: Copied! <pre>novae.plot.domains(adata)\n</pre> novae.plot.domains(adata) <pre>[INFO] (novae.utils._validate) Using obs_key='novae_domains_7' by default.\n</pre>"},{"location":"tutorials/resolutions/#spot-or-bin-resolutions","title":"Spot or bin resolutions\u00b6","text":"<p>Our main tutorials focus on imaging-based technologies such as Xenium or MERSCOPE data. Still, you can use Novae on NGS-based technologies such as Visium or Visium HD data. Since the resolution is highly different, we split this tutorial into two main sections: one for Visium-like technologies, and one for VisiumHD-like technologies.</p>"},{"location":"tutorials/resolutions/#visium-hd-usage","title":"Visium HD usage\u00b6","text":"<p>For technologies with small bins such as VisiumHD data, you have two possibilities: you can either work on the cells themselves, or on the bins.</p>"},{"location":"tutorials/resolutions/#option-1-going-at-the-single-cell-resolution","title":"Option 1: Going at the single-cell resolution\u00b6","text":"<p>You can also use this Visium HD tutorial from Sopa to segment cells on the H&amp;E image and then aggregate the 2um bins inside the cells. This way, you'll have a single-cell resolution table, similar to what we get with Xenium or MERSCOPE data.</p> <p>Then, based on this single-cell table, you can follow the \"normal usage\" tutorial.</p>"},{"location":"tutorials/resolutions/#option-2-using-the-8um-bins","title":"Option 2: Using the 8um bins\u00b6","text":"<p>You can use spatialdata_io to read the output of SpaceRanger, it will create a SpatialData object containing multiple <code>AnnData</code> objects for the bins. You can simply use the <code>AnnData</code> corresponding to the 8um bins, which is the one that is the closest to a typical cell size.</p> <p>Then, you can use a pre-trained model (in zero-shot or fine-tuning as in the other tutorial), but since the nature of the data is different, you can also re-train a model like below.</p> <p>For more customization, like using a GPU, you can look at the API or the FAQ.</p>"},{"location":"tutorials/resolutions/#visium-data","title":"Visium data\u00b6","text":"<p>We don't have yet a foundation model for spot-based technologies. This may be added in the future.</p> <p>Meanwhile, you can train a Novae model on your dataset. Since Visium datasets have a relatively low number of spots (usually less than 100,000 spots), training a new Novae model is very fast.</p> <p>For more customization, like using a GPU, you can look at the API or the FAQ.</p> <p>NB: you may experience lower performances than for other technologies as long as we don't release a Visium foundation model.</p>"}]}